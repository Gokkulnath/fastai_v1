{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from nb_005 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carvana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(See final section of notebook for one-time data processing steps.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/carvana')\n",
    "PATH_PNG = PATH/'train_masks_png'\n",
    "PATH_X_FULL = PATH/'train'\n",
    "PATH_X_128 = PATH/'train-128'\n",
    "PATH_Y_FULL = PATH_PNG\n",
    "PATH_Y_128 = PATH/'train_masks-128'\n",
    "\n",
    "# start with the 128x128 images\n",
    "PATH_X = PATH_X_128\n",
    "PATH_Y = PATH_Y_128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_f = next(PATH_X.iterdir())\n",
    "x = open_image(img_f)\n",
    "show_image(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def pil2tensor(image, as_mask=False):\n",
    "    arr = torch.ByteTensor(torch.ByteStorage.from_buffer(image.tobytes()))\n",
    "    arr = arr.view(image.size[1], image.size[0], -1)\n",
    "    arr = arr.permute(2,0,1).float()\n",
    "    return arr if as_mask else arr.div_(255)\n",
    "\n",
    "def open_image(fn, as_mask=False):\n",
    "    x = PIL.Image.open(fn)\n",
    "    if not as_mask: x = x.convert('RGB')\n",
    "    return pil2tensor(x, as_mask=as_mask)\n",
    "\n",
    "def image2np(image):\n",
    "    res = image.cpu().permute(1,2,0).numpy()\n",
    "    return res[...,0] if res.shape[2]==1 else res\n",
    "\n",
    "def show_image(img, ax=None, figsize=(3,3), hide_axis=True, cmap='binary', alpha=None):\n",
    "    if ax is None: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(image2np(img), cmap=cmap, alpha=alpha)\n",
    "    if hide_axis: ax.axis('off')\n",
    "    return ax\n",
    "        \n",
    "def show_xy_image(xim, yim, ax=None, figsize=(3,3), alpha=0.5, hide_axis=True, cmap='RdGy_r'):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax1 = show_image(xim, ax=ax, hide_axis=hide_axis, cmap=cmap)\n",
    "    show_image(yim, ax=ax1, alpha=alpha, hide_axis=hide_axis, cmap=cmap)\n",
    "    if hide_axis: ax.axis('off')\n",
    "        \n",
    "def show_xy_images(x,y,rows,figsize=(9,9)):\n",
    "    fig, axs = plt.subplots(rows,rows,figsize=figsize)\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        show_xy_image(x[i], y[i], ax)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "class ImageMask(Image):\n",
    "    # no lighting changes to masks\n",
    "    # ??? should it actually be no logit changes?\n",
    "    def lighting(self, func, *args, **kwargs):\n",
    "        return self\n",
    "    \n",
    "    def refresh(self):\n",
    "        # always use mode nearest for mask sampling\n",
    "        force_nearest = {'mode':'nearest'}\n",
    "        self.sample_kwargs = {**self.sample_kwargs, **force_nearest}\n",
    "        super().refresh()\n",
    "        return self\n",
    "    \n",
    "    \n",
    "import nb_002b\n",
    "nb_002b.pil2tensor = pil2tensor\n",
    "nb_002b.open_image = open_image\n",
    "nb_002b.image2np = image2np\n",
    "nb_002b.show_image = show_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_fn(x_fn): return PATH_Y/f'{x_fn.name[:-4]}_mask.png'\n",
    "\n",
    "img_y_f = get_y_fn(img_f)\n",
    "y = open_image(img_y_f, as_mask=True)\n",
    "show_image(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_xy_image(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xy transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data types: regr, class, seg, bbox, polygon, generative (s/res, color), custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def apply_tfms(tfms, x, do_resolve=True, xtra=None, size=None,\n",
    "               mult=32, do_crop=True, padding_mode='reflect',**kwargs):\n",
    "    if not tfms: return x\n",
    "    if not xtra: xtra={}\n",
    "    tfms = sorted(listify(tfms), key=lambda o: o.tfm.order)\n",
    "    if do_resolve: resolve_tfms(tfms)\n",
    "    x.set_sample(padding_mode=padding_mode, **kwargs)\n",
    "    if size:\n",
    "        crop_target = get_crop_target(size, mult=mult)\n",
    "        target = get_resize_target(x, crop_target, do_crop=do_crop)\n",
    "        x.resize(target)\n",
    "\n",
    "    size_tfms = [o for o in tfms if isinstance(o.tfm,TfmCrop)]\n",
    "    for tfm in tfms:\n",
    "        if tfm.tfm in xtra: x = tfm(x, **xtra[tfm.tfm])\n",
    "        elif tfm in size_tfms: x = tfm(x, size=size, padding_mode=padding_mode)\n",
    "        else: x = tfm(x)\n",
    "    return x.px\n",
    "\n",
    "import nb_003\n",
    "nb_003.apply_tfms = apply_tfms\n",
    "\n",
    "class DatasetTfm(Dataset):\n",
    "    def __init__(self, ds:Dataset,tfms:Collection[Callable]=None,\n",
    "                 x_class=Image, y_class=None, tfm_y:bool=False, **kwargs):\n",
    "        self.ds,self.tfms,self.x_class,self.y_class,self.tfm_y,self.x_kwargs = ds,tfms,x_class,y_class,tfm_y,kwargs\n",
    "        self.y_kwargs = {**self.x_kwargs, **{'do_resolve':False}} # don't reset random vars\n",
    "        \n",
    "    def __len__(self): return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        x,y = self.ds[idx]\n",
    "        \n",
    "        if self.tfms is not None: \n",
    "            if self.x_class: x = self.x_class(x)\n",
    "            x = apply_tfms(self.tfms, x, **self.x_kwargs)\n",
    "            if self.tfm_y:\n",
    "                if self.y_class: y = self.y_class(y)\n",
    "                y = apply_tfms(self.tfms, y, **self.y_kwargs)\n",
    "        return x,y\n",
    "    \n",
    "import nb_002b\n",
    "nb_002b.DatasetTfm = DatasetTfm\n",
    "    \n",
    "def transform_datasets(train_ds, valid_ds, tfms, tfm_y=False, x_class=Image, y_class=None, size=None):\n",
    "    ttds = DatasetTfm(train_ds, tfms[0], tfm_y=tfm_y, x_class=x_class, y_class=y_class, size=size)\n",
    "    vtds = DatasetTfm(valid_ds, tfms[1], tfm_y=tfm_y, x_class=x_class, y_class=y_class, size=size)\n",
    "    return ttds, vtds\n",
    "\n",
    "import nb_005\n",
    "nb_005.transform_datasets = transform_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class MatchedFilesDataset(Dataset):\n",
    "    x_fns:List[Path]; y_fns:List[Path]\n",
    "    def __post_init__(self): assert len(self.x_fns)==len(self.y_fns)\n",
    "    def __repr__(self): return f'{type(self).__name__} of len {len(self.x_fns)}'\n",
    "    def __len__(self): return len(self.x_fns)\n",
    "    def __getitem__(self, i): \n",
    "        return open_image(self.x_fns[i]), open_image(self.y_fns[i],as_mask=True)\n",
    "    \n",
    "def split_by_idxs(seq, idxs):\n",
    "    '''A generator that returns sequence pieces, seperated by indexes specified in idxs. '''\n",
    "    last = 0\n",
    "    for idx in idxs:\n",
    "        if not (-len(seq) <= idx < len(seq)):\n",
    "            raise KeyError(f'Idx {idx} is out-of-bounds')\n",
    "        yield seq[last:idx]\n",
    "        last = idx\n",
    "    yield seq[last:]\n",
    "\n",
    "def split_by_idx(idxs, *a):\n",
    "    \"\"\"\n",
    "    Split each array passed as *a, to a pair of arrays like this (elements selected by idxs,  the remaining elements)\n",
    "    This can be used to split multiple arrays containing training data to validation and training set.\n",
    "    :param idxs [int]: list of indexes selected\n",
    "    :param a list: list of np.array, each array should have same amount of elements in the first dimension\n",
    "    :return: list of tuples, each containing a split of corresponding array from *a.\n",
    "            First element of each tuple is an array composed from elements selected by idxs,\n",
    "            second element is an array of remaining elements.\n",
    "    \"\"\"\n",
    "    mask = np.zeros(len(a[0]),dtype=bool)\n",
    "    mask[np.array(idxs)] = True\n",
    "    return [(o[mask],o[~mask]) for o in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fns = [o for o in PATH_X.iterdir() if o.is_file()]\n",
    "y_fns = [get_y_fn(o) for o in x_fns]\n",
    "val_idxs = list(range(1008))\n",
    "((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, np.array(x_fns), np.array(y_fns))\n",
    "train_ds = MatchedFilesDataset(trn_x, trn_y)\n",
    "valid_ds = MatchedFilesDataset(val_x, val_y)\n",
    "train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(train_ds))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=128\n",
    "tfms = get_transforms(do_flip=True, max_rotate=20, max_zoom=2., max_lighting=0.7, max_warp=0.3,p_affine=0.75)\n",
    "train_tds, valid_tds = transform_datasets(train_ds, valid_ds, tfms, tfm_y=True, y_class=ImageMask, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(1,4, figsize=(12,6))\n",
    "for i in range(4):\n",
    "    imgx,imgy = train_tds[i]\n",
    "    show_xy_image(imgx, imgy, axes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def normalize(x, mean,std):   return (x-mean[...,None,None]) / std[...,None,None]\n",
    "def denormalize(x, mean,std): return x*std[...,None,None] + mean[...,None,None]\n",
    "\n",
    "def normalize_batch(b, mean, std, do_y=False):\n",
    "    x,y = b\n",
    "    x = normalize(x,mean,std)\n",
    "    if do_y: y = normalize(y,mean,std)\n",
    "    return x,y\n",
    "\n",
    "def normalize_funcs(mean, std, do_y=False, device=None):\n",
    "    if device is None: device=default_device\n",
    "    return (partial(normalize_batch, mean=mean.to(device),std=std.to(device), do_y=do_y),\n",
    "            partial(denormalize,     mean=mean,           std=std))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagenet mean/std\n",
    "default_mean, default_std = Tensor([0.485, 0.456, 0.406]), Tensor([0.229, 0.224, 0.225])\n",
    "default_norm,default_denorm = normalize_funcs(default_mean,default_std)\n",
    "\n",
    "bs = 64\n",
    "data = DataBunch.create(train_tds, valid_tds, bs=bs, dl_tfms=default_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(data.train_dl))\n",
    "x = x.cpu()\n",
    "y = y.cpu()\n",
    "x = default_denorm(x)\n",
    "#y = default_denorm(y)\n",
    "show_xy_images(x,y,6, figsize=(9,10))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torchvision.models import resnet34\n",
    "\n",
    "model_meta = {\n",
    "    resnet34:[8,6]\n",
    "}\n",
    "\n",
    "f = resnet34\n",
    "cut,lr_cut = model_meta[f]\n",
    "\n",
    "def cut_model(m, cut):\n",
    "    return list(m.children())[:cut] if cut else m\n",
    "\n",
    "def get_base():\n",
    "    layers = cut_model(f(True), cut)\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def dice(pred, targs):\n",
    "    pred = (pred>0).float()\n",
    "    return 2. * (pred*targs).sum() / (pred+targs).sum()\n",
    "\n",
    "def accuracy(out, yb):\n",
    "    preds = torch.max(out, dim=1)[1]\n",
    "    return (preds==yb).float().mean()\n",
    "\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "def to_gpu(x, *args, **kwargs):\n",
    "    '''puts pytorch variable to gpu, if cuda is available and USE_GPU is set to true. '''\n",
    "    return x.cuda(*args, **kwargs) if USE_GPU else x\n",
    "\n",
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()\n",
    "        \n",
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        return self.bn(F.relu(cat_p))\n",
    "    \n",
    "class Unet34(nn.Module):\n",
    "    def __init__(self, rn):\n",
    "        super().__init__()\n",
    "        self.rn = rn\n",
    "        self.sfs = [SaveFeatures(rn[i]) for i in [2,4,5,6]]\n",
    "        self.up1 = UnetBlock(512,256,256)\n",
    "        self.up2 = UnetBlock(256,128,256)\n",
    "        self.up3 = UnetBlock(256,64,256)\n",
    "        self.up4 = UnetBlock(256,64,256)\n",
    "        self.up5 = UnetBlock(256,3,16)\n",
    "        self.up6 = nn.ConvTranspose2d(16, 1, 1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        inp = x\n",
    "        x = F.relu(self.rn(x))\n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x, inp)\n",
    "        x = self.up6(x)\n",
    "        return x #[:,0]\n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()\n",
    "\n",
    "            \n",
    "class UnetModel():\n",
    "    def __init__(self,model,name='unet'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))\n",
    "        return lgs + [children(self.model)[1:]]\n",
    "    \n",
    "class UnetModel():\n",
    "    def __init__(self,model,name='unet'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))\n",
    "        return lgs + [children(self.model)[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_base = get_base()\n",
    "model = to_gpu(Unet34(m_base))\n",
    "learn = Learner(data, model)\n",
    "learn.metrics = [dice]\n",
    "learn.loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find(learn)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = OneCycleScheduler(learn, 0.5, 10)\n",
    "learn.fit(10, 0.1, callbacks=[sched])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(data.valid_dl))\n",
    "py = learn.model(x)\n",
    "py = py.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(y[0]), show_image(py[0]>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unet_128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=512\n",
    "bs = 8\n",
    "\n",
    "train_tds, valid_tds = transform_datasets(train_ds, valid_ds, tfms, tfm_y=True, y_class=ImageMask, size=size)\n",
    "data = DataBunch.create(train_tds, valid_tds, bs=bs, dl_tfms=default_norm)\n",
    "learn = Learner(data, model)\n",
    "learn.metrics = [dice]\n",
    "learn.loss_fn = nn.BCEWithLogitsLoss()\n",
    "learn.load('unet_128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find(learn)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = OneCycleScheduler(learn, 0.1, 10)\n",
    "learn.fit(10, 0.03, callbacks=[sched])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unet_512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_tfms??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from nb_005 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carvana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(See final section of notebook for one-time data processing steps.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/carvana')\n",
    "PATH_PNG = PATH/'train_masks_png'\n",
    "PATH_X_FULL = PATH/'train'\n",
    "PATH_X_128 = PATH/'train-128'\n",
    "PATH_Y_FULL = PATH_PNG\n",
    "PATH_Y_128 = PATH/'train_masks-128'\n",
    "\n",
    "# start with the 128x128 images\n",
    "PATH_X = PATH_X_128\n",
    "PATH_Y = PATH_Y_128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_f = next(PATH_X.iterdir())\n",
    "x = open_image(img_f)\n",
    "x.show()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageMask(Image):\n",
    "    def lighting(self, func, *args, **kwargs): return self\n",
    "    \n",
    "    def refresh(self):\n",
    "        self.sample_kwargs['mode'] = 'nearest'\n",
    "        return super().refresh()\n",
    "\n",
    "def open_mask(fn):\n",
    "    return ImageMask(pil2tensor(PIL.Image.open(fn)).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_fn(x_fn): return PATH_Y/f'{x_fn.name[:-4]}_mask.png'\n",
    "\n",
    "img_y_f = get_y_fn(img_f)\n",
    "y = open_mask(img_y_f)\n",
    "y.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as `show_image`, but renamed with _ prefix\n",
    "def _show_image(img, ax=None, figsize=(3,3), hide_axis=True, cmap='binary', alpha=None):\n",
    "    if ax is None: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(image2np(img), cmap=cmap, alpha=alpha)\n",
    "    if hide_axis: ax.axis('off')\n",
    "    return ax\n",
    "\n",
    "def show_image(x, y=None, ax=None, figsize=(3,3), alpha=0.4, hide_axis=True, cmap='viridis'):\n",
    "    ax1 = _show_image(x, ax=ax, hide_axis=hide_axis, cmap=cmap)\n",
    "    if y is not None: _show_image(y, ax=ax1, alpha=alpha, hide_axis=hide_axis, cmap=cmap)\n",
    "    if hide_axis: ax1.axis('off')\n",
    "        \n",
    "def _show(self, ax=None, y=None, **kwargs):\n",
    "    if y is not None: y=y.data\n",
    "    return show_image(self.data, ax=ax, y=y, **kwargs)\n",
    "\n",
    "Image.show = _show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.show(y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xy transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data types: regr, class, seg, bbox, polygon, generative (s/res, color), custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetTfm(Dataset):\n",
    "    def __init__(self, ds:Dataset,tfms:Collection[Callable]=None,tfm_y:bool=False, **kwargs):\n",
    "        self.ds,self.tfms,self.tfm_y,self.x_kwargs = ds,tfms,tfm_y,kwargs\n",
    "        self.y_kwargs = {**self.x_kwargs, 'do_resolve':False} # don't reset random vars\n",
    "        \n",
    "    def __len__(self): return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        x,y = self.ds[idx]\n",
    "        \n",
    "        x = apply_tfms(self.tfms, x, **self.x_kwargs)\n",
    "        if self.tfm_y: y = apply_tfms(self.tfms, y, **self.y_kwargs)\n",
    "        return x, y\n",
    "    \n",
    "    @property\n",
    "    def c(self): return self.ds.c\n",
    "    \n",
    "import nb_002b,nb_005\n",
    "nb_002b.DatasetTfm = DatasetTfm  \n",
    "nb_005.DatasetTfm  = DatasetTfm  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class MatchedFilesDataset(Dataset):\n",
    "    x_fns:List[Path]; y_fns:List[Path]\n",
    "    def __post_init__(self): assert len(self.x_fns)==len(self.y_fns)\n",
    "    def __repr__(self): return f'{type(self).__name__} of len {len(self.x_fns)}'\n",
    "    def __len__(self): return len(self.x_fns)\n",
    "    def __getitem__(self, i): \n",
    "        return open_image(self.x_fns[i]), open_mask(self.y_fns[i])\n",
    "    \n",
    "# def split_fns_by_idxs(seq, idxs):\n",
    "#     '''A generator that returns sequence pieces, seperated by indexes specified in idxs. '''\n",
    "#     last = 0\n",
    "#     for idx in idxs:\n",
    "#         if not (-len(seq) <= idx < len(seq)):\n",
    "#             raise KeyError(f'Idx {idx} is out-of-bounds')\n",
    "#         yield seq[last:idx]\n",
    "#         last = idx\n",
    "#     yield seq[last:]\n",
    "\n",
    "def split_arrs_by_idx(idxs, *a):\n",
    "    \"\"\"\n",
    "    Split each array passed as *a, to a pair of arrays like this (elements selected by idxs,  the remaining elements)\n",
    "    This can be used to split multiple arrays containing training data to validation and training set.\n",
    "    :param idxs [int]: list of indexes selected\n",
    "    :param a list: list of np.array, each array should have same amount of elements in the first dimension\n",
    "    :return: list of tuples, each containing a split of corresponding array from *a.\n",
    "            First element of each tuple is an array composed from elements selected by idxs,\n",
    "            second element is an array of remaining elements.\n",
    "    \"\"\"\n",
    "    mask = np.zeros(len(a[0]),dtype=bool)\n",
    "    mask[np.array(idxs)] = True\n",
    "    return [(o[mask],o[~mask]) for o in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fns = [o for o in PATH_X.iterdir() if o.is_file()]\n",
    "y_fns = [get_y_fn(o) for o in x_fns]\n",
    "val_idxs = list(range(1008))\n",
    "((val_x,trn_x),(val_y,trn_y)) = split_arrs_by_idx(val_idxs, np.array(x_fns), np.array(y_fns))\n",
    "train_ds = MatchedFilesDataset(trn_x, trn_y)\n",
    "valid_ds = MatchedFilesDataset(val_x, val_y)\n",
    "train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(train_ds))\n",
    "x.shape, y.shape, type(x), type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=128\n",
    "tfms = get_transforms(do_flip=True, max_rotate=20, max_zoom=2., max_lighting=0.7, max_warp=0.3,p_affine=0.75)\n",
    "train_tds, valid_tds, augm_tds = transform_datasets(train_ds, valid_ds, tfms, tfm_y=True, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(1,4, figsize=(12,6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    imgx,imgy = train_tds[i]\n",
    "    imgx.show(ax, y=imgy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def normalize_batch(b, mean, std, do_y=False):\n",
    "    x,y = b\n",
    "    x = normalize(x,mean,std)\n",
    "    if do_y: y = normalize(y,mean,std)\n",
    "    return x,y\n",
    "\n",
    "def normalize_funcs(mean, std, do_y=False, device=None):\n",
    "    if device is None: device=default_device\n",
    "    return (partial(normalize_batch, mean=mean.to(device),std=std.to(device), do_y=do_y),\n",
    "            partial(denormalize,     mean=mean,           std=std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagenet mean/std\n",
    "default_mean, default_std = tensor([0.485, 0.456, 0.406]), tensor([0.229, 0.224, 0.225])\n",
    "default_norm,default_denorm = normalize_funcs(default_mean,default_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "data = DataBunch.create(train_tds, valid_tds, bs=bs, dl_tfms=default_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_xy_images(x,y,rows,figsize=(9,9)):\n",
    "    fig, axs = plt.subplots(rows,rows,figsize=figsize)\n",
    "    for i, ax in enumerate(axs.flatten()): show_image(x[i], y=y[i], ax=ax)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(data.train_dl))\n",
    "x,y = x.cpu(),y.cpu()\n",
    "x = default_denorm(x)\n",
    "show_xy_images(x,y,6, figsize=(9,9))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torchvision.models import resnet34\n",
    "\n",
    "model_meta = {\n",
    "    resnet34:[8,6]\n",
    "}\n",
    "\n",
    "f = resnet34\n",
    "cut,lr_cut = model_meta[f]\n",
    "\n",
    "def cut_model(m, cut):\n",
    "    return list(m.children())[:cut] if cut else m\n",
    "\n",
    "def get_base():\n",
    "    layers = cut_model(f(True), cut)\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def dice(pred, targs):\n",
    "    pred = (pred>0).float()\n",
    "    return 2. * (pred*targs).sum() / (pred+targs).sum()\n",
    "\n",
    "def accuracy(out, yb):\n",
    "    preds = torch.max(out, dim=1)[1]\n",
    "    return (preds==yb).float().mean()\n",
    "\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "def to_gpu(x, *args, **kwargs):\n",
    "    '''puts pytorch variable to gpu, if cuda is available and USE_GPU is set to true. '''\n",
    "    return x.cuda(*args, **kwargs) if USE_GPU else x\n",
    "\n",
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()\n",
    "        \n",
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        return self.bn(F.relu(cat_p))\n",
    "    \n",
    "class Unet34(nn.Module):\n",
    "    def __init__(self, rn):\n",
    "        super().__init__()\n",
    "        self.rn = rn\n",
    "        self.sfs = [SaveFeatures(rn[i]) for i in [2,4,5,6]]\n",
    "        self.up1 = UnetBlock(512,256,256)\n",
    "        self.up2 = UnetBlock(256,128,256)\n",
    "        self.up3 = UnetBlock(256,64,256)\n",
    "        self.up4 = UnetBlock(256,64,256)\n",
    "        self.up5 = UnetBlock(256,3,16)\n",
    "        self.up6 = nn.ConvTranspose2d(16, 1, 1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        inp = x\n",
    "        x = F.relu(self.rn(x))\n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x, inp)\n",
    "        x = self.up6(x)\n",
    "        return x #[:,0]\n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()\n",
    "\n",
    "            \n",
    "class UnetModel():\n",
    "    def __init__(self,model,name='unet'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))\n",
    "        return lgs + [children(self.model)[1:]]\n",
    "    \n",
    "class UnetModel():\n",
    "    def __init__(self,model,name='unet'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))\n",
    "        return lgs + [children(self.model)[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_base = get_base()\n",
    "model = to_gpu(Unet34(m_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, model)\n",
    "learn.metrics = [dice]\n",
    "learn.loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find(learn)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_one_cycle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(data.valid_dl))\n",
    "py = learn.model(x)\n",
    "py = py.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(y[0]), show_image(py[0]>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unet_128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_X = PATH_X_FULL\n",
    "PATH_Y = PATH_Y_FULL\n",
    "\n",
    "size=512\n",
    "bs = 8\n",
    "\n",
    "x_fns = [o for o in PATH_X.iterdir() if o.is_file()]\n",
    "y_fns = [get_y_fn(o) for o in x_fns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idxs = list(range(1008))\n",
    "((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, np.array(x_fns), np.array(y_fns))\n",
    "train_ds = MatchedFilesDataset(trn_x, trn_y)\n",
    "valid_ds = MatchedFilesDataset(val_x, val_y)\n",
    "\n",
    "train_tds, valid_tds = transform_datasets(train_ds, valid_ds, tfms, tfm_y=True, y_class=ImageMask, size=size)\n",
    "data = DataBunch.create(train_tds, valid_tds, bs=bs, dl_tfms=default_norm)\n",
    "learn = Learner(data, model)\n",
    "learn.metrics = [dice]\n",
    "learn.loss_fn = nn.BCEWithLogitsLoss()\n",
    "learn.load('unet_128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find(learn)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = OneCycleScheduler(learn, 0.1, 10)\n",
    "learn.fit(10, 0.03, callbacks=[sched])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unet_512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_X = PATH_X_FULL\n",
    "PATH_Y = PATH_Y_FULL\n",
    "\n",
    "size=1024\n",
    "bs = 2\n",
    "\n",
    "x_fns = [o for o in PATH_X.iterdir() if o.is_file()]\n",
    "y_fns = [get_y_fn(o) for o in x_fns]\n",
    "\n",
    "val_idxs = list(range(1008))\n",
    "((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, np.array(x_fns), np.array(y_fns))\n",
    "train_ds = MatchedFilesDataset(trn_x, trn_y)\n",
    "valid_ds = MatchedFilesDataset(val_x, val_y)\n",
    "\n",
    "train_tds, valid_tds = transform_datasets(train_ds, valid_ds, tfms, tfm_y=True, y_class=ImageMask, size=size)\n",
    "data = DataBunch.create(train_tds, valid_tds, bs=bs, dl_tfms=default_norm)\n",
    "learn = Learner(data, model)\n",
    "learn.metrics = [dice]\n",
    "learn.loss_fn = nn.BCEWithLogitsLoss()\n",
    "learn.load('unet_512')\n",
    "\n",
    "sched = OneCycleScheduler(learn, 0.03, 10)\n",
    "learn.fit(10, 0.01, callbacks=[sched])\n",
    "learn.save('unet_1024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_X = PATH_X_FULL\n",
    "PATH_Y = PATH_Y_FULL\n",
    "\n",
    "size=1536\n",
    "bs = 1\n",
    "\n",
    "x_fns = [o for o in PATH_X.iterdir() if o.is_file()]\n",
    "y_fns = [get_y_fn(o) for o in x_fns]\n",
    "\n",
    "val_idxs = list(range(1008))\n",
    "((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, np.array(x_fns), np.array(y_fns))\n",
    "train_ds = MatchedFilesDataset(trn_x, trn_y)\n",
    "valid_ds = MatchedFilesDataset(val_x, val_y)\n",
    "\n",
    "tfms = get_transforms(do_flip=True, max_rotate=20, max_zoom=2., max_lighting=0.7, max_warp=0.3,p_affine=0.75)\n",
    "train_tds, valid_tds = transform_datasets(train_ds, valid_ds, tfms, tfm_y=True, y_class=ImageMask, size=size)\n",
    "data = DataBunch.create(train_tds, valid_tds, bs=bs, dl_tfms=default_norm)\n",
    "m_base = get_base()\n",
    "model = to_gpu(Unet34(m_base))\n",
    "learn = Learner(data, model)\n",
    "learn.metrics = [dice]\n",
    "learn.loss_fn = nn.BCEWithLogitsLoss()\n",
    "learn.load('unet_1024')\n",
    "\n",
    "sched = OneCycleScheduler(learn, 0.015, 30)\n",
    "learn.fit(30, 0.005, callbacks=[sched])\n",
    "learn.save('unet_1536')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

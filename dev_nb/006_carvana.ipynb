{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from nb_004c import *\n",
    "\n",
    "from functools import wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carvana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(See final section of notebook for one-time data processing steps.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/carvana')\n",
    "PATH_PNG = PATH/'train_masks_png'\n",
    "PATH_X = PATH/'train-128'\n",
    "PATH_Y = PATH/'train_masks-128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_f = next(PATH_X.iterdir())\n",
    "x = open_image(img_f)\n",
    "show_image(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_fn(x_fn): return PATH_Y/f'{x_fn.name[:-4]}_mask.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def pil2tensor(image, as_mask=False):\n",
    "    arr = torch.ByteTensor(torch.ByteStorage.from_buffer(image.tobytes()))\n",
    "    arr = arr.view(image.size[1], image.size[0], -1)\n",
    "    arr = arr.permute(2,0,1).float()\n",
    "    return arr if as_mask else arr.div_(255)\n",
    "\n",
    "def open_image(fn, as_mask=False):\n",
    "    x = PIL.Image.open(fn)\n",
    "    if not as_mask: x = x.convert('RGB')\n",
    "    return pil2tensor(x, as_mask=as_mask)\n",
    "\n",
    "def image2np(image):\n",
    "    res = image.cpu().permute(1,2,0).numpy()\n",
    "    return res[...,0] if res.shape[2]==1 else res\n",
    "\n",
    "def show_image(img, ax=None, figsize=(3,3), hide_axis=True, cmap='binary', alpha=None):\n",
    "    if ax is None: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(image2np(img), cmap=cmap, alpha=alpha)\n",
    "    if hide_axis: ax.axis('off')\n",
    "    return ax\n",
    "        \n",
    "def show_xy_image(xim, yim, ax=None, figsize=(3,3), alpha=0.5, hide_axis=True, cmap='RdGy_r'):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax1 = show_image(xim, ax=ax, hide_axis=hide_axis, cmap=cmap)\n",
    "    show_image(yim, ax=ax1, alpha=alpha, hide_axis=hide_axis, cmap=cmap)\n",
    "    if hide_axis: ax.axis('off')\n",
    "        \n",
    "def show_xy_images(x,y,rows,figsize=(9,9)):\n",
    "    fig, axs = plt.subplots(rows,rows,figsize=figsize)\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        show_xy_image(x[i], y[i], ax)\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_y_f = get_y_fn(img_f)\n",
    "y = open_image(img_y_f, as_mask=True)\n",
    "show_image(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_xy_image(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [\n",
    "    rotate(degrees=(-20,20.), p=0.75),\n",
    "    zoom(scale=(0.5,2), p=0.75),\n",
    "    contrast(scale=(0.6,1.4)),\n",
    "    brightness(change=(0.3,0.7)),\n",
    "    *zoom_crop(scale=(1.,2.), p=0.5, do_rand=True)\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(1,4, figsize=(12,3))\n",
    "for ax in axes: show_image(apply_tfms(tfms,x,size=128), ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xy transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data types: regr, class, seg, bbox, polygon, generative (s/res, color), custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def skip_ys(*args):\n",
    "    for tfm in args:\n",
    "        tfm._y_tfm = None\n",
    "    return args\n",
    "\n",
    "def kw_override(tfm, override):\n",
    "    new_tfm = copy(tfm)\n",
    "    new_tfm.kwargs = override\n",
    "    tfm._y_tfm = new_tfm\n",
    "    return tfm\n",
    "\n",
    "def force_nearest(tfm):\n",
    "    if not isinstance(tfm.tfm,TfmAffine): return tfm\n",
    "    else: return kw_override(tfm, {'mode': 'nearest'})\n",
    "        \n",
    "def affine_y_mode_nearest(*args):\n",
    "    return [force_nearest(tfm) for tfm in args]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_tfms = [\n",
    "    flip_lr(p=0.5),\n",
    "    rotate(degrees=(-20,20.), p=0.75),\n",
    "    zoom(scale=(0.5,2), p=0.75),\n",
    "    *skip_ys(\n",
    "        contrast(scale=(0.6,1.4)),\n",
    "        brightness(change=(0.3,0.7))\n",
    "    ),\n",
    "    *zoom_crop(scale=(1.,2.), p=0.5, do_rand=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def choose_tfm(tfm, do_y):\n",
    "    if do_y and hasattr(tfm, '_y_tfm'): \n",
    "        return tfm._y_tfm\n",
    "    else: return tfm\n",
    "        \n",
    "        \n",
    "def resolve_tfms_xy(tfms):\n",
    "    tfms = listify(tfms)\n",
    "    resolve_tfms(tfms)\n",
    "    for tfm in tfms:\n",
    "        if hasattr(tfm, '_y_tfm') and tfm._y_tfm:\n",
    "            tfm._y_tfm.resolve()\n",
    "            tfm._y_tfm.resolved = {**tfm.resolved, **tfm._y_tfm.resolved}\n",
    "        \n",
    "def apply_tfms(tfms, x, do_resolve=True, xtra=None, size=None,\n",
    "               mult=32, do_crop=True, padding_mode='reflect', do_y=False, **kwargs):\n",
    "    if not tfms: return x\n",
    "    if not xtra: xtra={}\n",
    "    tfms = sorted(listify(tfms), key=lambda o: o.tfm.order)\n",
    "    tfms = [choose_tfm(tfm, do_y) for tfm in tfms]\n",
    "    tfms = [tfm for tfm in tfms if not tfm is None]\n",
    "    \n",
    "    if do_resolve: \n",
    "        resolve_tfms_xy(tfms)\n",
    "    x = Image(x.clone())\n",
    "    mode = 'nearest' if do_y else 'bilinear'\n",
    "    x.set_sample(padding_mode=padding_mode, mode=mode, **kwargs)\n",
    "    if size:\n",
    "        crop_target = get_crop_target(size, mult=mult)\n",
    "        target = get_resize_target(x, crop_target, do_crop=do_crop)\n",
    "        x.resize(target)\n",
    "\n",
    "    size_tfms = [o for o in tfms if isinstance(o.tfm,TfmCrop)]\n",
    "    for tfm in tfms:\n",
    "        if tfm.tfm in xtra: x = tfm(x, **xtra[tfm.tfm])\n",
    "        elif tfm in size_tfms: x = tfm(x, size=size, padding_mode=padding_mode)\n",
    "        else: x = tfm(x)\n",
    "    return x.px\n",
    "\n",
    "\n",
    "def build_xy_tfm(tfms):\n",
    "    def xy_tfm(x_y, **kwargs):\n",
    "        kwargs = copy(kwargs)\n",
    "        if 'do_resolve_y' in kwargs:\n",
    "            do_resolve_y = kwargs.get('do_resolve_y')\n",
    "            del kwargs['do_resolve_y']\n",
    "        else:\n",
    "            do_resolve_y = False\n",
    "        x, y = x_y\n",
    "        xt = apply_tfms(tfms, x, **kwargs)\n",
    "        yt = apply_tfms(tfms, y, do_y=True,\n",
    "                        **{**kwargs, **{'do_resolve': do_resolve_y}})\n",
    "        return xt, yt\n",
    "    return xy_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=128\n",
    "_,axes = plt.subplots(1,4, figsize=(12,6))\n",
    "for i in range(4):\n",
    "    tfm = build_xy_tfm(xy_tfms)\n",
    "    imgx,imgy = tfm((x,y),size=size)\n",
    "    show_xy_image(imgx, imgy, axes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class MatchedFilesDataset(Dataset):\n",
    "    x_fns:List[Path]; y_fns:List[Path]\n",
    "    def __post_init__(self): assert len(self.x_fns)==len(self.y_fns)\n",
    "    def __repr__(self): return f'{type(self).__name__} of len {len(self.x_fns)}'\n",
    "    def __len__(self): return len(self.x_fns)\n",
    "    def __getitem__(self, i): return open_image(self.x_fns[i]), open_image(self.y_fns[i],as_mask=True)\n",
    "    \n",
    "def split_by_idxs(seq, idxs):\n",
    "    '''A generator that returns sequence pieces, seperated by indexes specified in idxs. '''\n",
    "    last = 0\n",
    "    for idx in idxs:\n",
    "        if not (-len(seq) <= idx < len(seq)):\n",
    "            raise KeyError(f'Idx {idx} is out-of-bounds')\n",
    "        yield seq[last:idx]\n",
    "        last = idx\n",
    "    yield seq[last:]\n",
    "\n",
    "def split_by_idx(idxs, *a):\n",
    "    \"\"\"\n",
    "    Split each array passed as *a, to a pair of arrays like this (elements selected by idxs,  the remaining elements)\n",
    "    This can be used to split multiple arrays containing training data to validation and training set.\n",
    "    :param idxs [int]: list of indexes selected\n",
    "    :param a list: list of np.array, each array should have same amount of elements in the first dimension\n",
    "    :return: list of tuples, each containing a split of corresponding array from *a.\n",
    "            First element of each tuple is an array composed from elements selected by idxs,\n",
    "            second element is an array of remaining elements.\n",
    "    \"\"\"\n",
    "    mask = np.zeros(len(a[0]),dtype=bool)\n",
    "    mask[np.array(idxs)] = True\n",
    "    return [(o[mask],o[~mask]) for o in a]\n",
    "\n",
    "class DatasetTfmXY(Dataset):\n",
    "    def __init__(self, ds:Dataset, tfms:Collection[Callable]=None, **kwargs):\n",
    "        self.ds,self.kwargs = ds, kwargs\n",
    "        if tfms is not None: self.tfm = build_xy_tfm(tfms)\n",
    "        else: self.tfm = None \n",
    "        \n",
    "    def __len__(self): return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        x,y = self.ds[idx]\n",
    "        if self.tfm: return self.tfm((x,y), **self.kwargs)\n",
    "        else: return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fns = [o for o in PATH_X.iterdir() if o.is_file()]\n",
    "y_fns = [get_y_fn(o) for o in x_fns]\n",
    "val_idxs = list(range(1008))\n",
    "((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, np.array(x_fns), np.array(y_fns))\n",
    "train_ds = MatchedFilesDataset(trn_x, trn_y)\n",
    "val_ds = MatchedFilesDataset(val_x, val_y)\n",
    "train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(train_ds))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(1,4, figsize=(12,6))\n",
    "for i in range(4):\n",
    "    tfm = build_xy_tfm(xy_tfms)\n",
    "    imgx,imgy = tfm(train_ds[i],size=size)\n",
    "    show_xy_image(imgx, imgy, axes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=128\n",
    "xy_train_tfms = [\n",
    "    flip_lr(p=0.5),\n",
    "    rotate(degrees=(-20,20.), p=0.75),\n",
    "    zoom(scale=(0.5,2), p=0.75),\n",
    "    *skip_ys(\n",
    "        contrast(scale=(0.6,1.4)),\n",
    "        brightness(change=(0.3,0.7))\n",
    "    ),\n",
    "    *zoom_crop(scale=(1.,2.), p=0.5, do_rand=True)\n",
    "]\n",
    "\n",
    "xy_valid_tfms = [\n",
    "    crop_pad()\n",
    "]\n",
    "\n",
    "train_tds = DatasetTfmXY(train_ds, xy_train_tfms,size=size)\n",
    "valid_tds = DatasetTfmXY(val_ds, xy_valid_tfms,size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(1,4, figsize=(12,9))\n",
    "for ax in axes.flat: show_xy_image(*train_tds[1], ax)\n",
    "train_tds[1][0].shape, train_tds[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def normalize(x, mean,std):   return (x-mean[...,None,None]) / std[...,None,None]\n",
    "def denormalize(x, mean,std): return x*std[...,None,None] + mean[...,None,None]\n",
    "\n",
    "def normalize_batch(b, mean, std, do_y=False):\n",
    "    x,y = b\n",
    "    x = normalize(x,mean,std)\n",
    "    if do_y: y = normalize(y,mean,std)\n",
    "    return x,y\n",
    "\n",
    "def normalize_funcs(mean, std, do_y=False, device=None):\n",
    "    if device is None: device=default_device\n",
    "    return (partial(normalize_batch, mean=mean.to(device),std=std.to(device), do_y=do_y),\n",
    "            partial(denormalize,     mean=mean,           std=std))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagenet\n",
    "default_mean, default_std = Tensor([0.485, 0.456, 0.406]), Tensor([0.229, 0.224, 0.225])\n",
    "default_norm,default_denorm = normalize_funcs(default_mean,default_std)\n",
    "\n",
    "bs = 64\n",
    "data = DataBunch.create(train_tds, valid_tds, bs=bs, dl_tfms=default_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(data.train_dl))\n",
    "x = x.cpu()\n",
    "y = y.cpu()\n",
    "print(x.min(),x.max(),x.mean(),x.std())\n",
    "x = default_denorm(x)\n",
    "#y = default_denorm(y)\n",
    "show_xy_images(x,y,6, figsize=(9,10))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet34\n",
    "\n",
    "model_meta = {\n",
    "    resnet34:[8,6]\n",
    "}\n",
    "\n",
    "f = resnet34\n",
    "cut,lr_cut = model_meta[f]\n",
    "\n",
    "def cut_model(m, cut):\n",
    "    return list(m.children())[:cut] if cut else m\n",
    "\n",
    "def get_base():\n",
    "    layers = cut_model(f(True), cut)\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def dice(pred, targs):\n",
    "    pred = (pred>0).float()\n",
    "    return 2. * (pred*targs).sum() / (pred+targs).sum()\n",
    "\n",
    "def accuracy(out, yb):\n",
    "    preds = torch.max(out, dim=1)[1]\n",
    "    return (preds==yb).float().mean()\n",
    "\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "def to_gpu(x, *args, **kwargs):\n",
    "    '''puts pytorch variable to gpu, if cuda is available and USE_GPU is set to true. '''\n",
    "    return x.cuda(*args, **kwargs) if USE_GPU else x\n",
    "\n",
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()\n",
    "        \n",
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        return self.bn(F.relu(cat_p))\n",
    "    \n",
    "class Unet34(nn.Module):\n",
    "    def __init__(self, rn):\n",
    "        super().__init__()\n",
    "        self.rn = rn\n",
    "        self.sfs = [SaveFeatures(rn[i]) for i in [2,4,5,6]]\n",
    "        self.up1 = UnetBlock(512,256,256)\n",
    "        self.up2 = UnetBlock(256,128,256)\n",
    "        self.up3 = UnetBlock(256,64,256)\n",
    "        self.up4 = UnetBlock(256,64,256)\n",
    "        self.up5 = UnetBlock(256,3,16)\n",
    "        self.up6 = nn.ConvTranspose2d(16, 1, 1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        inp = x\n",
    "        x = F.relu(self.rn(x))\n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x, inp)\n",
    "        x = self.up6(x)\n",
    "        return x #[:,0]\n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()\n",
    "\n",
    "            \n",
    "class UnetModel():\n",
    "    def __init__(self,model,name='unet'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))\n",
    "        return lgs + [children(self.model)[1:]]\n",
    "    \n",
    "class UnetModel():\n",
    "    def __init__(self,model,name='unet'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))\n",
    "        return lgs + [children(self.model)[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_base = get_base()\n",
    "model = to_gpu(Unet34(m_base))\n",
    "learn = Learner(data, model)\n",
    "learn.metrics = [dice]\n",
    "learn.loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find(learn, start_lr=0.01, end_lr=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = OneCycleScheduler(learn, 0.3, 10)\n",
    "learn.fit(10, 0.1, callbacks=[sched])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(data.valid_dl))\n",
    "py = learn.model(x)\n",
    "py = py.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(y[0]), show_image(py[0]>0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of the rotation augmentation on dogs-cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the old fastai library for its training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_001b import *\n",
    "from PIL import Image\n",
    "import PIL, matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os, random\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"data/dogscats/\")\n",
    "os.makedirs(PATH,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64\n",
    "sz=224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchvision data aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the relevant functions to get dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_device = torch.device('cuda', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_classes(folder):\n",
    "    classes = [d for d in folder.iterdir()\n",
    "               if d.is_dir() and not d.name.startswith('.')]\n",
    "    classes.sort(key=lambda d: d.name)\n",
    "    return classes\n",
    "\n",
    "def get_image_files(c):\n",
    "    return [o for o in list(c.iterdir())\n",
    "            if not o.name.startswith('.') and not o.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "class TransformedFilesDataset(Dataset):#Renamed to avoid conflict with fastai FilesDataset\n",
    "    def __init__(self, folder, tfms):\n",
    "        self.tfms = torchvision.transforms.Compose(tfms)\n",
    "        cls_dirs = find_classes(folder)\n",
    "        self.fns, self.y = [], []\n",
    "        self.classes = [cls.name for cls in cls_dirs]\n",
    "        for i, cls_dir in enumerate(cls_dirs):\n",
    "            fnames = get_image_files(cls_dir)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        \n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = Image.open(self.fns[i])\n",
    "        x = self.tfms(x)\n",
    "        return np.array(x, dtype=np.float32).transpose(2,0,1)/255,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device, stats):\n",
    "        self.dl,self.device = dl,device\n",
    "        self.m, self.s = map(lambda x:torch.tensor(x, dtype=torch.float32, device=device), stats)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            x, y = b[0].to(self.device),b[1].to(self.device)\n",
    "            x = (x - self.m[None,:,None,None]) / self.s[None,:,None,None]\n",
    "            yield x,y\n",
    "    \n",
    "    def __len__(self): return (len(self.dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the DataLoader from pytorch since fastai replaced the definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader as DataLoader1\n",
    "def get_dataloader(ds, bs, shuffle, device, stats):\n",
    "    return DeviceDataLoader(DataLoader1(ds, batch_size=bs, shuffle=shuffle,num_workers=0), device, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBunch():\n",
    "    def __init__(self, trn_ds, val_ds, stats, bs=64, device=None):\n",
    "        self.device = default_device if device is None else device\n",
    "        if hasattr(trn_ds, 'classes'): self.classes = trn_ds.classes\n",
    "        self.trn_dl = get_dataloader(trn_ds, bs,   shuffle=True,  device=self.device, stats=stats)\n",
    "        self.val_dl = get_dataloader(val_ds, bs*2, shuffle=False, device=self.device, stats=stats)\n",
    "\n",
    "    @classmethod\n",
    "    def from_files(cls, Path, size, trn_tfms, val_tfms, stats, trn_name='train', val_name='valid', bs=64, device=None):\n",
    "        trn_ds, val_ds = TransformedFilesDataset(Path/trn_name, trn_tfms), TransformedFilesDataset(Path/val_name, val_tfms)\n",
    "        return cls(trn_ds, val_ds, stats, bs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = [np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225])]\n",
    "trn_tfms = [torchvision.transforms.Pad(8, padding_mode='symmetric'),\n",
    "            torchvision.transforms.RandomRotation(10, resample=PIL.Image.BILINEAR),\n",
    "            torchvision.transforms.RandomResizedCrop(size)]\n",
    "val_tfms = [torchvision.transforms.Resize(size), \n",
    "            torchvision.transforms.CenterCrop(size)]\n",
    "data = DataBunch.from_files(PATH, (size,size), trn_tfms, val_tfms, stats, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(data.trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[0].cpu().numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time for (x,y) in iter(data.trn_dl): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_transform(img, matrix, interpol=True, padding='reflect'):\n",
    "    \"\"\"\n",
    "    Applies an affine transformation to an image.\n",
    "    \n",
    "    Optional: only computes the new coordinates without doing the interpolation to create the new images.\n",
    "    Args:\n",
    "    x: a batch of images\n",
    "    matrix: a matrix of size 2 by 3 describing the transformation.\n",
    "            if the transformation is Ax + b, the matrix is (A|b)\n",
    "    interpol: if False, returns only the new coordinates\n",
    "    padding: padding to apply during the interpolation. Supports zeros, border, reflect\n",
    "    \n",
    "    \"\"\"\n",
    "    coords = F.affine_grid(matrix[None], img[None].size())\n",
    "    return interpolate(img[None],coords,padding) if interpol else coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(x, coords, padding='reflect'):\n",
    "    if padding=='reflect':#Reflect padding isn't implemented in grid_sample yet\n",
    "        coords[coords < -1] = coords[coords < -1].mul_(-1).add_(-2)\n",
    "        coords[coords > 1] = coords[coords > 1].mul_(-1).add_(2)\n",
    "        padding='zeros'\n",
    "    return F.grid_sample(x, coords, padding_mode=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(data.trn_dl.dl.dataset.fns[0])\n",
    "img = torch.tensor((np.array(img, dtype=np.float32)/255).transpose(2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img.numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 10 * math.pi / 180\n",
    "matrix = torch.tensor([[math.cos(theta), -math.sin(theta), 0],\n",
    "                       [math.sin(theta), math.cos(theta), 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = affine_transform(img, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res[0].numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = torch.tensor([[0.8, 0, 0],\n",
    "                       [0, 0.8, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = affine_transform(img, matrix)\n",
    "plt.imshow(res[0].numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(coords, start, size):\n",
    "    t,l = start\n",
    "    d,r = t + size[0], l + size[1] \n",
    "    return coords[:,t:d,l:r,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = affine_transform(img,matrix,False)\n",
    "coords = crop(coords,(50,10),(200,120))\n",
    "res = interpolate(img[None], coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res[0].numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, h, w = img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = min(h,w) / 224\n",
    "img_size = torch.Size([1,3,int(h/ratio),int(w/ratio)])\n",
    "matrix = torch.eye(3)[:2,:]\n",
    "coords = F.affine_grid(matrix[None], img_size)\n",
    "res = interpolate(img[None], coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res[0].numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_rot_matrix(degrees):\n",
    "    theta = random.uniform(-degrees,degrees) * math.pi / 180\n",
    "    return torch.tensor([[math.cos(theta), -math.sin(theta), 0],\n",
    "                         [math.sin(theta), math.cos(theta),  0],\n",
    "                         [0,               0,                1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_scale_matrix(zoom_range):\n",
    "    scale = random.uniform(*zoom_range)\n",
    "    return torch.tensor([[scale, 0, 0],\n",
    "                         [0, scale, 0],\n",
    "                         [0,  0,    1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTfm():\n",
    "    \n",
    "    def __init__(self, degrees, min_zoom, max_zoom, size):\n",
    "        self.degrees,self.range_zooms,self.size = degrees,(min_zoom,max_zoom),size\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        matrix = get_random_rot_matrix(self.degrees)\n",
    "        matrix = matrix.mm(get_random_scale_matrix(self.range_zooms))\n",
    "        matrix = matrix[:2,:]\n",
    "        _, h, w = x.size()\n",
    "        ratio = min(h,w) / self.size\n",
    "        img_size = torch.Size([1,3,int(h/ratio),int(w/ratio)])\n",
    "        coords = F.affine_grid(matrix[None], img_size)\n",
    "        a = random.randint(0, img_size[2]-self.size) if img_size[2] >= self.size else 0\n",
    "        b = random.randint(0, img_size[3]-self.size) if img_size[3] >= self.size else 0\n",
    "        coords = crop(coords, (a,b), (self.size,self.size))\n",
    "        #if coords.size(1) < self.size or coords.size(2) < self.size: pdb.set_trace()\n",
    "        return interpolate(x[None], coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = CustomTfm(10, 0.8, 1, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,4,figsize=(12,12))\n",
    "for ax in axs.flatten():\n",
    "    res = tfm(img)\n",
    "    ax.imshow(res[0].numpy().transpose(1,2,0))\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a ModelData object and a Learner from the old fastai library to use the training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the same thing but do the rotaiton on the CPU instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "class TransformedFilesDataset1(Dataset):\n",
    "    def __init__(self, folder, tfms):\n",
    "        self.tfms = tfms\n",
    "        cls_dirs = find_classes(folder)\n",
    "        self.fns, self.y = [], []\n",
    "        self.classes = [cls.name for cls in cls_dirs]\n",
    "        for i, cls_dir in enumerate(cls_dirs):\n",
    "            fnames = get_image_files(cls_dir)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        \n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = Image.open(self.fns[i])\n",
    "        w,h = x.size\n",
    "        x = torch.tensor(np.array(x, dtype=np.float32).transpose(2,0,1)/255)\n",
    "        x = self.tfms(x)[0]\n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBunch1():\n",
    "    def __init__(self, trn_ds, val_ds, stats, bs=64, device=None):\n",
    "        self.device = default_device if device is None else device\n",
    "        if hasattr(trn_ds, 'classes'): self.classes = trn_ds.classes\n",
    "        self.trn_dl = get_dataloader(trn_ds, bs,   shuffle=True,  device=self.device, stats=stats)\n",
    "        self.val_dl = get_dataloader(val_ds, bs*2, shuffle=False, device=self.device, stats=stats)\n",
    "\n",
    "    @classmethod\n",
    "    def from_files(cls, Path, size, trn_tfms, val_tfms, stats, trn_name='train', val_name='valid', bs=64, device=None):\n",
    "        trn_ds, val_ds = TransformedFilesDataset1(Path/trn_name, trn_tfms), TransformedFilesDataset1(Path/val_name, val_tfms)\n",
    "        return cls(trn_ds, val_ds, stats, bs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = [np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225])]\n",
    "size = 224\n",
    "trn_tfms = CustomTfm(10, 0.8, 1, 224)\n",
    "val_tfms = CustomTfm(0, 1, 1, 224)\n",
    "data = DataBunch1.from_files(PATH, (size,size), trn_tfms, val_tfms, stats, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time for (x,y) in iter(data.trn_dl): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

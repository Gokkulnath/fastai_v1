{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS = '<eos>'\n",
    "PATH=Path('../data/wikitext')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small helper function to read the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    tokens = []\n",
    "    with open(PATH/filename, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            tokens.append(line.split() + [EOS])\n",
    "    return np.array(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_tok = read_file('wiki.train.tokens')\n",
    "val_tok = read_file('wiki.valid.tokens')\n",
    "tst_tok = read_file('wiki.test.tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36718, 3760, 4358)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_tok), len(val_tok), len(tst_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(trn_tok[4][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 113161),\n",
       " (',', 99913),\n",
       " ('.', 73388),\n",
       " ('of', 56889),\n",
       " ('<unk>', 54625),\n",
       " ('and', 50603),\n",
       " ('in', 39453),\n",
       " ('to', 39190),\n",
       " ('<eos>', 36718),\n",
       " ('a', 34237)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = Counter(word for sent in trn_tok for word in sent)\n",
    "cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give an id to each token and add the pad token (just in case we need it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = [o for o,c in cnt.most_common()]\n",
    "itos.insert(0,'<pad>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33279"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(itos); vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the mapping from token to id then numericalizing our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = collections.defaultdict(lambda : 5, {w:i for i,w in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ids = np.array([([stoi[w] for w in s]) for s in trn_tok])\n",
    "val_ids = np.array([([stoi[w] for w in s]) for s in val_tok])\n",
    "tst_ids = np.array([([stoi[w] for w in s]) for s in tst_tok])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing WeightDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a bunch of parameters for deterministic tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = nn.LSTM(20, 20)\n",
    "tst_input = torch.randn(2,5,20)\n",
    "tst_output = torch.randint(0,20,(10,)).long()\n",
    "save_params = {}\n",
    "for n,p in module._parameters.items(): save_params[n] = p.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old WeightDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WeightDrop(\n",
       "  (module): LSTM(20, 20)\n",
       ")"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = nn.LSTM(20, 20)\n",
    "for n,p in save_params.items(): module._parameters[n] = nn.Parameter(p.clone())\n",
    "dp_module = WeightDrop(module, 0.5)\n",
    "opt = optim.SGD(dp_module.parameters(), 10)\n",
    "dp_module.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x267b3a7b390>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tst_input.clone()\n",
    "x.requires_grad_(requires_grad=True)\n",
    "h = (torch.zeros(1,5,20), torch.zeros(1,5,20))\n",
    "for _ in range(5): x,h = dp_module(x,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0000,  0.2960,  0.0000,  ...,  0.0000, -0.0000, -0.2676],\n",
       "         [ 0.0000,  0.0000,  0.1761,  ..., -0.1233,  0.3515,  0.2500],\n",
       "         [ 0.0000, -0.0000, -0.2828,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         ...,\n",
       "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.3393,  0.0921],\n",
       "         [ 0.0000, -0.0000,  0.1991,  ...,  0.4160, -0.0000,  0.0000],\n",
       "         [-0.1975,  0.0776, -0.0000,  ..., -0.0000,  0.0000,  0.0000]],\n",
       "        grad_fn=<DropoutBackward>), Parameter containing:\n",
       " tensor([[-0.0017,  0.1480,  0.0863,  ...,  0.0488, -0.1722, -0.1338],\n",
       "         [ 0.2046,  0.0867,  0.0880,  ..., -0.0616,  0.1757,  0.1250],\n",
       "         [ 0.0520, -0.1550, -0.1414,  ...,  0.0677, -0.2110,  0.1627],\n",
       "         ...,\n",
       "         [-0.2192,  0.0924, -0.1362,  ...,  0.1746,  0.1697,  0.0461],\n",
       "         [ 0.0708, -0.1189,  0.0996,  ...,  0.2080, -0.1703,  0.0059],\n",
       "         [-0.0987,  0.0388, -0.1416,  ..., -0.0332,  0.0853,  0.1414]],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(dp_module.module, 'weight_hh_l0'),getattr(dp_module.module,'weight_hh_l0_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tst_output.clone()\n",
    "loss = F.nll_loss(x.view(-1,20), target)\n",
    "loss.backward()\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, tensor([[-0.0000, -0.0001, -0.0001,  ..., -0.0000, -0.0000,  0.0001],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0001, -0.0002,  0.0000],\n",
       "         [ 0.0002, -0.0000,  0.0001,  ..., -0.0001,  0.0002,  0.0001],\n",
       "         ...,\n",
       "         [ 0.0001,  0.0001,  0.0002,  ..., -0.0001,  0.0000, -0.0000],\n",
       "         [-0.0002,  0.0000, -0.0017,  ..., -0.0001,  0.0001,  0.0003],\n",
       "         [-0.0001,  0.0001, -0.0003,  ...,  0.0001, -0.0004,  0.0002]]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, w_raw = getattr(dp_module.module, 'weight_hh_l0'),getattr(dp_module.module,'weight_hh_l0_raw')\n",
    "w.grad, w_raw.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0000,  0.2960,  0.0000,  ...,  0.0000, -0.0000, -0.2676],\n",
       "         [ 0.0000,  0.0000,  0.1761,  ..., -0.1233,  0.3515,  0.2500],\n",
       "         [ 0.0000, -0.0000, -0.2828,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         ...,\n",
       "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.3393,  0.0921],\n",
       "         [ 0.0000, -0.0000,  0.1991,  ...,  0.4160, -0.0000,  0.0000],\n",
       "         [-0.1975,  0.0776, -0.0000,  ..., -0.0000,  0.0000,  0.0000]],\n",
       "        grad_fn=<DropoutBackward>), Parameter containing:\n",
       " tensor([[-0.0014,  0.1486,  0.0869,  ...,  0.0492, -0.1719, -0.1344],\n",
       "         [ 0.2048,  0.0869,  0.0884,  ..., -0.0610,  0.1774,  0.1247],\n",
       "         [ 0.0502, -0.1547, -0.1419,  ...,  0.0682, -0.2130,  0.1622],\n",
       "         ...,\n",
       "         [-0.2202,  0.0917, -0.1387,  ...,  0.1755,  0.1695,  0.0464],\n",
       "         [ 0.0726, -0.1192,  0.1170,  ...,  0.2085, -0.1711,  0.0032],\n",
       "         [-0.0979,  0.0376, -0.1388,  ..., -0.0343,  0.0894,  0.1396]],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(dp_module.module, 'weight_hh_l0'),getattr(dp_module.module,'weight_hh_l0_raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New WeightDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightDropout(nn.Module):\n",
    "    \"A module that warps another layer in which some weights will be replaced by 0 during training.\"\n",
    "    \n",
    "    def __init__(self, module, dropout, layer_names=['weight_hh_l0']):\n",
    "        super().__init__()\n",
    "        self.module,self.dropout,self.layer_names = module,dropout,layer_names\n",
    "        for layer in self.layer_names:\n",
    "            #Makes a copy of the weights of the selected layers.\n",
    "            w = getattr(self.module, layer)\n",
    "            self.register_parameter(f'{layer}_raw', nn.Parameter(w.data))\n",
    "    \n",
    "    def _setweights(self):\n",
    "        for layer in self.layer_names:\n",
    "            raw_w = getattr(self, f'{layer}_raw')\n",
    "            self.module._parameters[layer] = F.dropout(raw_w, p=self.dropout, training=self.training)\n",
    "            \n",
    "    def forward(self, *args):\n",
    "        self._setweights()\n",
    "        return self.module.forward(*args)\n",
    "    \n",
    "    def reset(self):\n",
    "        if hasattr(self.module, 'reset'): self.module.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WeightDropout(\n",
       "  (module): LSTM(20, 20)\n",
       ")"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = nn.LSTM(20, 20)\n",
    "for n,p in save_params.items(): module._parameters[n] = nn.Parameter(p.clone())\n",
    "dp_module = WeightDropout(module, 0.5)\n",
    "opt = optim.SGD(dp_module.parameters(), 10)\n",
    "dp_module.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x267b3a7b390>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tst_input.clone()\n",
    "x.requires_grad_(requires_grad=True)\n",
    "h = (torch.zeros(1,5,20), torch.zeros(1,5,20))\n",
    "for _ in range(5): x,h = dp_module(x,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0000,  0.2960,  0.0000,  ...,  0.0000, -0.0000, -0.2676],\n",
       "         [ 0.0000,  0.0000,  0.1761,  ..., -0.1233,  0.3515,  0.2500],\n",
       "         [ 0.0000, -0.0000, -0.2828,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         ...,\n",
       "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.3393,  0.0921],\n",
       "         [ 0.0000, -0.0000,  0.1991,  ...,  0.4160, -0.0000,  0.0000],\n",
       "         [-0.1975,  0.0776, -0.0000,  ..., -0.0000,  0.0000,  0.0000]],\n",
       "        grad_fn=<DropoutBackward>), Parameter containing:\n",
       " tensor([[-0.0017,  0.1480,  0.0863,  ...,  0.0488, -0.1722, -0.1338],\n",
       "         [ 0.2046,  0.0867,  0.0880,  ..., -0.0616,  0.1757,  0.1250],\n",
       "         [ 0.0520, -0.1550, -0.1414,  ...,  0.0677, -0.2110,  0.1627],\n",
       "         ...,\n",
       "         [-0.2192,  0.0924, -0.1362,  ...,  0.1746,  0.1697,  0.0461],\n",
       "         [ 0.0708, -0.1189,  0.0996,  ...,  0.2080, -0.1703,  0.0059],\n",
       "         [-0.0987,  0.0388, -0.1416,  ..., -0.0332,  0.0853,  0.1414]],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(dp_module.module, 'weight_hh_l0'),getattr(dp_module,'weight_hh_l0_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tst_output.clone()\n",
    "loss = F.nll_loss(x.view(-1,20), target)\n",
    "loss.backward()\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, tensor([[-0.0000, -0.0001, -0.0001,  ..., -0.0000, -0.0000,  0.0001],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0001, -0.0002,  0.0000],\n",
       "         [ 0.0002, -0.0000,  0.0001,  ..., -0.0001,  0.0002,  0.0001],\n",
       "         ...,\n",
       "         [ 0.0001,  0.0001,  0.0002,  ..., -0.0001,  0.0000, -0.0000],\n",
       "         [-0.0002,  0.0000, -0.0017,  ..., -0.0001,  0.0001,  0.0003],\n",
       "         [-0.0001,  0.0001, -0.0003,  ...,  0.0001, -0.0004,  0.0002]]))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, w_raw = getattr(dp_module.module, 'weight_hh_l0'),getattr(dp_module,'weight_hh_l0_raw')\n",
    "w.grad, w_raw.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0000,  0.2960,  0.0000,  ...,  0.0000, -0.0000, -0.2676],\n",
       "         [ 0.0000,  0.0000,  0.1761,  ..., -0.1233,  0.3515,  0.2500],\n",
       "         [ 0.0000, -0.0000, -0.2828,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         ...,\n",
       "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.3393,  0.0921],\n",
       "         [ 0.0000, -0.0000,  0.1991,  ...,  0.4160, -0.0000,  0.0000],\n",
       "         [-0.1975,  0.0776, -0.0000,  ..., -0.0000,  0.0000,  0.0000]],\n",
       "        grad_fn=<DropoutBackward>), Parameter containing:\n",
       " tensor([[-0.0014,  0.1486,  0.0869,  ...,  0.0492, -0.1719, -0.1344],\n",
       "         [ 0.2048,  0.0869,  0.0884,  ..., -0.0610,  0.1774,  0.1247],\n",
       "         [ 0.0502, -0.1547, -0.1419,  ...,  0.0682, -0.2130,  0.1622],\n",
       "         ...,\n",
       "         [-0.2202,  0.0917, -0.1387,  ...,  0.1755,  0.1695,  0.0464],\n",
       "         [ 0.0726, -0.1192,  0.1170,  ...,  0.2085, -0.1711,  0.0032],\n",
       "         [-0.0979,  0.0376, -0.1388,  ..., -0.0343,  0.0894,  0.1396]],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(dp_module.module, 'weight_hh_l0'),getattr(dp_module,'weight_hh_l0_raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing EmbeddingDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a bunch of parameters for deterministic tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = nn.Embedding(100,20, padding_idx=0)\n",
    "tst_input = torch.randint(0,100,(25,)).long()\n",
    "save_params = enc.weight.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old EmbeddingDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = nn.Embedding(100,20, padding_idx=0)\n",
    "enc.weight = nn.Parameter(save_params.clone())\n",
    "enc_dp = EmbeddingDropout(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x267b3a7b390>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.5968,  2.2839,  0.2721,  0.0570, -1.6870,  1.4972,  0.2437,  1.8152,\n",
       "         -2.6273,  1.2273,  1.1763,  0.5037, -1.5096,  3.2505,  3.5982,  1.2784,\n",
       "         -0.7848, -1.1731, -1.4113,  0.7130],\n",
       "        [-0.8334,  0.3309, -1.4314,  2.4850, -2.6664,  0.5921, -0.1873,  3.9878,\n",
       "         -0.2396,  1.9089,  0.2984,  3.2444,  0.3894, -3.1906,  1.1718, -2.1071,\n",
       "         -1.3819,  0.5844,  2.9225,  2.0132],\n",
       "        [-0.0241, -2.8601,  0.7630,  0.6362,  0.2076,  1.2215,  0.0995,  2.7534,\n",
       "         -0.8016, -0.7123, -1.2020, -0.9800, -1.3590, -0.7056, -0.7452, -1.9312,\n",
       "          3.8816, -2.9207,  3.0680,  0.9727],\n",
       "        [-0.8925, -0.2838, -3.5902,  0.4280, -0.5449,  0.6160, -1.7927,  0.9662,\n",
       "         -1.8964, -0.4531,  1.5771,  1.3366,  0.9028, -1.7587, -1.4735, -2.4497,\n",
       "          2.2552,  1.9607,  0.1777,  0.2684],\n",
       "        [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0000, -0.0000],\n",
       "        [ 0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,\n",
       "         -0.0000, -0.0000, -0.0000,  0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "          0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "         -0.0000,  0.0000,  0.0000, -0.0000],\n",
       "        [-2.0247,  2.0005,  2.9300,  0.6409,  1.5333,  4.2490, -1.3660, -1.1211,\n",
       "          3.0018, -7.7377, -2.0532,  1.3431, -3.5391, -0.6202, -2.2379, -0.7048,\n",
       "         -1.5704,  1.7494, -3.8439, -0.5866],\n",
       "        [ 0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
       "         -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000, -0.0000],\n",
       "        [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "         -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000,  0.0000,  0.0000],\n",
       "        [-1.9156,  3.5037,  1.9591,  0.8210,  3.5350, -0.1664,  1.0174,  2.2356,\n",
       "          0.3266,  1.0025,  2.8411,  2.3084, -3.0731, -1.1154, -0.8767,  2.3144,\n",
       "         -0.0379, -0.8145,  1.0634, -1.4839],\n",
       "        [-0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
       "         -0.0000, -0.0000,  0.0000, -0.0000],\n",
       "        [ 0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000,  0.0000],\n",
       "        [ 1.2265,  0.5661,  2.3709, -2.5959, -1.5745,  3.4844,  1.1760,  0.5510,\n",
       "         -1.5909, -4.2679, -1.4985,  1.2679,  2.0073, -4.3761, -1.9854,  1.7770,\n",
       "         -3.0305, -1.8254,  2.5432,  0.2903],\n",
       "        [ 3.0310,  1.2366,  1.3392, -1.4387,  0.4750, -1.3065, -1.6107,  1.9977,\n",
       "          0.3571, -0.2550,  0.8700, -2.3916, -2.3863,  0.8446,  1.9074, -0.4997,\n",
       "          3.0794, -2.0631,  0.0751,  0.2417],\n",
       "        [-0.2885,  3.2241,  3.1342, -1.8777, -3.4355, -1.1648, -1.2307,  3.0992,\n",
       "          1.1978, -1.2753, -4.5716, -0.7353, -0.7732, -2.0740,  1.1841, -1.5113,\n",
       "          0.7835,  1.4940,  2.7595,  2.5754],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "          0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "         -0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-1.0945, -2.3153, -1.6892,  0.7396,  2.3395, -3.4070,  0.3343, -3.9851,\n",
       "          1.4646, -0.5102,  2.8714, -2.8153, -1.4564,  2.6719,  1.4754, -1.7049,\n",
       "          0.7048, -0.9525, -2.2271,  0.5412],\n",
       "        [ 0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [-1.5772,  0.8225, -1.0743, -0.0485, -0.8999, -0.0004, -0.6308, -2.3086,\n",
       "         -1.1489, -0.4389, -0.7562,  1.1551,  0.2940, -1.4227, -1.1548, -0.2256,\n",
       "         -0.3646, -1.6049,  0.4017, -4.7985],\n",
       "        [-1.2516,  0.2826, -1.4568, -1.4407, -0.9941,  1.8913,  0.8736,  1.8730,\n",
       "          2.9395, -1.3067,  0.9059, -2.5514,  3.2087,  2.9153,  0.3965,  0.1945,\n",
       "          1.7574,  1.1067, -2.5834,  1.7590],\n",
       "        [-0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0000, -0.0000]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tst_input.clone()\n",
    "enc_dp(x, dropout=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New EmbeddingDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_mask(x, sz, p):\n",
    "    \"Returns a dropout mask of the same type as x, size sz, with probability p to cancel an element.\"\n",
    "    return x.new(*sz).bernoulli_(1-p)/(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDropout1(nn.Module):\n",
    "\n",
    "    \"Applies dropout in the embedding layer by zeroing out some elements of the embedding vector.\"\n",
    "    def __init__(self, emb):\n",
    "        super().__init__()\n",
    "        self.emb = emb\n",
    "        self.pad_idx = self.emb.padding_idx\n",
    "        if self.pad_idx is None: self.pad_idx = -1\n",
    "\n",
    "    def forward(self, words, dropout=0.1, scale=None):\n",
    "        if dropout:\n",
    "            size = (self.emb.weight.size(0),1)\n",
    "            mask = dropout_mask(self.emb.weight.data, size, dropout)\n",
    "            masked_emb_weight = mask * self.emb.weight\n",
    "        else: masked_emb_weight = self.emb.weight\n",
    "        if scale: masked_emb_weight = scale * masked_emb_weight\n",
    "        return F.embedding(words, masked_emb_weight, self.pad_idx, self.emb.max_norm,\n",
    "                           self.emb.norm_type, self.emb.scale_grad_by_freq, self.emb.sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = nn.Embedding(100,20, padding_idx=0)\n",
    "enc.weight = nn.Parameter(save_params.clone())\n",
    "enc_dp = EmbeddingDropout1(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x267b3a7b390>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.5968,  2.2839,  0.2721,  0.0570, -1.6870,  1.4972,  0.2437,  1.8152,\n",
       "         -2.6273,  1.2273,  1.1763,  0.5037, -1.5096,  3.2505,  3.5982,  1.2784,\n",
       "         -0.7848, -1.1731, -1.4113,  0.7130],\n",
       "        [-0.8334,  0.3309, -1.4314,  2.4850, -2.6664,  0.5921, -0.1873,  3.9878,\n",
       "         -0.2396,  1.9089,  0.2984,  3.2444,  0.3894, -3.1906,  1.1718, -2.1071,\n",
       "         -1.3819,  0.5844,  2.9225,  2.0132],\n",
       "        [-0.0241, -2.8601,  0.7630,  0.6362,  0.2076,  1.2215,  0.0995,  2.7534,\n",
       "         -0.8016, -0.7123, -1.2020, -0.9800, -1.3590, -0.7056, -0.7452, -1.9312,\n",
       "          3.8816, -2.9207,  3.0680,  0.9727],\n",
       "        [-0.8925, -0.2838, -3.5902,  0.4280, -0.5449,  0.6160, -1.7927,  0.9662,\n",
       "         -1.8964, -0.4531,  1.5771,  1.3366,  0.9028, -1.7587, -1.4735, -2.4497,\n",
       "          2.2552,  1.9607,  0.1777,  0.2684],\n",
       "        [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0000, -0.0000],\n",
       "        [ 0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,\n",
       "         -0.0000, -0.0000, -0.0000,  0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "          0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "         -0.0000,  0.0000,  0.0000, -0.0000],\n",
       "        [-2.0247,  2.0005,  2.9300,  0.6409,  1.5333,  4.2490, -1.3660, -1.1211,\n",
       "          3.0018, -7.7377, -2.0532,  1.3431, -3.5391, -0.6202, -2.2379, -0.7048,\n",
       "         -1.5704,  1.7494, -3.8439, -0.5866],\n",
       "        [ 0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
       "         -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000, -0.0000],\n",
       "        [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "         -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000,  0.0000,  0.0000],\n",
       "        [-1.9156,  3.5037,  1.9591,  0.8210,  3.5350, -0.1664,  1.0174,  2.2356,\n",
       "          0.3266,  1.0025,  2.8411,  2.3084, -3.0731, -1.1154, -0.8767,  2.3144,\n",
       "         -0.0379, -0.8145,  1.0634, -1.4839],\n",
       "        [-0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
       "         -0.0000, -0.0000,  0.0000, -0.0000],\n",
       "        [ 0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000,  0.0000],\n",
       "        [ 1.2265,  0.5661,  2.3709, -2.5959, -1.5745,  3.4844,  1.1760,  0.5510,\n",
       "         -1.5909, -4.2679, -1.4985,  1.2679,  2.0073, -4.3761, -1.9854,  1.7770,\n",
       "         -3.0305, -1.8254,  2.5432,  0.2903],\n",
       "        [ 3.0310,  1.2366,  1.3392, -1.4387,  0.4750, -1.3065, -1.6107,  1.9977,\n",
       "          0.3571, -0.2550,  0.8700, -2.3916, -2.3863,  0.8446,  1.9074, -0.4997,\n",
       "          3.0794, -2.0631,  0.0751,  0.2417],\n",
       "        [-0.2885,  3.2241,  3.1342, -1.8777, -3.4355, -1.1648, -1.2307,  3.0992,\n",
       "          1.1978, -1.2753, -4.5716, -0.7353, -0.7732, -2.0740,  1.1841, -1.5113,\n",
       "          0.7835,  1.4940,  2.7595,  2.5754],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "          0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "         -0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-1.0945, -2.3153, -1.6892,  0.7396,  2.3395, -3.4070,  0.3343, -3.9851,\n",
       "          1.4646, -0.5102,  2.8714, -2.8153, -1.4564,  2.6719,  1.4754, -1.7049,\n",
       "          0.7048, -0.9525, -2.2271,  0.5412],\n",
       "        [ 0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [-1.5772,  0.8225, -1.0743, -0.0485, -0.8999, -0.0004, -0.6308, -2.3086,\n",
       "         -1.1489, -0.4389, -0.7562,  1.1551,  0.2940, -1.4227, -1.1548, -0.2256,\n",
       "         -0.3646, -1.6049,  0.4017, -4.7985],\n",
       "        [-1.2516,  0.2826, -1.4568, -1.4407, -0.9941,  1.8913,  0.8736,  1.8730,\n",
       "          2.9395, -1.3067,  0.9059, -2.5514,  3.2087,  2.9153,  0.3965,  0.1945,\n",
       "          1.7574,  1.1067, -2.5834,  1.7590],\n",
       "        [-0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0000, -0.0000]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tst_input.clone()\n",
    "enc_dp(x, dropout=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a bunch of parameters for deterministic testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_model = get_language_model(500, 20, 100, 2, 0, bias=True)\n",
    "save_parameters = {}\n",
    "for n,p in tst_model.state_dict().items(): save_parameters[n] = p.clone()\n",
    "tst_input = torch.randint(0, 500, (10,5)).long()\n",
    "tst_output = torch.randint(0, 500, (50,)).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_model = get_language_model(500, 20, 100, 2, 0, bias=True)\n",
    "state_dict = OrderedDict()\n",
    "for n,p in save_parameters.items(): state_dict[n] = p.clone()\n",
    "tst_model.load_state_dict(state_dict)\n",
    "opt = optim.SGD(tst_model.parameters(), lr=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x267b3a7b390>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0044, -0.0150, -0.0099,  ...,  0.0240,  0.0212,  0.0210],\n",
       "         [ 0.0352,  0.0143,  0.0101,  ...,  0.0142,  0.0458,  0.0124],\n",
       "         [ 0.0028,  0.0098,  0.0056,  ...,  0.0348,  0.0142,  0.0040],\n",
       "         ...,\n",
       "         [ 0.0062,  0.0257, -0.0043,  ...,  0.0987,  0.0324,  0.0284],\n",
       "         [ 0.0079, -0.0157,  0.0004,  ...,  0.0660,  0.0977,  0.0812],\n",
       "         [-0.0418, -0.0244, -0.0035,  ...,  0.0666,  0.0294,  0.0278]],\n",
       "        grad_fn=<ViewBackward>),\n",
       " [tensor([[[-0.0039,  0.0119,  0.0085,  ..., -0.0195, -0.0137, -0.0333],\n",
       "           [-0.0123,  0.0093,  0.0111,  ..., -0.0242, -0.0010, -0.0357],\n",
       "           [-0.0069,  0.0100,  0.0128,  ..., -0.0192, -0.0096, -0.0339],\n",
       "           [-0.0044,  0.0128,  0.0127,  ..., -0.0161, -0.0135, -0.0358],\n",
       "           [-0.0102,  0.0170,  0.0098,  ..., -0.0186, -0.0101, -0.0359]],\n",
       "  \n",
       "          [[-0.0081,  0.0124,  0.0230,  ..., -0.0372, -0.0193, -0.0457],\n",
       "           [-0.0096,  0.0081,  0.0214,  ..., -0.0444, -0.0150, -0.0437],\n",
       "           [-0.0031,  0.0079,  0.0137,  ..., -0.0374, -0.0206, -0.0355],\n",
       "           [-0.0107,  0.0214,  0.0204,  ..., -0.0286, -0.0201, -0.0471],\n",
       "           [-0.0070,  0.0102,  0.0225,  ..., -0.0328, -0.0206, -0.0335]],\n",
       "  \n",
       "          [[-0.0052,  0.0131,  0.0342,  ..., -0.0450, -0.0203, -0.0359],\n",
       "           [-0.0112,  0.0148,  0.0301,  ..., -0.0480, -0.0225, -0.0482],\n",
       "           [-0.0124,  0.0196,  0.0243,  ..., -0.0367, -0.0270, -0.0408],\n",
       "           [-0.0123,  0.0277,  0.0282,  ..., -0.0353, -0.0271, -0.0518],\n",
       "           [-0.0136,  0.0295,  0.0355,  ..., -0.0390, -0.0202, -0.0480]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-0.0212,  0.0324,  0.0507,  ..., -0.0604, -0.0292, -0.0589],\n",
       "           [-0.0264,  0.0269,  0.0441,  ..., -0.0550, -0.0293, -0.0482],\n",
       "           [-0.0277,  0.0253,  0.0381,  ..., -0.0647, -0.0150, -0.0317],\n",
       "           [-0.0245,  0.0242,  0.0540,  ..., -0.0635, -0.0288, -0.0530],\n",
       "           [-0.0185,  0.0425,  0.0383,  ..., -0.0629, -0.0311, -0.0593]],\n",
       "  \n",
       "          [[-0.0284,  0.0419,  0.0565,  ..., -0.0555, -0.0305, -0.0717],\n",
       "           [-0.0275,  0.0401,  0.0431,  ..., -0.0627, -0.0207, -0.0573],\n",
       "           [-0.0343,  0.0393,  0.0452,  ..., -0.0547, -0.0256, -0.0490],\n",
       "           [-0.0270,  0.0285,  0.0502,  ..., -0.0609, -0.0276, -0.0574],\n",
       "           [-0.0257,  0.0394,  0.0454,  ..., -0.0660, -0.0280, -0.0540]],\n",
       "  \n",
       "          [[-0.0272,  0.0221,  0.0544,  ..., -0.0650, -0.0281, -0.0533],\n",
       "           [-0.0227,  0.0336,  0.0407,  ..., -0.0543, -0.0278, -0.0533],\n",
       "           [-0.0292,  0.0335,  0.0454,  ..., -0.0529, -0.0304, -0.0420],\n",
       "           [-0.0291,  0.0316,  0.0519,  ..., -0.0571, -0.0283, -0.0531],\n",
       "           [-0.0258,  0.0376,  0.0458,  ..., -0.0626, -0.0256, -0.0515]]],\n",
       "         grad_fn=<CatBackward>),\n",
       "  tensor([[[-0.0769, -0.0221,  0.0094, -0.0702,  0.0995,  0.0194,  0.0204,\n",
       "            -0.0060,  0.0416, -0.0060, -0.0538, -0.0301, -0.0601, -0.0085,\n",
       "            -0.0722,  0.0033,  0.0594,  0.0386,  0.0775, -0.0287],\n",
       "           [-0.0852, -0.0296,  0.0129, -0.0701,  0.1093,  0.0231,  0.0200,\n",
       "            -0.0109,  0.0458, -0.0095, -0.0493, -0.0280, -0.0613, -0.0094,\n",
       "            -0.0712, -0.0139,  0.0591,  0.0433,  0.0802, -0.0217],\n",
       "           [-0.0814, -0.0198, -0.0031, -0.0684,  0.1010,  0.0217,  0.0242,\n",
       "            -0.0058,  0.0454, -0.0087, -0.0586, -0.0318, -0.0660, -0.0060,\n",
       "            -0.0755, -0.0063,  0.0666,  0.0342,  0.0811, -0.0286],\n",
       "           [-0.0829, -0.0244,  0.0191, -0.0767,  0.1035,  0.0210,  0.0200,\n",
       "            -0.0102,  0.0435, -0.0116, -0.0543, -0.0296, -0.0589, -0.0098,\n",
       "            -0.0692, -0.0026,  0.0643,  0.0402,  0.0768, -0.0343],\n",
       "           [-0.0861, -0.0219, -0.0038, -0.0736,  0.1028,  0.0244,  0.0203,\n",
       "            -0.0083,  0.0352,  0.0017, -0.0547, -0.0272, -0.0612, -0.0099,\n",
       "            -0.0730, -0.0049,  0.0704,  0.0421,  0.0828, -0.0239]],\n",
       "  \n",
       "          [[-0.1194, -0.0218,  0.0141, -0.1106,  0.1512,  0.0277,  0.0161,\n",
       "            -0.0192,  0.0641, -0.0010, -0.0768, -0.0360, -0.0998, -0.0235,\n",
       "            -0.1159,  0.0227,  0.0890,  0.0639,  0.0983, -0.0657],\n",
       "           [-0.1343, -0.0460,  0.0279, -0.1091,  0.1627,  0.0286,  0.0182,\n",
       "            -0.0364,  0.0783, -0.0126, -0.0674, -0.0380, -0.0988, -0.0285,\n",
       "            -0.1164, -0.0101,  0.0868,  0.0752,  0.1009, -0.0549],\n",
       "           [-0.1297, -0.0183, -0.0110, -0.1083,  0.1506,  0.0346,  0.0289,\n",
       "            -0.0145,  0.0720, -0.0118, -0.0899, -0.0452, -0.1088, -0.0225,\n",
       "            -0.1179,  0.0075,  0.1000,  0.0584,  0.1072, -0.0669],\n",
       "           [-0.1297, -0.0354,  0.0380, -0.1234,  0.1608,  0.0337,  0.0184,\n",
       "            -0.0284,  0.0732, -0.0236, -0.0802, -0.0415, -0.0968, -0.0318,\n",
       "            -0.1106,  0.0132,  0.0954,  0.0659,  0.0963, -0.0769],\n",
       "           [-0.1367, -0.0282, -0.0030, -0.1175,  0.1600,  0.0407,  0.0144,\n",
       "            -0.0180,  0.0522,  0.0046, -0.0838, -0.0376, -0.1073, -0.0251,\n",
       "            -0.1148,  0.0050,  0.1038,  0.0662,  0.1064, -0.0581]],\n",
       "  \n",
       "          [[-0.1401, -0.0207,  0.0227, -0.1359,  0.1819,  0.0324,  0.0151,\n",
       "            -0.0242,  0.0877, -0.0090, -0.0918, -0.0335, -0.1238, -0.0397,\n",
       "            -0.1404,  0.0413,  0.0975,  0.0766,  0.1022, -0.0962],\n",
       "           [-0.1609, -0.0508,  0.0436, -0.1350,  0.1976,  0.0290,  0.0170,\n",
       "            -0.0634,  0.1014, -0.0122, -0.0743, -0.0413, -0.1252, -0.0481,\n",
       "            -0.1427,  0.0008,  0.0985,  0.1000,  0.1009, -0.0848],\n",
       "           [-0.1563, -0.0122, -0.0226, -0.1329,  0.1763,  0.0357,  0.0286,\n",
       "            -0.0248,  0.0906, -0.0182, -0.1078, -0.0525, -0.1350, -0.0414,\n",
       "            -0.1445,  0.0232,  0.1176,  0.0672,  0.1155, -0.1004],\n",
       "           [-0.1567, -0.0320,  0.0477, -0.1534,  0.1916,  0.0393,  0.0128,\n",
       "            -0.0482,  0.0937, -0.0358, -0.0952, -0.0437, -0.1229, -0.0509,\n",
       "            -0.1351,  0.0286,  0.1100,  0.0800,  0.0962, -0.1071],\n",
       "           [-0.1636, -0.0273,  0.0005, -0.1458,  0.1960,  0.0454,  0.0069,\n",
       "            -0.0254,  0.0659,  0.0041, -0.1018, -0.0408, -0.1344, -0.0463,\n",
       "            -0.1384,  0.0214,  0.1176,  0.0791,  0.1101, -0.0859]],\n",
       "  \n",
       "          [[-0.1557, -0.0166,  0.0210, -0.1520,  0.2046,  0.0280,  0.0142,\n",
       "            -0.0330,  0.1044, -0.0133, -0.0953, -0.0329, -0.1378, -0.0539,\n",
       "            -0.1558,  0.0624,  0.0998,  0.0842,  0.0970, -0.1141],\n",
       "           [-0.1769, -0.0521,  0.0499, -0.1487,  0.2202,  0.0275,  0.0158,\n",
       "            -0.0843,  0.1139, -0.0169, -0.0771, -0.0384, -0.1440, -0.0615,\n",
       "            -0.1567,  0.0129,  0.1028,  0.1112,  0.0938, -0.1063],\n",
       "           [-0.1754, -0.0045, -0.0318, -0.1466,  0.1934,  0.0350,  0.0280,\n",
       "            -0.0283,  0.1041, -0.0250, -0.1194, -0.0549, -0.1525, -0.0655,\n",
       "            -0.1542,  0.0374,  0.1226,  0.0740,  0.1182, -0.1213],\n",
       "           [-0.1731, -0.0268,  0.0545, -0.1709,  0.2132,  0.0397,  0.0116,\n",
       "            -0.0589,  0.1128, -0.0497, -0.1022, -0.0444, -0.1335, -0.0704,\n",
       "            -0.1487,  0.0481,  0.1157,  0.0883,  0.0936, -0.1288],\n",
       "           [-0.1794, -0.0226,  0.0006, -0.1607,  0.2177,  0.0463,  0.0014,\n",
       "            -0.0300,  0.0743,  0.0021, -0.1164, -0.0413, -0.1526, -0.0600,\n",
       "            -0.1488,  0.0378,  0.1270,  0.0846,  0.1049, -0.1034]],\n",
       "  \n",
       "          [[-0.1619, -0.0114,  0.0131, -0.1603,  0.2181,  0.0221,  0.0159,\n",
       "            -0.0376,  0.1129, -0.0135, -0.0965, -0.0310, -0.1474, -0.0618,\n",
       "            -0.1626,  0.0802,  0.1019,  0.0861,  0.0911, -0.1253],\n",
       "           [-0.1844, -0.0454,  0.0504, -0.1618,  0.2319,  0.0237,  0.0163,\n",
       "            -0.1026,  0.1246, -0.0212, -0.0763, -0.0360, -0.1536, -0.0701,\n",
       "            -0.1711,  0.0190,  0.1025,  0.1205,  0.0902, -0.1202],\n",
       "           [-0.1873,  0.0057, -0.0368, -0.1566,  0.2066,  0.0365,  0.0290,\n",
       "            -0.0342,  0.1134, -0.0335, -0.1240, -0.0577, -0.1617, -0.0773,\n",
       "            -0.1594,  0.0499,  0.1252,  0.0820,  0.1161, -0.1358],\n",
       "           [-0.1807, -0.0168,  0.0550, -0.1817,  0.2235,  0.0379,  0.0080,\n",
       "            -0.0683,  0.1268, -0.0608, -0.1073, -0.0451, -0.1413, -0.0858,\n",
       "            -0.1584,  0.0548,  0.1189,  0.0926,  0.0889, -0.1407],\n",
       "           [-0.1894, -0.0136,  0.0032, -0.1709,  0.2295,  0.0440,  0.0006,\n",
       "            -0.0289,  0.0819, -0.0012, -0.1201, -0.0388, -0.1588, -0.0730,\n",
       "            -0.1496,  0.0495,  0.1318,  0.0900,  0.1015, -0.1124]],\n",
       "  \n",
       "          [[-0.1677, -0.0066,  0.0133, -0.1609,  0.2304,  0.0171,  0.0182,\n",
       "            -0.0357,  0.1230, -0.0174, -0.1034, -0.0296, -0.1516, -0.0743,\n",
       "            -0.1658,  0.0915,  0.1041,  0.0880,  0.0900, -0.1287],\n",
       "           [-0.1858, -0.0418,  0.0509, -0.1694,  0.2381,  0.0218,  0.0180,\n",
       "            -0.1109,  0.1342, -0.0248, -0.0752, -0.0315, -0.1576, -0.0775,\n",
       "            -0.1766,  0.0279,  0.1044,  0.1255,  0.0848, -0.1292],\n",
       "           [-0.1936,  0.0172, -0.0378, -0.1658,  0.2152,  0.0395,  0.0323,\n",
       "            -0.0375,  0.1236, -0.0425, -0.1219, -0.0572, -0.1645, -0.0854,\n",
       "            -0.1619,  0.0601,  0.1242,  0.0901,  0.1146, -0.1457],\n",
       "           [-0.1868, -0.0035,  0.0535, -0.1961,  0.2293,  0.0413,  0.0113,\n",
       "            -0.0770,  0.1358, -0.0660, -0.1109, -0.0452, -0.1477, -0.0959,\n",
       "            -0.1622,  0.0643,  0.1183,  0.1022,  0.0892, -0.1514],\n",
       "           [-0.1971, -0.0070, -0.0001, -0.1825,  0.2361,  0.0427,  0.0006,\n",
       "            -0.0278,  0.0896, -0.0059, -0.1171, -0.0360, -0.1574, -0.0809,\n",
       "            -0.1533,  0.0604,  0.1360,  0.0953,  0.0976, -0.1184]],\n",
       "  \n",
       "          [[-0.1693, -0.0032,  0.0139, -0.1687,  0.2358,  0.0133,  0.0233,\n",
       "            -0.0405,  0.1348, -0.0255, -0.1034, -0.0360, -0.1513, -0.0787,\n",
       "            -0.1729,  0.0975,  0.1073,  0.0935,  0.0863, -0.1318],\n",
       "           [-0.1884, -0.0398,  0.0476, -0.1718,  0.2407,  0.0188,  0.0182,\n",
       "            -0.1196,  0.1419, -0.0291, -0.0751, -0.0283, -0.1599, -0.0823,\n",
       "            -0.1803,  0.0329,  0.1041,  0.1276,  0.0791, -0.1340],\n",
       "           [-0.1991,  0.0207, -0.0435, -0.1683,  0.2215,  0.0387,  0.0325,\n",
       "            -0.0375,  0.1246, -0.0456, -0.1264, -0.0592, -0.1695, -0.0901,\n",
       "            -0.1605,  0.0685,  0.1232,  0.0893,  0.1122, -0.1528],\n",
       "           [-0.1890,  0.0016,  0.0494, -0.2024,  0.2392,  0.0453,  0.0122,\n",
       "            -0.0828,  0.1463, -0.0761, -0.1137, -0.0443, -0.1522, -0.1005,\n",
       "            -0.1602,  0.0717,  0.1199,  0.1076,  0.0844, -0.1587],\n",
       "           [-0.1986, -0.0050, -0.0009, -0.1878,  0.2425,  0.0402,  0.0010,\n",
       "            -0.0263,  0.0956, -0.0102, -0.1213, -0.0365, -0.1619, -0.0859,\n",
       "            -0.1561,  0.0679,  0.1354,  0.0956,  0.0949, -0.1247]],\n",
       "  \n",
       "          [[-0.1691, -0.0010,  0.0168, -0.1659,  0.2435,  0.0100,  0.0232,\n",
       "            -0.0432,  0.1401, -0.0306, -0.1067, -0.0414, -0.1567, -0.0830,\n",
       "            -0.1756,  0.0995,  0.1048,  0.0925,  0.0816, -0.1349],\n",
       "           [-0.1878, -0.0374,  0.0432, -0.1727,  0.2395,  0.0161,  0.0211,\n",
       "            -0.1188,  0.1470, -0.0333, -0.0726, -0.0229, -0.1571, -0.0871,\n",
       "            -0.1818,  0.0419,  0.1052,  0.1280,  0.0773, -0.1374],\n",
       "           [-0.2026,  0.0251, -0.0479, -0.1729,  0.2248,  0.0406,  0.0328,\n",
       "            -0.0374,  0.1254, -0.0474, -0.1291, -0.0609, -0.1689, -0.0919,\n",
       "            -0.1601,  0.0740,  0.1223,  0.0945,  0.1105, -0.1574],\n",
       "           [-0.1905,  0.0060,  0.0425, -0.2039,  0.2430,  0.0412,  0.0114,\n",
       "            -0.0881,  0.1512, -0.0803, -0.1150, -0.0436, -0.1522, -0.1083,\n",
       "            -0.1605,  0.0762,  0.1188,  0.1069,  0.0822, -0.1601],\n",
       "           [-0.1986, -0.0029, -0.0024, -0.1876,  0.2493,  0.0378,  0.0048,\n",
       "            -0.0319,  0.0969, -0.0097, -0.1294, -0.0392, -0.1686, -0.0868,\n",
       "            -0.1554,  0.0740,  0.1353,  0.0954,  0.0894, -0.1262]],\n",
       "  \n",
       "          [[-0.1698,  0.0012,  0.0147, -0.1637,  0.2492,  0.0055,  0.0228,\n",
       "            -0.0458,  0.1401, -0.0335, -0.1069, -0.0478, -0.1589, -0.0859,\n",
       "            -0.1746,  0.1049,  0.1029,  0.0900,  0.0791, -0.1363],\n",
       "           [-0.1834, -0.0369,  0.0444, -0.1772,  0.2446,  0.0163,  0.0214,\n",
       "            -0.1230,  0.1492, -0.0318, -0.0768, -0.0260, -0.1613, -0.0893,\n",
       "            -0.1819,  0.0442,  0.1055,  0.1290,  0.0759, -0.1394],\n",
       "           [-0.2042,  0.0266, -0.0517, -0.1751,  0.2291,  0.0405,  0.0350,\n",
       "            -0.0408,  0.1226, -0.0499, -0.1281, -0.0611, -0.1705, -0.0888,\n",
       "            -0.1599,  0.0780,  0.1221,  0.0935,  0.1102, -0.1607],\n",
       "           [-0.1914,  0.0075,  0.0356, -0.2034,  0.2501,  0.0382,  0.0132,\n",
       "            -0.0902,  0.1550, -0.0845, -0.1167, -0.0455, -0.1519, -0.1149,\n",
       "            -0.1580,  0.0829,  0.1197,  0.1055,  0.0810, -0.1610],\n",
       "           [-0.2013,  0.0014, -0.0073, -0.1902,  0.2504,  0.0359,  0.0066,\n",
       "            -0.0324,  0.1000, -0.0098, -0.1264, -0.0380, -0.1641, -0.0913,\n",
       "            -0.1550,  0.0761,  0.1373,  0.0979,  0.0892, -0.1259]],\n",
       "  \n",
       "          [[-0.1745,  0.0038,  0.0075, -0.1598,  0.2476,  0.0066,  0.0220,\n",
       "            -0.0462,  0.1390, -0.0412, -0.1066, -0.0442, -0.1555, -0.0901,\n",
       "            -0.1719,  0.1084,  0.1038,  0.0912,  0.0795, -0.1389],\n",
       "           [-0.1849, -0.0393,  0.0432, -0.1752,  0.2459,  0.0149,  0.0231,\n",
       "            -0.1223,  0.1508, -0.0340, -0.0774, -0.0241, -0.1611, -0.0914,\n",
       "            -0.1804,  0.0469,  0.1031,  0.1290,  0.0743, -0.1422],\n",
       "           [-0.2036,  0.0278, -0.0563, -0.1772,  0.2305,  0.0408,  0.0350,\n",
       "            -0.0415,  0.1208, -0.0537, -0.1269, -0.0611, -0.1725, -0.0870,\n",
       "            -0.1618,  0.0792,  0.1207,  0.0920,  0.1118, -0.1641],\n",
       "           [-0.1913,  0.0060,  0.0316, -0.2035,  0.2524,  0.0353,  0.0161,\n",
       "            -0.0891,  0.1571, -0.0905, -0.1160, -0.0473, -0.1477, -0.1207,\n",
       "            -0.1587,  0.0896,  0.1213,  0.1030,  0.0838, -0.1622],\n",
       "           [-0.1999,  0.0029, -0.0105, -0.1903,  0.2516,  0.0345,  0.0071,\n",
       "            -0.0316,  0.1014, -0.0095, -0.1275, -0.0384, -0.1658, -0.0921,\n",
       "            -0.1549,  0.0766,  0.1375,  0.0979,  0.0898, -0.1275]]],\n",
       "         grad_fn=<CatBackward>)],\n",
       " [tensor([[[-0.0056,  0.0171,  0.0000,  ..., -0.0279, -0.0195, -0.0476],\n",
       "           [-0.0175,  0.0133,  0.0000,  ..., -0.0346, -0.0015, -0.0000],\n",
       "           [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0137, -0.0000],\n",
       "           [-0.0063,  0.0183,  0.0181,  ..., -0.0230, -0.0000, -0.0511],\n",
       "           [-0.0146,  0.0242,  0.0140,  ..., -0.0266, -0.0000, -0.0513]],\n",
       "  \n",
       "          [[-0.0116,  0.0178,  0.0000,  ..., -0.0532, -0.0276, -0.0653],\n",
       "           [-0.0137,  0.0116,  0.0000,  ..., -0.0634, -0.0214, -0.0000],\n",
       "           [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0295, -0.0000],\n",
       "           [-0.0153,  0.0305,  0.0292,  ..., -0.0408, -0.0000, -0.0672],\n",
       "           [-0.0100,  0.0146,  0.0321,  ..., -0.0468, -0.0000, -0.0478]],\n",
       "  \n",
       "          [[-0.0075,  0.0188,  0.0000,  ..., -0.0643, -0.0291, -0.0513],\n",
       "           [-0.0160,  0.0212,  0.0000,  ..., -0.0686, -0.0321, -0.0000],\n",
       "           [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0385, -0.0000],\n",
       "           [-0.0175,  0.0395,  0.0403,  ..., -0.0504, -0.0000, -0.0740],\n",
       "           [-0.0194,  0.0422,  0.0507,  ..., -0.0558, -0.0000, -0.0686]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-0.0303,  0.0463,  0.0000,  ..., -0.0863, -0.0417, -0.0842],\n",
       "           [-0.0378,  0.0384,  0.0000,  ..., -0.0786, -0.0418, -0.0000],\n",
       "           [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0215, -0.0000],\n",
       "           [-0.0350,  0.0345,  0.0771,  ..., -0.0906, -0.0000, -0.0756],\n",
       "           [-0.0264,  0.0608,  0.0546,  ..., -0.0899, -0.0000, -0.0847]],\n",
       "  \n",
       "          [[-0.0406,  0.0599,  0.0000,  ..., -0.0793, -0.0436, -0.1025],\n",
       "           [-0.0393,  0.0574,  0.0000,  ..., -0.0896, -0.0295, -0.0000],\n",
       "           [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0366, -0.0000],\n",
       "           [-0.0385,  0.0407,  0.0717,  ..., -0.0870, -0.0000, -0.0820],\n",
       "           [-0.0367,  0.0563,  0.0649,  ..., -0.0943, -0.0000, -0.0772]],\n",
       "  \n",
       "          [[-0.0388,  0.0316,  0.0000,  ..., -0.0928, -0.0401, -0.0761],\n",
       "           [-0.0324,  0.0480,  0.0000,  ..., -0.0775, -0.0397, -0.0000],\n",
       "           [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0435, -0.0000],\n",
       "           [-0.0415,  0.0452,  0.0741,  ..., -0.0816, -0.0000, -0.0759],\n",
       "           [-0.0369,  0.0537,  0.0655,  ..., -0.0894, -0.0000, -0.0736]]],\n",
       "         grad_fn=<ThMulBackward>),\n",
       "  tensor([[[-0.0769, -0.0221,  0.0094, -0.0702,  0.0995,  0.0194,  0.0204,\n",
       "            -0.0060,  0.0416, -0.0060, -0.0538, -0.0301, -0.0601, -0.0085,\n",
       "            -0.0722,  0.0033,  0.0594,  0.0386,  0.0775, -0.0287],\n",
       "           [-0.0852, -0.0296,  0.0129, -0.0701,  0.1093,  0.0231,  0.0200,\n",
       "            -0.0109,  0.0458, -0.0095, -0.0493, -0.0280, -0.0613, -0.0094,\n",
       "            -0.0712, -0.0139,  0.0591,  0.0433,  0.0802, -0.0217],\n",
       "           [-0.0814, -0.0198, -0.0031, -0.0684,  0.1010,  0.0217,  0.0242,\n",
       "            -0.0058,  0.0454, -0.0087, -0.0586, -0.0318, -0.0660, -0.0060,\n",
       "            -0.0755, -0.0063,  0.0666,  0.0342,  0.0811, -0.0286],\n",
       "           [-0.0829, -0.0244,  0.0191, -0.0767,  0.1035,  0.0210,  0.0200,\n",
       "            -0.0102,  0.0435, -0.0116, -0.0543, -0.0296, -0.0589, -0.0098,\n",
       "            -0.0692, -0.0026,  0.0643,  0.0402,  0.0768, -0.0343],\n",
       "           [-0.0861, -0.0219, -0.0038, -0.0736,  0.1028,  0.0244,  0.0203,\n",
       "            -0.0083,  0.0352,  0.0017, -0.0547, -0.0272, -0.0612, -0.0099,\n",
       "            -0.0730, -0.0049,  0.0704,  0.0421,  0.0828, -0.0239]],\n",
       "  \n",
       "          [[-0.1194, -0.0218,  0.0141, -0.1106,  0.1512,  0.0277,  0.0161,\n",
       "            -0.0192,  0.0641, -0.0010, -0.0768, -0.0360, -0.0998, -0.0235,\n",
       "            -0.1159,  0.0227,  0.0890,  0.0639,  0.0983, -0.0657],\n",
       "           [-0.1343, -0.0460,  0.0279, -0.1091,  0.1627,  0.0286,  0.0182,\n",
       "            -0.0364,  0.0783, -0.0126, -0.0674, -0.0380, -0.0988, -0.0285,\n",
       "            -0.1164, -0.0101,  0.0868,  0.0752,  0.1009, -0.0549],\n",
       "           [-0.1297, -0.0183, -0.0110, -0.1083,  0.1506,  0.0346,  0.0289,\n",
       "            -0.0145,  0.0720, -0.0118, -0.0899, -0.0452, -0.1088, -0.0225,\n",
       "            -0.1179,  0.0075,  0.1000,  0.0584,  0.1072, -0.0669],\n",
       "           [-0.1297, -0.0354,  0.0380, -0.1234,  0.1608,  0.0337,  0.0184,\n",
       "            -0.0284,  0.0732, -0.0236, -0.0802, -0.0415, -0.0968, -0.0318,\n",
       "            -0.1106,  0.0132,  0.0954,  0.0659,  0.0963, -0.0769],\n",
       "           [-0.1367, -0.0282, -0.0030, -0.1175,  0.1600,  0.0407,  0.0144,\n",
       "            -0.0180,  0.0522,  0.0046, -0.0838, -0.0376, -0.1073, -0.0251,\n",
       "            -0.1148,  0.0050,  0.1038,  0.0662,  0.1064, -0.0581]],\n",
       "  \n",
       "          [[-0.1401, -0.0207,  0.0227, -0.1359,  0.1819,  0.0324,  0.0151,\n",
       "            -0.0242,  0.0877, -0.0090, -0.0918, -0.0335, -0.1238, -0.0397,\n",
       "            -0.1404,  0.0413,  0.0975,  0.0766,  0.1022, -0.0962],\n",
       "           [-0.1609, -0.0508,  0.0436, -0.1350,  0.1976,  0.0290,  0.0170,\n",
       "            -0.0634,  0.1014, -0.0122, -0.0743, -0.0413, -0.1252, -0.0481,\n",
       "            -0.1427,  0.0008,  0.0985,  0.1000,  0.1009, -0.0848],\n",
       "           [-0.1563, -0.0122, -0.0226, -0.1329,  0.1763,  0.0357,  0.0286,\n",
       "            -0.0248,  0.0906, -0.0182, -0.1078, -0.0525, -0.1350, -0.0414,\n",
       "            -0.1445,  0.0232,  0.1176,  0.0672,  0.1155, -0.1004],\n",
       "           [-0.1567, -0.0320,  0.0477, -0.1534,  0.1916,  0.0393,  0.0128,\n",
       "            -0.0482,  0.0937, -0.0358, -0.0952, -0.0437, -0.1229, -0.0509,\n",
       "            -0.1351,  0.0286,  0.1100,  0.0800,  0.0962, -0.1071],\n",
       "           [-0.1636, -0.0273,  0.0005, -0.1458,  0.1960,  0.0454,  0.0069,\n",
       "            -0.0254,  0.0659,  0.0041, -0.1018, -0.0408, -0.1344, -0.0463,\n",
       "            -0.1384,  0.0214,  0.1176,  0.0791,  0.1101, -0.0859]],\n",
       "  \n",
       "          [[-0.1557, -0.0166,  0.0210, -0.1520,  0.2046,  0.0280,  0.0142,\n",
       "            -0.0330,  0.1044, -0.0133, -0.0953, -0.0329, -0.1378, -0.0539,\n",
       "            -0.1558,  0.0624,  0.0998,  0.0842,  0.0970, -0.1141],\n",
       "           [-0.1769, -0.0521,  0.0499, -0.1487,  0.2202,  0.0275,  0.0158,\n",
       "            -0.0843,  0.1139, -0.0169, -0.0771, -0.0384, -0.1440, -0.0615,\n",
       "            -0.1567,  0.0129,  0.1028,  0.1112,  0.0938, -0.1063],\n",
       "           [-0.1754, -0.0045, -0.0318, -0.1466,  0.1934,  0.0350,  0.0280,\n",
       "            -0.0283,  0.1041, -0.0250, -0.1194, -0.0549, -0.1525, -0.0655,\n",
       "            -0.1542,  0.0374,  0.1226,  0.0740,  0.1182, -0.1213],\n",
       "           [-0.1731, -0.0268,  0.0545, -0.1709,  0.2132,  0.0397,  0.0116,\n",
       "            -0.0589,  0.1128, -0.0497, -0.1022, -0.0444, -0.1335, -0.0704,\n",
       "            -0.1487,  0.0481,  0.1157,  0.0883,  0.0936, -0.1288],\n",
       "           [-0.1794, -0.0226,  0.0006, -0.1607,  0.2177,  0.0463,  0.0014,\n",
       "            -0.0300,  0.0743,  0.0021, -0.1164, -0.0413, -0.1526, -0.0600,\n",
       "            -0.1488,  0.0378,  0.1270,  0.0846,  0.1049, -0.1034]],\n",
       "  \n",
       "          [[-0.1619, -0.0114,  0.0131, -0.1603,  0.2181,  0.0221,  0.0159,\n",
       "            -0.0376,  0.1129, -0.0135, -0.0965, -0.0310, -0.1474, -0.0618,\n",
       "            -0.1626,  0.0802,  0.1019,  0.0861,  0.0911, -0.1253],\n",
       "           [-0.1844, -0.0454,  0.0504, -0.1618,  0.2319,  0.0237,  0.0163,\n",
       "            -0.1026,  0.1246, -0.0212, -0.0763, -0.0360, -0.1536, -0.0701,\n",
       "            -0.1711,  0.0190,  0.1025,  0.1205,  0.0902, -0.1202],\n",
       "           [-0.1873,  0.0057, -0.0368, -0.1566,  0.2066,  0.0365,  0.0290,\n",
       "            -0.0342,  0.1134, -0.0335, -0.1240, -0.0577, -0.1617, -0.0773,\n",
       "            -0.1594,  0.0499,  0.1252,  0.0820,  0.1161, -0.1358],\n",
       "           [-0.1807, -0.0168,  0.0550, -0.1817,  0.2235,  0.0379,  0.0080,\n",
       "            -0.0683,  0.1268, -0.0608, -0.1073, -0.0451, -0.1413, -0.0858,\n",
       "            -0.1584,  0.0548,  0.1189,  0.0926,  0.0889, -0.1407],\n",
       "           [-0.1894, -0.0136,  0.0032, -0.1709,  0.2295,  0.0440,  0.0006,\n",
       "            -0.0289,  0.0819, -0.0012, -0.1201, -0.0388, -0.1588, -0.0730,\n",
       "            -0.1496,  0.0495,  0.1318,  0.0900,  0.1015, -0.1124]],\n",
       "  \n",
       "          [[-0.1677, -0.0066,  0.0133, -0.1609,  0.2304,  0.0171,  0.0182,\n",
       "            -0.0357,  0.1230, -0.0174, -0.1034, -0.0296, -0.1516, -0.0743,\n",
       "            -0.1658,  0.0915,  0.1041,  0.0880,  0.0900, -0.1287],\n",
       "           [-0.1858, -0.0418,  0.0509, -0.1694,  0.2381,  0.0218,  0.0180,\n",
       "            -0.1109,  0.1342, -0.0248, -0.0752, -0.0315, -0.1576, -0.0775,\n",
       "            -0.1766,  0.0279,  0.1044,  0.1255,  0.0848, -0.1292],\n",
       "           [-0.1936,  0.0172, -0.0378, -0.1658,  0.2152,  0.0395,  0.0323,\n",
       "            -0.0375,  0.1236, -0.0425, -0.1219, -0.0572, -0.1645, -0.0854,\n",
       "            -0.1619,  0.0601,  0.1242,  0.0901,  0.1146, -0.1457],\n",
       "           [-0.1868, -0.0035,  0.0535, -0.1961,  0.2293,  0.0413,  0.0113,\n",
       "            -0.0770,  0.1358, -0.0660, -0.1109, -0.0452, -0.1477, -0.0959,\n",
       "            -0.1622,  0.0643,  0.1183,  0.1022,  0.0892, -0.1514],\n",
       "           [-0.1971, -0.0070, -0.0001, -0.1825,  0.2361,  0.0427,  0.0006,\n",
       "            -0.0278,  0.0896, -0.0059, -0.1171, -0.0360, -0.1574, -0.0809,\n",
       "            -0.1533,  0.0604,  0.1360,  0.0953,  0.0976, -0.1184]],\n",
       "  \n",
       "          [[-0.1693, -0.0032,  0.0139, -0.1687,  0.2358,  0.0133,  0.0233,\n",
       "            -0.0405,  0.1348, -0.0255, -0.1034, -0.0360, -0.1513, -0.0787,\n",
       "            -0.1729,  0.0975,  0.1073,  0.0935,  0.0863, -0.1318],\n",
       "           [-0.1884, -0.0398,  0.0476, -0.1718,  0.2407,  0.0188,  0.0182,\n",
       "            -0.1196,  0.1419, -0.0291, -0.0751, -0.0283, -0.1599, -0.0823,\n",
       "            -0.1803,  0.0329,  0.1041,  0.1276,  0.0791, -0.1340],\n",
       "           [-0.1991,  0.0207, -0.0435, -0.1683,  0.2215,  0.0387,  0.0325,\n",
       "            -0.0375,  0.1246, -0.0456, -0.1264, -0.0592, -0.1695, -0.0901,\n",
       "            -0.1605,  0.0685,  0.1232,  0.0893,  0.1122, -0.1528],\n",
       "           [-0.1890,  0.0016,  0.0494, -0.2024,  0.2392,  0.0453,  0.0122,\n",
       "            -0.0828,  0.1463, -0.0761, -0.1137, -0.0443, -0.1522, -0.1005,\n",
       "            -0.1602,  0.0717,  0.1199,  0.1076,  0.0844, -0.1587],\n",
       "           [-0.1986, -0.0050, -0.0009, -0.1878,  0.2425,  0.0402,  0.0010,\n",
       "            -0.0263,  0.0956, -0.0102, -0.1213, -0.0365, -0.1619, -0.0859,\n",
       "            -0.1561,  0.0679,  0.1354,  0.0956,  0.0949, -0.1247]],\n",
       "  \n",
       "          [[-0.1691, -0.0010,  0.0168, -0.1659,  0.2435,  0.0100,  0.0232,\n",
       "            -0.0432,  0.1401, -0.0306, -0.1067, -0.0414, -0.1567, -0.0830,\n",
       "            -0.1756,  0.0995,  0.1048,  0.0925,  0.0816, -0.1349],\n",
       "           [-0.1878, -0.0374,  0.0432, -0.1727,  0.2395,  0.0161,  0.0211,\n",
       "            -0.1188,  0.1470, -0.0333, -0.0726, -0.0229, -0.1571, -0.0871,\n",
       "            -0.1818,  0.0419,  0.1052,  0.1280,  0.0773, -0.1374],\n",
       "           [-0.2026,  0.0251, -0.0479, -0.1729,  0.2248,  0.0406,  0.0328,\n",
       "            -0.0374,  0.1254, -0.0474, -0.1291, -0.0609, -0.1689, -0.0919,\n",
       "            -0.1601,  0.0740,  0.1223,  0.0945,  0.1105, -0.1574],\n",
       "           [-0.1905,  0.0060,  0.0425, -0.2039,  0.2430,  0.0412,  0.0114,\n",
       "            -0.0881,  0.1512, -0.0803, -0.1150, -0.0436, -0.1522, -0.1083,\n",
       "            -0.1605,  0.0762,  0.1188,  0.1069,  0.0822, -0.1601],\n",
       "           [-0.1986, -0.0029, -0.0024, -0.1876,  0.2493,  0.0378,  0.0048,\n",
       "            -0.0319,  0.0969, -0.0097, -0.1294, -0.0392, -0.1686, -0.0868,\n",
       "            -0.1554,  0.0740,  0.1353,  0.0954,  0.0894, -0.1262]],\n",
       "  \n",
       "          [[-0.1698,  0.0012,  0.0147, -0.1637,  0.2492,  0.0055,  0.0228,\n",
       "            -0.0458,  0.1401, -0.0335, -0.1069, -0.0478, -0.1589, -0.0859,\n",
       "            -0.1746,  0.1049,  0.1029,  0.0900,  0.0791, -0.1363],\n",
       "           [-0.1834, -0.0369,  0.0444, -0.1772,  0.2446,  0.0163,  0.0214,\n",
       "            -0.1230,  0.1492, -0.0318, -0.0768, -0.0260, -0.1613, -0.0893,\n",
       "            -0.1819,  0.0442,  0.1055,  0.1290,  0.0759, -0.1394],\n",
       "           [-0.2042,  0.0266, -0.0517, -0.1751,  0.2291,  0.0405,  0.0350,\n",
       "            -0.0408,  0.1226, -0.0499, -0.1281, -0.0611, -0.1705, -0.0888,\n",
       "            -0.1599,  0.0780,  0.1221,  0.0935,  0.1102, -0.1607],\n",
       "           [-0.1914,  0.0075,  0.0356, -0.2034,  0.2501,  0.0382,  0.0132,\n",
       "            -0.0902,  0.1550, -0.0845, -0.1167, -0.0455, -0.1519, -0.1149,\n",
       "            -0.1580,  0.0829,  0.1197,  0.1055,  0.0810, -0.1610],\n",
       "           [-0.2013,  0.0014, -0.0073, -0.1902,  0.2504,  0.0359,  0.0066,\n",
       "            -0.0324,  0.1000, -0.0098, -0.1264, -0.0380, -0.1641, -0.0913,\n",
       "            -0.1550,  0.0761,  0.1373,  0.0979,  0.0892, -0.1259]],\n",
       "  \n",
       "          [[-0.1745,  0.0038,  0.0075, -0.1598,  0.2476,  0.0066,  0.0220,\n",
       "            -0.0462,  0.1390, -0.0412, -0.1066, -0.0442, -0.1555, -0.0901,\n",
       "            -0.1719,  0.1084,  0.1038,  0.0912,  0.0795, -0.1389],\n",
       "           [-0.1849, -0.0393,  0.0432, -0.1752,  0.2459,  0.0149,  0.0231,\n",
       "            -0.1223,  0.1508, -0.0340, -0.0774, -0.0241, -0.1611, -0.0914,\n",
       "            -0.1804,  0.0469,  0.1031,  0.1290,  0.0743, -0.1422],\n",
       "           [-0.2036,  0.0278, -0.0563, -0.1772,  0.2305,  0.0408,  0.0350,\n",
       "            -0.0415,  0.1208, -0.0537, -0.1269, -0.0611, -0.1725, -0.0870,\n",
       "            -0.1618,  0.0792,  0.1207,  0.0920,  0.1118, -0.1641],\n",
       "           [-0.1913,  0.0060,  0.0316, -0.2035,  0.2524,  0.0353,  0.0161,\n",
       "            -0.0891,  0.1571, -0.0905, -0.1160, -0.0473, -0.1477, -0.1207,\n",
       "            -0.1587,  0.0896,  0.1213,  0.1030,  0.0838, -0.1622],\n",
       "           [-0.1999,  0.0029, -0.0105, -0.1903,  0.2516,  0.0345,  0.0071,\n",
       "            -0.0316,  0.1014, -0.0095, -0.1275, -0.0384, -0.1658, -0.0921,\n",
       "            -0.1549,  0.0766,  0.1375,  0.0979,  0.0898, -0.1275]]],\n",
       "         grad_fn=<CatBackward>)])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tst_input.clone()\n",
    "z = tst_model(x)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tst_output.clone()\n",
    "loss = F.nll_loss(z[0], y)\n",
    "loss.backward()\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0948, -0.0363,  0.0216,  ...,  0.0825,  0.0630,  0.0566],\n",
       "        [-0.0019,  0.0985, -0.0828,  ..., -0.0157,  0.0701,  0.0889],\n",
       "        [ 0.0453, -0.0627, -0.0027,  ..., -0.0360,  0.0525,  0.0500],\n",
       "        ...,\n",
       "        [ 0.0754, -0.0676,  0.0044,  ..., -0.0547,  0.0707, -0.0865],\n",
       "        [-0.0077, -0.0351, -0.0692,  ..., -0.0755,  0.0336, -0.0864],\n",
       "        [ 0.0905, -0.0593, -0.0061,  ..., -0.0371,  0.0576, -0.0191]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_model[0].rnns[0].module._parameters['weight_hh_l0_raw']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNDropout(nn.Module):\n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__()\n",
    "        self.p=p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.training or not self.p: return x\n",
    "        m = dropout_mask(x.data, (1, x.size(1), x.size(2)), self.p)\n",
    "        return m * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repackage_var1(h):\n",
    "    \"Detaches h from its history.\"\n",
    "    return h.detach() if type(h) == torch.Tensor else tuple(repackage_var(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCore(nn.Module):\n",
    "    \"AWD-LSTM/QRNN inspired by https://arxiv.org/abs/1708.02182\"\n",
    "\n",
    "    initrange=0.1\n",
    "\n",
    "    def __init__(self, vocab_sz, emb_sz, n_hid, n_layers, pad_token, bidir=False,\n",
    "                 dropouth=0.3, dropouti=0.65, dropoute=0.1, wdrop=0.5, qrnn=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.bs,self.qrnn,self.ndir = 1, qrnn,(2 if bidir else 1)\n",
    "        self.emb_sz,self.n_hid,self.n_layers,self.dropoute = emb_sz,n_hid,n_layers,dropoute\n",
    "        self.encoder = nn.Embedding(vocab_sz, emb_sz, padding_idx=pad_token)\n",
    "        self.dp_encoder = EmbeddingDropout(self.encoder)\n",
    "        if self.qrnn:\n",
    "            #Using QRNN requires cupy: https://github.com/cupy/cupy\n",
    "            from .torchqrnn.qrnn import QRNNLayer\n",
    "            self.rnns = [QRNNLayer(emb_sz if l == 0 else n_hid, (n_hid if l != n_layers - 1 else emb_sz)//self.ndir,\n",
    "                save_prev_x=True, zoneout=0, window=2 if l == 0 else 1, output_gate=True) for l in range(n_layers)]\n",
    "            if wdrop:\n",
    "                for rnn in self.rnns:\n",
    "                    rnn.linear = WeightDropout(rnn.linear, wdrop, layer_names=['weight'])\n",
    "        else:\n",
    "            self.rnns = [nn.LSTM(emb_sz if l == 0 else n_hid, (n_hid if l != n_layers - 1 else emb_sz)//self.ndir,\n",
    "                1, bidirectional=bidir) for l in range(n_layers)]\n",
    "            if wdrop: self.rnns = [WeightDropout(rnn, wdrop) for rnn in self.rnns]\n",
    "        self.rnns = torch.nn.ModuleList(self.rnns)\n",
    "        self.encoder.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.dropouti = RNNDropout(dropouti)\n",
    "        self.dropouths = nn.ModuleList([RNNDropout(dropouth) for l in range(n_layers)])\n",
    "\n",
    "    def forward(self, input):\n",
    "        sl,bs = input.size()\n",
    "        if bs!=self.bs:\n",
    "            self.bs=bs\n",
    "            self.reset()\n",
    "        emb = self.dp_encoder(input, dropout=self.dropoute if self.training else 0)\n",
    "        emb = self.dropouti(emb)\n",
    "        raw_output = emb\n",
    "        new_hidden,raw_outputs,outputs = [],[],[]\n",
    "        for l, (rnn,drop) in enumerate(zip(self.rnns, self.dropouths)):\n",
    "            #with warnings.catch_warnings():\n",
    "            #    warnings.simplefilter(\"ignore\")\n",
    "            raw_output, new_h = rnn(raw_output, self.hidden[l])\n",
    "            new_hidden.append(new_h)\n",
    "            raw_outputs.append(raw_output)\n",
    "            if l != self.n_layers - 1: raw_output = drop(raw_output)\n",
    "            outputs.append(raw_output)\n",
    "        self.hidden = repackage_var1(new_hidden)\n",
    "        return raw_outputs, outputs\n",
    "\n",
    "    def one_hidden(self, l):\n",
    "        nh = (self.n_hid if l != self.n_layers - 1 else self.emb_sz)//self.ndir\n",
    "        return self.weights.new(self.ndir, self.bs, nh).zero_()\n",
    "\n",
    "    def reset(self):\n",
    "        [r.reset() for r in self.rnns if hasattr(r, 'reset')]\n",
    "        self.weights = next(self.parameters()).data\n",
    "        if self.qrnn: self.hidden = [self.one_hidden(l) for l in range(self.n_layers)]\n",
    "        else: self.hidden = [(self.one_hidden(l), self.one_hidden(l)) for l in range(self.n_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearDecoder1(nn.Module):\n",
    "    \"To go on top of a RNN_Core module\"\n",
    "    \n",
    "    initrange=0.1\n",
    "    \n",
    "    def __init__(self, n_out, n_hid, dropout, tie_encoder=None, bias=True):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Linear(n_hid, n_out, bias=bias)\n",
    "        self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.dropout = RNNDropout(dropout)\n",
    "        if bias: self.decoder.bias.data.zero_()\n",
    "        if tie_encoder: self.decoder.weight = tie_encoder.weight\n",
    "\n",
    "    def forward(self, input):\n",
    "        raw_outputs, outputs = input\n",
    "        output = self.dropout(outputs[-1])\n",
    "        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n",
    "        return decoded, raw_outputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialRNN1(nn.Sequential):\n",
    "    def reset(self):\n",
    "        for c in self.children():\n",
    "            if hasattr(c, 'reset'): c.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language_model1(vocab_sz, emb_sz, n_hid, n_layers, pad_token, tie_weights=True, qrnn=False, bias=True,\n",
    "                 dropout=0.4, dropouth=0.3, dropouti=0.5, dropoute=0.1, wdrop=0.5):\n",
    "    \"To create a full AWD-LSTM\"\n",
    "    rnn_enc = RNNCore(vocab_sz, emb_sz, n_hid=n_hid, n_layers=n_layers, pad_token=pad_token, qrnn=qrnn,\n",
    "                 dropouth=dropouth, dropouti=dropouti, dropoute=dropoute, wdrop=wdrop)\n",
    "    enc = rnn_enc.encoder if tie_weights else None\n",
    "    return SequentialRNN1(rnn_enc, LinearDecoder1(vocab_sz, emb_sz, dropout, tie_encoder=enc, bias=bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new model has weights that are organized a bit differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_parameters1 = {}\n",
    "for n,p in save_parameters.items(): \n",
    "    if 'weight_hh_l0' not in n and n!='0.encoder_with_dropout.embed.weight':  save_parameters1[n] = p.clone()\n",
    "    elif n=='0.encoder_with_dropout.embed.weight': save_parameters1['0.dp_encoder.embed.weight'] = p.clone()\n",
    "    else: \n",
    "        save_parameters1[n[:-4]] = p.clone()\n",
    "        splits = n.split('.')\n",
    "        splits.remove(splits[-2])\n",
    "        n1 = '.'.join(splits)\n",
    "        save_parameters1[n1] = p.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_model = get_language_model1(500, 20, 100, 2, 0)\n",
    "tst_model.load_state_dict(save_parameters1)\n",
    "opt = optim.SGD(tst_model.parameters(), lr=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x267b3a7b390>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0044, -0.0150, -0.0099,  ...,  0.0240,  0.0212,  0.0210],\n",
       "         [ 0.0352,  0.0143,  0.0101,  ...,  0.0142,  0.0458,  0.0124],\n",
       "         [ 0.0028,  0.0098,  0.0056,  ...,  0.0348,  0.0142,  0.0040],\n",
       "         ...,\n",
       "         [ 0.0062,  0.0257, -0.0043,  ...,  0.0987,  0.0324,  0.0284],\n",
       "         [ 0.0079, -0.0157,  0.0004,  ...,  0.0660,  0.0977,  0.0812],\n",
       "         [-0.0418, -0.0244, -0.0035,  ...,  0.0666,  0.0294,  0.0278]],\n",
       "        grad_fn=<ThAddmmBackward>),\n",
       " [tensor([[[-0.0039,  0.0119,  0.0085,  ..., -0.0195, -0.0137, -0.0333],\n",
       "           [-0.0123,  0.0093,  0.0111,  ..., -0.0242, -0.0010, -0.0357],\n",
       "           [-0.0069,  0.0100,  0.0128,  ..., -0.0192, -0.0096, -0.0339],\n",
       "           [-0.0044,  0.0128,  0.0127,  ..., -0.0161, -0.0135, -0.0358],\n",
       "           [-0.0102,  0.0170,  0.0098,  ..., -0.0186, -0.0101, -0.0359]],\n",
       "  \n",
       "          [[-0.0081,  0.0124,  0.0230,  ..., -0.0372, -0.0193, -0.0457],\n",
       "           [-0.0096,  0.0081,  0.0214,  ..., -0.0444, -0.0150, -0.0437],\n",
       "           [-0.0031,  0.0079,  0.0137,  ..., -0.0374, -0.0206, -0.0355],\n",
       "           [-0.0107,  0.0214,  0.0204,  ..., -0.0286, -0.0201, -0.0471],\n",
       "           [-0.0070,  0.0102,  0.0225,  ..., -0.0328, -0.0206, -0.0335]],\n",
       "  \n",
       "          [[-0.0052,  0.0131,  0.0342,  ..., -0.0450, -0.0203, -0.0359],\n",
       "           [-0.0112,  0.0148,  0.0301,  ..., -0.0480, -0.0225, -0.0482],\n",
       "           [-0.0124,  0.0196,  0.0243,  ..., -0.0367, -0.0270, -0.0408],\n",
       "           [-0.0123,  0.0277,  0.0282,  ..., -0.0353, -0.0271, -0.0518],\n",
       "           [-0.0136,  0.0295,  0.0355,  ..., -0.0390, -0.0202, -0.0480]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-0.0212,  0.0324,  0.0507,  ..., -0.0604, -0.0292, -0.0589],\n",
       "           [-0.0264,  0.0269,  0.0441,  ..., -0.0550, -0.0293, -0.0482],\n",
       "           [-0.0277,  0.0253,  0.0381,  ..., -0.0647, -0.0150, -0.0317],\n",
       "           [-0.0245,  0.0242,  0.0540,  ..., -0.0635, -0.0288, -0.0530],\n",
       "           [-0.0185,  0.0425,  0.0383,  ..., -0.0629, -0.0311, -0.0593]],\n",
       "  \n",
       "          [[-0.0284,  0.0419,  0.0565,  ..., -0.0555, -0.0305, -0.0717],\n",
       "           [-0.0275,  0.0401,  0.0431,  ..., -0.0627, -0.0207, -0.0573],\n",
       "           [-0.0343,  0.0393,  0.0452,  ..., -0.0547, -0.0256, -0.0490],\n",
       "           [-0.0270,  0.0285,  0.0502,  ..., -0.0609, -0.0276, -0.0574],\n",
       "           [-0.0257,  0.0394,  0.0454,  ..., -0.0660, -0.0280, -0.0540]],\n",
       "  \n",
       "          [[-0.0272,  0.0221,  0.0544,  ..., -0.0650, -0.0281, -0.0533],\n",
       "           [-0.0227,  0.0336,  0.0407,  ..., -0.0543, -0.0278, -0.0533],\n",
       "           [-0.0292,  0.0335,  0.0454,  ..., -0.0529, -0.0304, -0.0420],\n",
       "           [-0.0291,  0.0316,  0.0519,  ..., -0.0571, -0.0283, -0.0531],\n",
       "           [-0.0258,  0.0376,  0.0458,  ..., -0.0626, -0.0256, -0.0515]]],\n",
       "         grad_fn=<CatBackward>),\n",
       "  tensor([[[-0.0769, -0.0221,  0.0094, -0.0702,  0.0995,  0.0194,  0.0204,\n",
       "            -0.0060,  0.0416, -0.0060, -0.0538, -0.0301, -0.0601, -0.0085,\n",
       "            -0.0722,  0.0033,  0.0594,  0.0386,  0.0775, -0.0287],\n",
       "           [-0.0852, -0.0296,  0.0129, -0.0701,  0.1093,  0.0231,  0.0200,\n",
       "            -0.0109,  0.0458, -0.0095, -0.0493, -0.0280, -0.0613, -0.0094,\n",
       "            -0.0712, -0.0139,  0.0591,  0.0433,  0.0802, -0.0217],\n",
       "           [-0.0814, -0.0198, -0.0031, -0.0684,  0.1010,  0.0217,  0.0242,\n",
       "            -0.0058,  0.0454, -0.0087, -0.0586, -0.0318, -0.0660, -0.0060,\n",
       "            -0.0755, -0.0063,  0.0666,  0.0342,  0.0811, -0.0286],\n",
       "           [-0.0829, -0.0244,  0.0191, -0.0767,  0.1035,  0.0210,  0.0200,\n",
       "            -0.0102,  0.0435, -0.0116, -0.0543, -0.0296, -0.0589, -0.0098,\n",
       "            -0.0692, -0.0026,  0.0643,  0.0402,  0.0768, -0.0343],\n",
       "           [-0.0861, -0.0219, -0.0038, -0.0736,  0.1028,  0.0244,  0.0203,\n",
       "            -0.0083,  0.0352,  0.0017, -0.0547, -0.0272, -0.0612, -0.0099,\n",
       "            -0.0730, -0.0049,  0.0704,  0.0421,  0.0828, -0.0239]],\n",
       "  \n",
       "          [[-0.1194, -0.0218,  0.0141, -0.1106,  0.1512,  0.0277,  0.0161,\n",
       "            -0.0192,  0.0641, -0.0010, -0.0768, -0.0360, -0.0998, -0.0235,\n",
       "            -0.1159,  0.0227,  0.0890,  0.0639,  0.0983, -0.0657],\n",
       "           [-0.1343, -0.0460,  0.0279, -0.1091,  0.1627,  0.0286,  0.0182,\n",
       "            -0.0364,  0.0783, -0.0126, -0.0674, -0.0380, -0.0988, -0.0285,\n",
       "            -0.1164, -0.0101,  0.0868,  0.0752,  0.1009, -0.0549],\n",
       "           [-0.1297, -0.0183, -0.0110, -0.1083,  0.1506,  0.0346,  0.0289,\n",
       "            -0.0145,  0.0720, -0.0118, -0.0899, -0.0452, -0.1088, -0.0225,\n",
       "            -0.1179,  0.0075,  0.1000,  0.0584,  0.1072, -0.0669],\n",
       "           [-0.1297, -0.0354,  0.0380, -0.1234,  0.1608,  0.0337,  0.0184,\n",
       "            -0.0284,  0.0732, -0.0236, -0.0802, -0.0415, -0.0968, -0.0318,\n",
       "            -0.1106,  0.0132,  0.0954,  0.0659,  0.0963, -0.0769],\n",
       "           [-0.1367, -0.0282, -0.0030, -0.1175,  0.1600,  0.0407,  0.0144,\n",
       "            -0.0180,  0.0522,  0.0046, -0.0838, -0.0376, -0.1073, -0.0251,\n",
       "            -0.1148,  0.0050,  0.1038,  0.0662,  0.1064, -0.0581]],\n",
       "  \n",
       "          [[-0.1401, -0.0207,  0.0227, -0.1359,  0.1819,  0.0324,  0.0151,\n",
       "            -0.0242,  0.0877, -0.0090, -0.0918, -0.0335, -0.1238, -0.0397,\n",
       "            -0.1404,  0.0413,  0.0975,  0.0766,  0.1022, -0.0962],\n",
       "           [-0.1609, -0.0508,  0.0436, -0.1350,  0.1976,  0.0290,  0.0170,\n",
       "            -0.0634,  0.1014, -0.0122, -0.0743, -0.0413, -0.1252, -0.0481,\n",
       "            -0.1427,  0.0008,  0.0985,  0.1000,  0.1009, -0.0848],\n",
       "           [-0.1563, -0.0122, -0.0226, -0.1329,  0.1763,  0.0357,  0.0286,\n",
       "            -0.0248,  0.0906, -0.0182, -0.1078, -0.0525, -0.1350, -0.0414,\n",
       "            -0.1445,  0.0232,  0.1176,  0.0672,  0.1155, -0.1004],\n",
       "           [-0.1567, -0.0320,  0.0477, -0.1534,  0.1916,  0.0393,  0.0128,\n",
       "            -0.0482,  0.0937, -0.0358, -0.0952, -0.0437, -0.1229, -0.0509,\n",
       "            -0.1351,  0.0286,  0.1100,  0.0800,  0.0962, -0.1071],\n",
       "           [-0.1636, -0.0273,  0.0005, -0.1458,  0.1960,  0.0454,  0.0069,\n",
       "            -0.0254,  0.0659,  0.0041, -0.1018, -0.0408, -0.1344, -0.0463,\n",
       "            -0.1384,  0.0214,  0.1176,  0.0791,  0.1101, -0.0859]],\n",
       "  \n",
       "          [[-0.1557, -0.0166,  0.0210, -0.1520,  0.2046,  0.0280,  0.0142,\n",
       "            -0.0330,  0.1044, -0.0133, -0.0953, -0.0329, -0.1378, -0.0539,\n",
       "            -0.1558,  0.0624,  0.0998,  0.0842,  0.0970, -0.1141],\n",
       "           [-0.1769, -0.0521,  0.0499, -0.1487,  0.2202,  0.0275,  0.0158,\n",
       "            -0.0843,  0.1139, -0.0169, -0.0771, -0.0384, -0.1440, -0.0615,\n",
       "            -0.1567,  0.0129,  0.1028,  0.1112,  0.0938, -0.1063],\n",
       "           [-0.1754, -0.0045, -0.0318, -0.1466,  0.1934,  0.0350,  0.0280,\n",
       "            -0.0283,  0.1041, -0.0250, -0.1194, -0.0549, -0.1525, -0.0655,\n",
       "            -0.1542,  0.0374,  0.1226,  0.0740,  0.1182, -0.1213],\n",
       "           [-0.1731, -0.0268,  0.0545, -0.1709,  0.2132,  0.0397,  0.0116,\n",
       "            -0.0589,  0.1128, -0.0497, -0.1022, -0.0444, -0.1335, -0.0704,\n",
       "            -0.1487,  0.0481,  0.1157,  0.0883,  0.0936, -0.1288],\n",
       "           [-0.1794, -0.0226,  0.0006, -0.1607,  0.2177,  0.0463,  0.0014,\n",
       "            -0.0300,  0.0743,  0.0021, -0.1164, -0.0413, -0.1526, -0.0600,\n",
       "            -0.1488,  0.0378,  0.1270,  0.0846,  0.1049, -0.1034]],\n",
       "  \n",
       "          [[-0.1619, -0.0114,  0.0131, -0.1603,  0.2181,  0.0221,  0.0159,\n",
       "            -0.0376,  0.1129, -0.0135, -0.0965, -0.0310, -0.1474, -0.0618,\n",
       "            -0.1626,  0.0802,  0.1019,  0.0861,  0.0911, -0.1253],\n",
       "           [-0.1844, -0.0454,  0.0504, -0.1618,  0.2319,  0.0237,  0.0163,\n",
       "            -0.1026,  0.1246, -0.0212, -0.0763, -0.0360, -0.1536, -0.0701,\n",
       "            -0.1711,  0.0190,  0.1025,  0.1205,  0.0902, -0.1202],\n",
       "           [-0.1873,  0.0057, -0.0368, -0.1566,  0.2066,  0.0365,  0.0290,\n",
       "            -0.0342,  0.1134, -0.0335, -0.1240, -0.0577, -0.1617, -0.0773,\n",
       "            -0.1594,  0.0499,  0.1252,  0.0820,  0.1161, -0.1358],\n",
       "           [-0.1807, -0.0168,  0.0550, -0.1817,  0.2235,  0.0379,  0.0080,\n",
       "            -0.0683,  0.1268, -0.0608, -0.1073, -0.0451, -0.1413, -0.0858,\n",
       "            -0.1584,  0.0548,  0.1189,  0.0926,  0.0889, -0.1407],\n",
       "           [-0.1894, -0.0136,  0.0032, -0.1709,  0.2295,  0.0440,  0.0006,\n",
       "            -0.0289,  0.0819, -0.0012, -0.1201, -0.0388, -0.1588, -0.0730,\n",
       "            -0.1496,  0.0495,  0.1318,  0.0900,  0.1015, -0.1124]],\n",
       "  \n",
       "          [[-0.1677, -0.0066,  0.0133, -0.1609,  0.2304,  0.0171,  0.0182,\n",
       "            -0.0357,  0.1230, -0.0174, -0.1034, -0.0296, -0.1516, -0.0743,\n",
       "            -0.1658,  0.0915,  0.1041,  0.0880,  0.0900, -0.1287],\n",
       "           [-0.1858, -0.0418,  0.0509, -0.1694,  0.2381,  0.0218,  0.0180,\n",
       "            -0.1109,  0.1342, -0.0248, -0.0752, -0.0315, -0.1576, -0.0775,\n",
       "            -0.1766,  0.0279,  0.1044,  0.1255,  0.0848, -0.1292],\n",
       "           [-0.1936,  0.0172, -0.0378, -0.1658,  0.2152,  0.0395,  0.0323,\n",
       "            -0.0375,  0.1236, -0.0425, -0.1219, -0.0572, -0.1645, -0.0854,\n",
       "            -0.1619,  0.0601,  0.1242,  0.0901,  0.1146, -0.1457],\n",
       "           [-0.1868, -0.0035,  0.0535, -0.1961,  0.2293,  0.0413,  0.0113,\n",
       "            -0.0770,  0.1358, -0.0660, -0.1109, -0.0452, -0.1477, -0.0959,\n",
       "            -0.1622,  0.0643,  0.1183,  0.1022,  0.0892, -0.1514],\n",
       "           [-0.1971, -0.0070, -0.0001, -0.1825,  0.2361,  0.0427,  0.0006,\n",
       "            -0.0278,  0.0896, -0.0059, -0.1171, -0.0360, -0.1574, -0.0809,\n",
       "            -0.1533,  0.0604,  0.1360,  0.0953,  0.0976, -0.1184]],\n",
       "  \n",
       "          [[-0.1693, -0.0032,  0.0139, -0.1687,  0.2358,  0.0133,  0.0233,\n",
       "            -0.0405,  0.1348, -0.0255, -0.1034, -0.0360, -0.1513, -0.0787,\n",
       "            -0.1729,  0.0975,  0.1073,  0.0935,  0.0863, -0.1318],\n",
       "           [-0.1884, -0.0398,  0.0476, -0.1718,  0.2407,  0.0188,  0.0182,\n",
       "            -0.1196,  0.1419, -0.0291, -0.0751, -0.0283, -0.1599, -0.0823,\n",
       "            -0.1803,  0.0329,  0.1041,  0.1276,  0.0791, -0.1340],\n",
       "           [-0.1991,  0.0207, -0.0435, -0.1683,  0.2215,  0.0387,  0.0325,\n",
       "            -0.0375,  0.1246, -0.0456, -0.1264, -0.0592, -0.1695, -0.0901,\n",
       "            -0.1605,  0.0685,  0.1232,  0.0893,  0.1122, -0.1528],\n",
       "           [-0.1890,  0.0016,  0.0494, -0.2024,  0.2392,  0.0453,  0.0122,\n",
       "            -0.0828,  0.1463, -0.0761, -0.1137, -0.0443, -0.1522, -0.1005,\n",
       "            -0.1602,  0.0717,  0.1199,  0.1076,  0.0844, -0.1587],\n",
       "           [-0.1986, -0.0050, -0.0009, -0.1878,  0.2425,  0.0402,  0.0010,\n",
       "            -0.0263,  0.0956, -0.0102, -0.1213, -0.0365, -0.1619, -0.0859,\n",
       "            -0.1561,  0.0679,  0.1354,  0.0956,  0.0949, -0.1247]],\n",
       "  \n",
       "          [[-0.1691, -0.0010,  0.0168, -0.1659,  0.2435,  0.0100,  0.0232,\n",
       "            -0.0432,  0.1401, -0.0306, -0.1067, -0.0414, -0.1567, -0.0830,\n",
       "            -0.1756,  0.0995,  0.1048,  0.0925,  0.0816, -0.1349],\n",
       "           [-0.1878, -0.0374,  0.0432, -0.1727,  0.2395,  0.0161,  0.0211,\n",
       "            -0.1188,  0.1470, -0.0333, -0.0726, -0.0229, -0.1571, -0.0871,\n",
       "            -0.1818,  0.0419,  0.1052,  0.1280,  0.0773, -0.1374],\n",
       "           [-0.2026,  0.0251, -0.0479, -0.1729,  0.2248,  0.0406,  0.0328,\n",
       "            -0.0374,  0.1254, -0.0474, -0.1291, -0.0609, -0.1689, -0.0919,\n",
       "            -0.1601,  0.0740,  0.1223,  0.0945,  0.1105, -0.1574],\n",
       "           [-0.1905,  0.0060,  0.0425, -0.2039,  0.2430,  0.0412,  0.0114,\n",
       "            -0.0881,  0.1512, -0.0803, -0.1150, -0.0436, -0.1522, -0.1083,\n",
       "            -0.1605,  0.0762,  0.1188,  0.1069,  0.0822, -0.1601],\n",
       "           [-0.1986, -0.0029, -0.0024, -0.1876,  0.2493,  0.0378,  0.0048,\n",
       "            -0.0319,  0.0969, -0.0097, -0.1294, -0.0392, -0.1686, -0.0868,\n",
       "            -0.1554,  0.0740,  0.1353,  0.0954,  0.0894, -0.1262]],\n",
       "  \n",
       "          [[-0.1698,  0.0012,  0.0147, -0.1637,  0.2492,  0.0055,  0.0228,\n",
       "            -0.0458,  0.1401, -0.0335, -0.1069, -0.0478, -0.1589, -0.0859,\n",
       "            -0.1746,  0.1049,  0.1029,  0.0900,  0.0791, -0.1363],\n",
       "           [-0.1834, -0.0369,  0.0444, -0.1772,  0.2446,  0.0163,  0.0214,\n",
       "            -0.1230,  0.1492, -0.0318, -0.0768, -0.0260, -0.1613, -0.0893,\n",
       "            -0.1819,  0.0442,  0.1055,  0.1290,  0.0759, -0.1394],\n",
       "           [-0.2042,  0.0266, -0.0517, -0.1751,  0.2291,  0.0405,  0.0350,\n",
       "            -0.0408,  0.1226, -0.0499, -0.1281, -0.0611, -0.1705, -0.0888,\n",
       "            -0.1599,  0.0780,  0.1221,  0.0935,  0.1102, -0.1607],\n",
       "           [-0.1914,  0.0075,  0.0356, -0.2034,  0.2501,  0.0382,  0.0132,\n",
       "            -0.0902,  0.1550, -0.0845, -0.1167, -0.0455, -0.1519, -0.1149,\n",
       "            -0.1580,  0.0829,  0.1197,  0.1055,  0.0810, -0.1610],\n",
       "           [-0.2013,  0.0014, -0.0073, -0.1902,  0.2504,  0.0359,  0.0066,\n",
       "            -0.0324,  0.1000, -0.0098, -0.1264, -0.0380, -0.1641, -0.0913,\n",
       "            -0.1550,  0.0761,  0.1373,  0.0979,  0.0892, -0.1259]],\n",
       "  \n",
       "          [[-0.1745,  0.0038,  0.0075, -0.1598,  0.2476,  0.0066,  0.0220,\n",
       "            -0.0462,  0.1390, -0.0412, -0.1066, -0.0442, -0.1555, -0.0901,\n",
       "            -0.1719,  0.1084,  0.1038,  0.0912,  0.0795, -0.1389],\n",
       "           [-0.1849, -0.0393,  0.0432, -0.1752,  0.2459,  0.0149,  0.0231,\n",
       "            -0.1223,  0.1508, -0.0340, -0.0774, -0.0241, -0.1611, -0.0914,\n",
       "            -0.1804,  0.0469,  0.1031,  0.1290,  0.0743, -0.1422],\n",
       "           [-0.2036,  0.0278, -0.0563, -0.1772,  0.2305,  0.0408,  0.0350,\n",
       "            -0.0415,  0.1208, -0.0537, -0.1269, -0.0611, -0.1725, -0.0870,\n",
       "            -0.1618,  0.0792,  0.1207,  0.0920,  0.1118, -0.1641],\n",
       "           [-0.1913,  0.0060,  0.0316, -0.2035,  0.2524,  0.0353,  0.0161,\n",
       "            -0.0891,  0.1571, -0.0905, -0.1160, -0.0473, -0.1477, -0.1207,\n",
       "            -0.1587,  0.0896,  0.1213,  0.1030,  0.0838, -0.1622],\n",
       "           [-0.1999,  0.0029, -0.0105, -0.1903,  0.2516,  0.0345,  0.0071,\n",
       "            -0.0316,  0.1014, -0.0095, -0.1275, -0.0384, -0.1658, -0.0921,\n",
       "            -0.1549,  0.0766,  0.1375,  0.0979,  0.0898, -0.1275]]],\n",
       "         grad_fn=<CatBackward>)],\n",
       " [tensor([[[-0.0056,  0.0171,  0.0000,  ..., -0.0279, -0.0195, -0.0476],\n",
       "           [-0.0175,  0.0133,  0.0000,  ..., -0.0346, -0.0015, -0.0000],\n",
       "           [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0137, -0.0000],\n",
       "           [-0.0063,  0.0183,  0.0181,  ..., -0.0230, -0.0000, -0.0511],\n",
       "           [-0.0146,  0.0242,  0.0140,  ..., -0.0266, -0.0000, -0.0513]],\n",
       "  \n",
       "          [[-0.0116,  0.0178,  0.0000,  ..., -0.0532, -0.0276, -0.0653],\n",
       "           [-0.0137,  0.0116,  0.0000,  ..., -0.0634, -0.0214, -0.0000],\n",
       "           [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0295, -0.0000],\n",
       "           [-0.0153,  0.0305,  0.0292,  ..., -0.0408, -0.0000, -0.0672],\n",
       "           [-0.0100,  0.0146,  0.0321,  ..., -0.0468, -0.0000, -0.0478]],\n",
       "  \n",
       "          [[-0.0075,  0.0188,  0.0000,  ..., -0.0643, -0.0291, -0.0513],\n",
       "           [-0.0160,  0.0212,  0.0000,  ..., -0.0686, -0.0321, -0.0000],\n",
       "           [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0385, -0.0000],\n",
       "           [-0.0175,  0.0395,  0.0403,  ..., -0.0504, -0.0000, -0.0740],\n",
       "           [-0.0194,  0.0422,  0.0507,  ..., -0.0558, -0.0000, -0.0686]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-0.0303,  0.0463,  0.0000,  ..., -0.0863, -0.0417, -0.0842],\n",
       "           [-0.0378,  0.0384,  0.0000,  ..., -0.0786, -0.0418, -0.0000],\n",
       "           [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0215, -0.0000],\n",
       "           [-0.0350,  0.0345,  0.0771,  ..., -0.0906, -0.0000, -0.0756],\n",
       "           [-0.0264,  0.0608,  0.0546,  ..., -0.0899, -0.0000, -0.0847]],\n",
       "  \n",
       "          [[-0.0406,  0.0599,  0.0000,  ..., -0.0793, -0.0436, -0.1025],\n",
       "           [-0.0393,  0.0574,  0.0000,  ..., -0.0896, -0.0295, -0.0000],\n",
       "           [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0366, -0.0000],\n",
       "           [-0.0385,  0.0407,  0.0717,  ..., -0.0870, -0.0000, -0.0820],\n",
       "           [-0.0367,  0.0563,  0.0649,  ..., -0.0943, -0.0000, -0.0772]],\n",
       "  \n",
       "          [[-0.0388,  0.0316,  0.0000,  ..., -0.0928, -0.0401, -0.0761],\n",
       "           [-0.0324,  0.0480,  0.0000,  ..., -0.0775, -0.0397, -0.0000],\n",
       "           [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0435, -0.0000],\n",
       "           [-0.0415,  0.0452,  0.0741,  ..., -0.0816, -0.0000, -0.0759],\n",
       "           [-0.0369,  0.0537,  0.0655,  ..., -0.0894, -0.0000, -0.0736]]],\n",
       "         grad_fn=<ThMulBackward>),\n",
       "  tensor([[[-0.0769, -0.0221,  0.0094, -0.0702,  0.0995,  0.0194,  0.0204,\n",
       "            -0.0060,  0.0416, -0.0060, -0.0538, -0.0301, -0.0601, -0.0085,\n",
       "            -0.0722,  0.0033,  0.0594,  0.0386,  0.0775, -0.0287],\n",
       "           [-0.0852, -0.0296,  0.0129, -0.0701,  0.1093,  0.0231,  0.0200,\n",
       "            -0.0109,  0.0458, -0.0095, -0.0493, -0.0280, -0.0613, -0.0094,\n",
       "            -0.0712, -0.0139,  0.0591,  0.0433,  0.0802, -0.0217],\n",
       "           [-0.0814, -0.0198, -0.0031, -0.0684,  0.1010,  0.0217,  0.0242,\n",
       "            -0.0058,  0.0454, -0.0087, -0.0586, -0.0318, -0.0660, -0.0060,\n",
       "            -0.0755, -0.0063,  0.0666,  0.0342,  0.0811, -0.0286],\n",
       "           [-0.0829, -0.0244,  0.0191, -0.0767,  0.1035,  0.0210,  0.0200,\n",
       "            -0.0102,  0.0435, -0.0116, -0.0543, -0.0296, -0.0589, -0.0098,\n",
       "            -0.0692, -0.0026,  0.0643,  0.0402,  0.0768, -0.0343],\n",
       "           [-0.0861, -0.0219, -0.0038, -0.0736,  0.1028,  0.0244,  0.0203,\n",
       "            -0.0083,  0.0352,  0.0017, -0.0547, -0.0272, -0.0612, -0.0099,\n",
       "            -0.0730, -0.0049,  0.0704,  0.0421,  0.0828, -0.0239]],\n",
       "  \n",
       "          [[-0.1194, -0.0218,  0.0141, -0.1106,  0.1512,  0.0277,  0.0161,\n",
       "            -0.0192,  0.0641, -0.0010, -0.0768, -0.0360, -0.0998, -0.0235,\n",
       "            -0.1159,  0.0227,  0.0890,  0.0639,  0.0983, -0.0657],\n",
       "           [-0.1343, -0.0460,  0.0279, -0.1091,  0.1627,  0.0286,  0.0182,\n",
       "            -0.0364,  0.0783, -0.0126, -0.0674, -0.0380, -0.0988, -0.0285,\n",
       "            -0.1164, -0.0101,  0.0868,  0.0752,  0.1009, -0.0549],\n",
       "           [-0.1297, -0.0183, -0.0110, -0.1083,  0.1506,  0.0346,  0.0289,\n",
       "            -0.0145,  0.0720, -0.0118, -0.0899, -0.0452, -0.1088, -0.0225,\n",
       "            -0.1179,  0.0075,  0.1000,  0.0584,  0.1072, -0.0669],\n",
       "           [-0.1297, -0.0354,  0.0380, -0.1234,  0.1608,  0.0337,  0.0184,\n",
       "            -0.0284,  0.0732, -0.0236, -0.0802, -0.0415, -0.0968, -0.0318,\n",
       "            -0.1106,  0.0132,  0.0954,  0.0659,  0.0963, -0.0769],\n",
       "           [-0.1367, -0.0282, -0.0030, -0.1175,  0.1600,  0.0407,  0.0144,\n",
       "            -0.0180,  0.0522,  0.0046, -0.0838, -0.0376, -0.1073, -0.0251,\n",
       "            -0.1148,  0.0050,  0.1038,  0.0662,  0.1064, -0.0581]],\n",
       "  \n",
       "          [[-0.1401, -0.0207,  0.0227, -0.1359,  0.1819,  0.0324,  0.0151,\n",
       "            -0.0242,  0.0877, -0.0090, -0.0918, -0.0335, -0.1238, -0.0397,\n",
       "            -0.1404,  0.0413,  0.0975,  0.0766,  0.1022, -0.0962],\n",
       "           [-0.1609, -0.0508,  0.0436, -0.1350,  0.1976,  0.0290,  0.0170,\n",
       "            -0.0634,  0.1014, -0.0122, -0.0743, -0.0413, -0.1252, -0.0481,\n",
       "            -0.1427,  0.0008,  0.0985,  0.1000,  0.1009, -0.0848],\n",
       "           [-0.1563, -0.0122, -0.0226, -0.1329,  0.1763,  0.0357,  0.0286,\n",
       "            -0.0248,  0.0906, -0.0182, -0.1078, -0.0525, -0.1350, -0.0414,\n",
       "            -0.1445,  0.0232,  0.1176,  0.0672,  0.1155, -0.1004],\n",
       "           [-0.1567, -0.0320,  0.0477, -0.1534,  0.1916,  0.0393,  0.0128,\n",
       "            -0.0482,  0.0937, -0.0358, -0.0952, -0.0437, -0.1229, -0.0509,\n",
       "            -0.1351,  0.0286,  0.1100,  0.0800,  0.0962, -0.1071],\n",
       "           [-0.1636, -0.0273,  0.0005, -0.1458,  0.1960,  0.0454,  0.0069,\n",
       "            -0.0254,  0.0659,  0.0041, -0.1018, -0.0408, -0.1344, -0.0463,\n",
       "            -0.1384,  0.0214,  0.1176,  0.0791,  0.1101, -0.0859]],\n",
       "  \n",
       "          [[-0.1557, -0.0166,  0.0210, -0.1520,  0.2046,  0.0280,  0.0142,\n",
       "            -0.0330,  0.1044, -0.0133, -0.0953, -0.0329, -0.1378, -0.0539,\n",
       "            -0.1558,  0.0624,  0.0998,  0.0842,  0.0970, -0.1141],\n",
       "           [-0.1769, -0.0521,  0.0499, -0.1487,  0.2202,  0.0275,  0.0158,\n",
       "            -0.0843,  0.1139, -0.0169, -0.0771, -0.0384, -0.1440, -0.0615,\n",
       "            -0.1567,  0.0129,  0.1028,  0.1112,  0.0938, -0.1063],\n",
       "           [-0.1754, -0.0045, -0.0318, -0.1466,  0.1934,  0.0350,  0.0280,\n",
       "            -0.0283,  0.1041, -0.0250, -0.1194, -0.0549, -0.1525, -0.0655,\n",
       "            -0.1542,  0.0374,  0.1226,  0.0740,  0.1182, -0.1213],\n",
       "           [-0.1731, -0.0268,  0.0545, -0.1709,  0.2132,  0.0397,  0.0116,\n",
       "            -0.0589,  0.1128, -0.0497, -0.1022, -0.0444, -0.1335, -0.0704,\n",
       "            -0.1487,  0.0481,  0.1157,  0.0883,  0.0936, -0.1288],\n",
       "           [-0.1794, -0.0226,  0.0006, -0.1607,  0.2177,  0.0463,  0.0014,\n",
       "            -0.0300,  0.0743,  0.0021, -0.1164, -0.0413, -0.1526, -0.0600,\n",
       "            -0.1488,  0.0378,  0.1270,  0.0846,  0.1049, -0.1034]],\n",
       "  \n",
       "          [[-0.1619, -0.0114,  0.0131, -0.1603,  0.2181,  0.0221,  0.0159,\n",
       "            -0.0376,  0.1129, -0.0135, -0.0965, -0.0310, -0.1474, -0.0618,\n",
       "            -0.1626,  0.0802,  0.1019,  0.0861,  0.0911, -0.1253],\n",
       "           [-0.1844, -0.0454,  0.0504, -0.1618,  0.2319,  0.0237,  0.0163,\n",
       "            -0.1026,  0.1246, -0.0212, -0.0763, -0.0360, -0.1536, -0.0701,\n",
       "            -0.1711,  0.0190,  0.1025,  0.1205,  0.0902, -0.1202],\n",
       "           [-0.1873,  0.0057, -0.0368, -0.1566,  0.2066,  0.0365,  0.0290,\n",
       "            -0.0342,  0.1134, -0.0335, -0.1240, -0.0577, -0.1617, -0.0773,\n",
       "            -0.1594,  0.0499,  0.1252,  0.0820,  0.1161, -0.1358],\n",
       "           [-0.1807, -0.0168,  0.0550, -0.1817,  0.2235,  0.0379,  0.0080,\n",
       "            -0.0683,  0.1268, -0.0608, -0.1073, -0.0451, -0.1413, -0.0858,\n",
       "            -0.1584,  0.0548,  0.1189,  0.0926,  0.0889, -0.1407],\n",
       "           [-0.1894, -0.0136,  0.0032, -0.1709,  0.2295,  0.0440,  0.0006,\n",
       "            -0.0289,  0.0819, -0.0012, -0.1201, -0.0388, -0.1588, -0.0730,\n",
       "            -0.1496,  0.0495,  0.1318,  0.0900,  0.1015, -0.1124]],\n",
       "  \n",
       "          [[-0.1677, -0.0066,  0.0133, -0.1609,  0.2304,  0.0171,  0.0182,\n",
       "            -0.0357,  0.1230, -0.0174, -0.1034, -0.0296, -0.1516, -0.0743,\n",
       "            -0.1658,  0.0915,  0.1041,  0.0880,  0.0900, -0.1287],\n",
       "           [-0.1858, -0.0418,  0.0509, -0.1694,  0.2381,  0.0218,  0.0180,\n",
       "            -0.1109,  0.1342, -0.0248, -0.0752, -0.0315, -0.1576, -0.0775,\n",
       "            -0.1766,  0.0279,  0.1044,  0.1255,  0.0848, -0.1292],\n",
       "           [-0.1936,  0.0172, -0.0378, -0.1658,  0.2152,  0.0395,  0.0323,\n",
       "            -0.0375,  0.1236, -0.0425, -0.1219, -0.0572, -0.1645, -0.0854,\n",
       "            -0.1619,  0.0601,  0.1242,  0.0901,  0.1146, -0.1457],\n",
       "           [-0.1868, -0.0035,  0.0535, -0.1961,  0.2293,  0.0413,  0.0113,\n",
       "            -0.0770,  0.1358, -0.0660, -0.1109, -0.0452, -0.1477, -0.0959,\n",
       "            -0.1622,  0.0643,  0.1183,  0.1022,  0.0892, -0.1514],\n",
       "           [-0.1971, -0.0070, -0.0001, -0.1825,  0.2361,  0.0427,  0.0006,\n",
       "            -0.0278,  0.0896, -0.0059, -0.1171, -0.0360, -0.1574, -0.0809,\n",
       "            -0.1533,  0.0604,  0.1360,  0.0953,  0.0976, -0.1184]],\n",
       "  \n",
       "          [[-0.1693, -0.0032,  0.0139, -0.1687,  0.2358,  0.0133,  0.0233,\n",
       "            -0.0405,  0.1348, -0.0255, -0.1034, -0.0360, -0.1513, -0.0787,\n",
       "            -0.1729,  0.0975,  0.1073,  0.0935,  0.0863, -0.1318],\n",
       "           [-0.1884, -0.0398,  0.0476, -0.1718,  0.2407,  0.0188,  0.0182,\n",
       "            -0.1196,  0.1419, -0.0291, -0.0751, -0.0283, -0.1599, -0.0823,\n",
       "            -0.1803,  0.0329,  0.1041,  0.1276,  0.0791, -0.1340],\n",
       "           [-0.1991,  0.0207, -0.0435, -0.1683,  0.2215,  0.0387,  0.0325,\n",
       "            -0.0375,  0.1246, -0.0456, -0.1264, -0.0592, -0.1695, -0.0901,\n",
       "            -0.1605,  0.0685,  0.1232,  0.0893,  0.1122, -0.1528],\n",
       "           [-0.1890,  0.0016,  0.0494, -0.2024,  0.2392,  0.0453,  0.0122,\n",
       "            -0.0828,  0.1463, -0.0761, -0.1137, -0.0443, -0.1522, -0.1005,\n",
       "            -0.1602,  0.0717,  0.1199,  0.1076,  0.0844, -0.1587],\n",
       "           [-0.1986, -0.0050, -0.0009, -0.1878,  0.2425,  0.0402,  0.0010,\n",
       "            -0.0263,  0.0956, -0.0102, -0.1213, -0.0365, -0.1619, -0.0859,\n",
       "            -0.1561,  0.0679,  0.1354,  0.0956,  0.0949, -0.1247]],\n",
       "  \n",
       "          [[-0.1691, -0.0010,  0.0168, -0.1659,  0.2435,  0.0100,  0.0232,\n",
       "            -0.0432,  0.1401, -0.0306, -0.1067, -0.0414, -0.1567, -0.0830,\n",
       "            -0.1756,  0.0995,  0.1048,  0.0925,  0.0816, -0.1349],\n",
       "           [-0.1878, -0.0374,  0.0432, -0.1727,  0.2395,  0.0161,  0.0211,\n",
       "            -0.1188,  0.1470, -0.0333, -0.0726, -0.0229, -0.1571, -0.0871,\n",
       "            -0.1818,  0.0419,  0.1052,  0.1280,  0.0773, -0.1374],\n",
       "           [-0.2026,  0.0251, -0.0479, -0.1729,  0.2248,  0.0406,  0.0328,\n",
       "            -0.0374,  0.1254, -0.0474, -0.1291, -0.0609, -0.1689, -0.0919,\n",
       "            -0.1601,  0.0740,  0.1223,  0.0945,  0.1105, -0.1574],\n",
       "           [-0.1905,  0.0060,  0.0425, -0.2039,  0.2430,  0.0412,  0.0114,\n",
       "            -0.0881,  0.1512, -0.0803, -0.1150, -0.0436, -0.1522, -0.1083,\n",
       "            -0.1605,  0.0762,  0.1188,  0.1069,  0.0822, -0.1601],\n",
       "           [-0.1986, -0.0029, -0.0024, -0.1876,  0.2493,  0.0378,  0.0048,\n",
       "            -0.0319,  0.0969, -0.0097, -0.1294, -0.0392, -0.1686, -0.0868,\n",
       "            -0.1554,  0.0740,  0.1353,  0.0954,  0.0894, -0.1262]],\n",
       "  \n",
       "          [[-0.1698,  0.0012,  0.0147, -0.1637,  0.2492,  0.0055,  0.0228,\n",
       "            -0.0458,  0.1401, -0.0335, -0.1069, -0.0478, -0.1589, -0.0859,\n",
       "            -0.1746,  0.1049,  0.1029,  0.0900,  0.0791, -0.1363],\n",
       "           [-0.1834, -0.0369,  0.0444, -0.1772,  0.2446,  0.0163,  0.0214,\n",
       "            -0.1230,  0.1492, -0.0318, -0.0768, -0.0260, -0.1613, -0.0893,\n",
       "            -0.1819,  0.0442,  0.1055,  0.1290,  0.0759, -0.1394],\n",
       "           [-0.2042,  0.0266, -0.0517, -0.1751,  0.2291,  0.0405,  0.0350,\n",
       "            -0.0408,  0.1226, -0.0499, -0.1281, -0.0611, -0.1705, -0.0888,\n",
       "            -0.1599,  0.0780,  0.1221,  0.0935,  0.1102, -0.1607],\n",
       "           [-0.1914,  0.0075,  0.0356, -0.2034,  0.2501,  0.0382,  0.0132,\n",
       "            -0.0902,  0.1550, -0.0845, -0.1167, -0.0455, -0.1519, -0.1149,\n",
       "            -0.1580,  0.0829,  0.1197,  0.1055,  0.0810, -0.1610],\n",
       "           [-0.2013,  0.0014, -0.0073, -0.1902,  0.2504,  0.0359,  0.0066,\n",
       "            -0.0324,  0.1000, -0.0098, -0.1264, -0.0380, -0.1641, -0.0913,\n",
       "            -0.1550,  0.0761,  0.1373,  0.0979,  0.0892, -0.1259]],\n",
       "  \n",
       "          [[-0.1745,  0.0038,  0.0075, -0.1598,  0.2476,  0.0066,  0.0220,\n",
       "            -0.0462,  0.1390, -0.0412, -0.1066, -0.0442, -0.1555, -0.0901,\n",
       "            -0.1719,  0.1084,  0.1038,  0.0912,  0.0795, -0.1389],\n",
       "           [-0.1849, -0.0393,  0.0432, -0.1752,  0.2459,  0.0149,  0.0231,\n",
       "            -0.1223,  0.1508, -0.0340, -0.0774, -0.0241, -0.1611, -0.0914,\n",
       "            -0.1804,  0.0469,  0.1031,  0.1290,  0.0743, -0.1422],\n",
       "           [-0.2036,  0.0278, -0.0563, -0.1772,  0.2305,  0.0408,  0.0350,\n",
       "            -0.0415,  0.1208, -0.0537, -0.1269, -0.0611, -0.1725, -0.0870,\n",
       "            -0.1618,  0.0792,  0.1207,  0.0920,  0.1118, -0.1641],\n",
       "           [-0.1913,  0.0060,  0.0316, -0.2035,  0.2524,  0.0353,  0.0161,\n",
       "            -0.0891,  0.1571, -0.0905, -0.1160, -0.0473, -0.1477, -0.1207,\n",
       "            -0.1587,  0.0896,  0.1213,  0.1030,  0.0838, -0.1622],\n",
       "           [-0.1999,  0.0029, -0.0105, -0.1903,  0.2516,  0.0345,  0.0071,\n",
       "            -0.0316,  0.1014, -0.0095, -0.1275, -0.0384, -0.1658, -0.0921,\n",
       "            -0.1549,  0.0766,  0.1375,  0.0979,  0.0898, -0.1275]]],\n",
       "         grad_fn=<CatBackward>)])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tst_input.clone()\n",
    "z = tst_model(x)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tst_output.clone()\n",
    "loss = F.nll_loss(z[0], y)\n",
    "loss.backward()\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0948, -0.0363,  0.0216,  ...,  0.0825,  0.0630,  0.0566],\n",
       "        [-0.0019,  0.0985, -0.0828,  ..., -0.0157,  0.0701,  0.0889],\n",
       "        [ 0.0453, -0.0627, -0.0027,  ..., -0.0360,  0.0525,  0.0500],\n",
       "        ...,\n",
       "        [ 0.0754, -0.0676,  0.0044,  ..., -0.0547,  0.0707, -0.0865],\n",
       "        [-0.0077, -0.0351, -0.0692,  ..., -0.0755,  0.0336, -0.0864],\n",
       "        [ 0.0905, -0.0593, -0.0061,  ..., -0.0371,  0.0576, -0.0191]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_model[0].rnns[0]._parameters['weight_hh_l0_raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

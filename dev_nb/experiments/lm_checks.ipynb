{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS = '<eos>'\n",
    "PATH=Path('../data/wikitext')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small helper function to read the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    tokens = []\n",
    "    with open(PATH/filename, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            tokens.append(line.split() + [EOS])\n",
    "    return np.array(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_tok = read_file('wiki.train.tokens')\n",
    "val_tok = read_file('wiki.valid.tokens')\n",
    "tst_tok = read_file('wiki.test.tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36718, 3760, 4358)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_tok), len(val_tok), len(tst_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(trn_tok[4][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 113161),\n",
       " (',', 99913),\n",
       " ('.', 73388),\n",
       " ('of', 56889),\n",
       " ('<unk>', 54625),\n",
       " ('and', 50603),\n",
       " ('in', 39453),\n",
       " ('to', 39190),\n",
       " ('<eos>', 36718),\n",
       " ('a', 34237)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = Counter(word for sent in trn_tok for word in sent)\n",
    "cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give an id to each token and add the pad token (just in case we need it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = [o for o,c in cnt.most_common()]\n",
    "itos.insert(0,'<pad>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33279"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(itos); vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the mapping from token to id then numericalizing our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = collections.defaultdict(lambda : 5, {w:i for i,w in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ids = np.array([([stoi[w] for w in s]) for s in trn_tok])\n",
    "val_ids = np.array([([stoi[w] for w in s]) for s in val_tok])\n",
    "tst_ids = np.array([([stoi[w] for w in s]) for s in tst_tok])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing WeightDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a bunch of parameters for deterministic tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = nn.LSTM(20, 20)\n",
    "tst_input = torch.randn(2,5,20)\n",
    "tst_output = torch.randint(0,20,(10,)).long()\n",
    "save_params = {}\n",
    "for n,p in module._parameters.items(): save_params[n] = p.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old WeightDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WeightDrop(\n",
       "  (module): LSTM(20, 20)\n",
       ")"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = nn.LSTM(20, 20)\n",
    "for n,p in save_params.items(): module._parameters[n] = nn.Parameter(p.clone())\n",
    "dp_module = WeightDrop(module, 0.5)\n",
    "opt = optim.SGD(dp_module.parameters(), 10)\n",
    "dp_module.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x267b3a7b390>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tst_input.clone()\n",
    "x.requires_grad_(requires_grad=True)\n",
    "h = (torch.zeros(1,5,20), torch.zeros(1,5,20))\n",
    "for _ in range(5): x,h = dp_module(x,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0000,  0.2960,  0.0000,  ...,  0.0000, -0.0000, -0.2676],\n",
       "         [ 0.0000,  0.0000,  0.1761,  ..., -0.1233,  0.3515,  0.2500],\n",
       "         [ 0.0000, -0.0000, -0.2828,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         ...,\n",
       "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.3393,  0.0921],\n",
       "         [ 0.0000, -0.0000,  0.1991,  ...,  0.4160, -0.0000,  0.0000],\n",
       "         [-0.1975,  0.0776, -0.0000,  ..., -0.0000,  0.0000,  0.0000]],\n",
       "        grad_fn=<DropoutBackward>), Parameter containing:\n",
       " tensor([[-0.0017,  0.1480,  0.0863,  ...,  0.0488, -0.1722, -0.1338],\n",
       "         [ 0.2046,  0.0867,  0.0880,  ..., -0.0616,  0.1757,  0.1250],\n",
       "         [ 0.0520, -0.1550, -0.1414,  ...,  0.0677, -0.2110,  0.1627],\n",
       "         ...,\n",
       "         [-0.2192,  0.0924, -0.1362,  ...,  0.1746,  0.1697,  0.0461],\n",
       "         [ 0.0708, -0.1189,  0.0996,  ...,  0.2080, -0.1703,  0.0059],\n",
       "         [-0.0987,  0.0388, -0.1416,  ..., -0.0332,  0.0853,  0.1414]],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(dp_module.module, 'weight_hh_l0'),getattr(dp_module.module,'weight_hh_l0_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tst_output.clone()\n",
    "loss = F.nll_loss(x.view(-1,20), target)\n",
    "loss.backward()\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, tensor([[-0.0000, -0.0001, -0.0001,  ..., -0.0000, -0.0000,  0.0001],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0001, -0.0002,  0.0000],\n",
       "         [ 0.0002, -0.0000,  0.0001,  ..., -0.0001,  0.0002,  0.0001],\n",
       "         ...,\n",
       "         [ 0.0001,  0.0001,  0.0002,  ..., -0.0001,  0.0000, -0.0000],\n",
       "         [-0.0002,  0.0000, -0.0017,  ..., -0.0001,  0.0001,  0.0003],\n",
       "         [-0.0001,  0.0001, -0.0003,  ...,  0.0001, -0.0004,  0.0002]]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, w_raw = getattr(dp_module.module, 'weight_hh_l0'),getattr(dp_module.module,'weight_hh_l0_raw')\n",
    "w.grad, w_raw.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0000,  0.2960,  0.0000,  ...,  0.0000, -0.0000, -0.2676],\n",
       "         [ 0.0000,  0.0000,  0.1761,  ..., -0.1233,  0.3515,  0.2500],\n",
       "         [ 0.0000, -0.0000, -0.2828,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         ...,\n",
       "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.3393,  0.0921],\n",
       "         [ 0.0000, -0.0000,  0.1991,  ...,  0.4160, -0.0000,  0.0000],\n",
       "         [-0.1975,  0.0776, -0.0000,  ..., -0.0000,  0.0000,  0.0000]],\n",
       "        grad_fn=<DropoutBackward>), Parameter containing:\n",
       " tensor([[-0.0014,  0.1486,  0.0869,  ...,  0.0492, -0.1719, -0.1344],\n",
       "         [ 0.2048,  0.0869,  0.0884,  ..., -0.0610,  0.1774,  0.1247],\n",
       "         [ 0.0502, -0.1547, -0.1419,  ...,  0.0682, -0.2130,  0.1622],\n",
       "         ...,\n",
       "         [-0.2202,  0.0917, -0.1387,  ...,  0.1755,  0.1695,  0.0464],\n",
       "         [ 0.0726, -0.1192,  0.1170,  ...,  0.2085, -0.1711,  0.0032],\n",
       "         [-0.0979,  0.0376, -0.1388,  ..., -0.0343,  0.0894,  0.1396]],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(dp_module.module, 'weight_hh_l0'),getattr(dp_module.module,'weight_hh_l0_raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New WeightDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightDropout(nn.Module):\n",
    "    \"A module that warps another layer in which some weights will be replaced by 0 during training.\"\n",
    "    \n",
    "    def __init__(self, module, dropout, layer_names=['weight_hh_l0']):\n",
    "        super().__init__()\n",
    "        self.module,self.dropout,self.layer_names = module,dropout,layer_names\n",
    "        for layer in self.layer_names:\n",
    "            #Makes a copy of the weights of the selected layers.\n",
    "            w = getattr(self.module, layer)\n",
    "            self.register_parameter(f'{layer}_raw', nn.Parameter(w.data))\n",
    "    \n",
    "    def _setweights(self):\n",
    "        for layer in self.layer_names:\n",
    "            raw_w = getattr(self, f'{layer}_raw')\n",
    "            self.module._parameters[layer] = F.dropout(raw_w, p=self.dropout, training=self.training)\n",
    "            \n",
    "    def forward(self, *args):\n",
    "        self._setweights()\n",
    "        return self.module.forward(*args)\n",
    "    \n",
    "    def reset(self):\n",
    "        if hasattr(self.module, 'reset'): self.module.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WeightDropout(\n",
       "  (module): LSTM(20, 20)\n",
       ")"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = nn.LSTM(20, 20)\n",
    "for n,p in save_params.items(): module._parameters[n] = nn.Parameter(p.clone())\n",
    "dp_module = WeightDropout(module, 0.5)\n",
    "opt = optim.SGD(dp_module.parameters(), 10)\n",
    "dp_module.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x267b3a7b390>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tst_input.clone()\n",
    "x.requires_grad_(requires_grad=True)\n",
    "h = (torch.zeros(1,5,20), torch.zeros(1,5,20))\n",
    "for _ in range(5): x,h = dp_module(x,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0000,  0.2960,  0.0000,  ...,  0.0000, -0.0000, -0.2676],\n",
       "         [ 0.0000,  0.0000,  0.1761,  ..., -0.1233,  0.3515,  0.2500],\n",
       "         [ 0.0000, -0.0000, -0.2828,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         ...,\n",
       "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.3393,  0.0921],\n",
       "         [ 0.0000, -0.0000,  0.1991,  ...,  0.4160, -0.0000,  0.0000],\n",
       "         [-0.1975,  0.0776, -0.0000,  ..., -0.0000,  0.0000,  0.0000]],\n",
       "        grad_fn=<DropoutBackward>), Parameter containing:\n",
       " tensor([[-0.0017,  0.1480,  0.0863,  ...,  0.0488, -0.1722, -0.1338],\n",
       "         [ 0.2046,  0.0867,  0.0880,  ..., -0.0616,  0.1757,  0.1250],\n",
       "         [ 0.0520, -0.1550, -0.1414,  ...,  0.0677, -0.2110,  0.1627],\n",
       "         ...,\n",
       "         [-0.2192,  0.0924, -0.1362,  ...,  0.1746,  0.1697,  0.0461],\n",
       "         [ 0.0708, -0.1189,  0.0996,  ...,  0.2080, -0.1703,  0.0059],\n",
       "         [-0.0987,  0.0388, -0.1416,  ..., -0.0332,  0.0853,  0.1414]],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(dp_module.module, 'weight_hh_l0'),getattr(dp_module,'weight_hh_l0_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tst_output.clone()\n",
    "loss = F.nll_loss(x.view(-1,20), target)\n",
    "loss.backward()\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, tensor([[-0.0000, -0.0001, -0.0001,  ..., -0.0000, -0.0000,  0.0001],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0001, -0.0002,  0.0000],\n",
       "         [ 0.0002, -0.0000,  0.0001,  ..., -0.0001,  0.0002,  0.0001],\n",
       "         ...,\n",
       "         [ 0.0001,  0.0001,  0.0002,  ..., -0.0001,  0.0000, -0.0000],\n",
       "         [-0.0002,  0.0000, -0.0017,  ..., -0.0001,  0.0001,  0.0003],\n",
       "         [-0.0001,  0.0001, -0.0003,  ...,  0.0001, -0.0004,  0.0002]]))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, w_raw = getattr(dp_module.module, 'weight_hh_l0'),getattr(dp_module,'weight_hh_l0_raw')\n",
    "w.grad, w_raw.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0000,  0.2960,  0.0000,  ...,  0.0000, -0.0000, -0.2676],\n",
       "         [ 0.0000,  0.0000,  0.1761,  ..., -0.1233,  0.3515,  0.2500],\n",
       "         [ 0.0000, -0.0000, -0.2828,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         ...,\n",
       "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.3393,  0.0921],\n",
       "         [ 0.0000, -0.0000,  0.1991,  ...,  0.4160, -0.0000,  0.0000],\n",
       "         [-0.1975,  0.0776, -0.0000,  ..., -0.0000,  0.0000,  0.0000]],\n",
       "        grad_fn=<DropoutBackward>), Parameter containing:\n",
       " tensor([[-0.0014,  0.1486,  0.0869,  ...,  0.0492, -0.1719, -0.1344],\n",
       "         [ 0.2048,  0.0869,  0.0884,  ..., -0.0610,  0.1774,  0.1247],\n",
       "         [ 0.0502, -0.1547, -0.1419,  ...,  0.0682, -0.2130,  0.1622],\n",
       "         ...,\n",
       "         [-0.2202,  0.0917, -0.1387,  ...,  0.1755,  0.1695,  0.0464],\n",
       "         [ 0.0726, -0.1192,  0.1170,  ...,  0.2085, -0.1711,  0.0032],\n",
       "         [-0.0979,  0.0376, -0.1388,  ..., -0.0343,  0.0894,  0.1396]],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(dp_module.module, 'weight_hh_l0'),getattr(dp_module,'weight_hh_l0_raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing EmbeddingDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a bunch of parameters for deterministic tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = nn.Embedding(100,20, padding_idx=0)\n",
    "tst_input = torch.randint(0,100,(25,)).long()\n",
    "save_params = enc.weight.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old EmbeddingDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = nn.Embedding(100,20, padding_idx=0)\n",
    "enc.weight = nn.Parameter(save_params.clone())\n",
    "enc_dp = EmbeddingDropout(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x267b3a7b390>"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2839,  0.2721,  0.0570,  0.0656,  1.4972,  0.2437,  1.8152, -2.6273,\n",
       "          1.2273,  1.1763,  0.5037,  4.9464,  3.2505,  3.5982,  1.2784, -0.7848,\n",
       "         -1.1731, -1.4113,  0.7130, -2.2369],\n",
       "        [ 0.3309, -1.4314,  2.4850, -2.6664,  0.5921, -0.1873,  3.9878, -1.4402,\n",
       "          1.9089,  0.2984,  3.2444,  0.3894, -3.1906,  1.1718, -2.1071, -2.0537,\n",
       "          0.5844,  2.9225,  2.0132,  1.9562],\n",
       "        [-2.8601,  0.7630,  0.6362,  2.8698,  1.2215,  0.0995,  2.7534, -0.8016,\n",
       "         -0.7123, -1.2020, -0.9800,  3.4296, -0.7056, -0.7452, -1.9312,  3.8816,\n",
       "         -2.9207,  3.0680,  0.9727, -0.3739],\n",
       "        [-0.2838, -3.5902,  0.4280, -0.5449,  0.6160, -1.7927,  0.9662, -3.0062,\n",
       "         -0.4531,  1.5771,  1.3366,  0.9028, -1.7587, -1.4735, -2.4497, -0.2795,\n",
       "          1.9607,  0.1777,  0.2684,  1.2090],\n",
       "        [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
       "          0.0000, -0.0000, -0.0000,  0.0000],\n",
       "        [ 0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
       "          0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
       "         -0.0000, -0.0000,  0.0000, -0.0000],\n",
       "        [-0.0000, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          0.0000,  0.0000, -0.0000,  0.0000],\n",
       "        [ 2.0005,  2.9300,  0.6409,  1.5333,  4.2490, -1.3660, -1.1211, -3.2661,\n",
       "         -7.7377, -2.0532,  1.3431, -3.5391, -0.6202, -2.2379, -0.7048, -4.5230,\n",
       "          1.7494, -3.8439, -0.5866,  2.7993],\n",
       "        [ 0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000, -0.0000, -0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,\n",
       "         -0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 3.5037,  1.9591,  0.8210,  3.5350, -0.1664,  1.0174,  2.2356,  2.2571,\n",
       "          1.0025,  2.8411,  2.3084, -3.0731, -1.1154, -0.8767,  2.3144,  0.1779,\n",
       "         -0.8145,  1.0634, -1.4839, -1.2751],\n",
       "        [ 0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "         -0.0000,  0.0000, -0.0000, -0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000,  0.0000,  0.0000],\n",
       "        [ 0.5661,  2.3709, -2.5959, -1.5745,  3.4844,  1.1760,  0.5510, -1.8673,\n",
       "         -4.2679, -1.4985,  1.2679,  2.0073, -4.3761, -1.9854,  1.7770, -2.9734,\n",
       "         -1.8254,  2.5432,  0.2903,  2.7410],\n",
       "        [ 1.2366,  1.3392, -1.4387,  0.4750, -1.3065, -1.6107,  1.9977,  0.2763,\n",
       "         -0.2550,  0.8700, -2.3916, -2.3863,  0.8446,  1.9074, -0.4997, -0.2728,\n",
       "         -2.0631,  0.0751,  0.2417, -1.4114],\n",
       "        [ 3.2241,  3.1342, -1.8777, -2.4739, -1.1648, -1.2307,  3.0992,  1.1978,\n",
       "         -1.2753, -4.5716, -0.7353, -1.7644, -2.0740,  1.1841, -1.5113,  0.7835,\n",
       "          1.4940,  2.7595,  2.5754,  1.7369],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,\n",
       "          0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-2.3153, -1.6892,  0.7396,  1.2826, -3.4070,  0.3343, -3.9851,  1.4646,\n",
       "         -0.5102,  2.8714, -2.8153, -1.1707,  2.6719,  1.4754, -1.7049,  0.7048,\n",
       "         -0.9525, -2.2271,  0.5412, -1.0625],\n",
       "        [ 0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "          0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
       "         -0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [ 0.8225, -1.0743, -0.0485,  2.3570, -0.0004, -0.6308, -2.3086, -1.1489,\n",
       "         -0.4389, -0.7562,  1.1551, -1.3846, -1.4227, -1.1548, -0.2256, -0.3646,\n",
       "         -1.6049,  0.4017, -4.7985, -3.3314],\n",
       "        [ 0.2826, -1.4568, -1.4407, -0.9941,  1.8913,  0.8736,  1.8730, -3.3958,\n",
       "         -1.3067,  0.9059, -2.5514,  3.2087,  2.9153,  0.3965,  0.1945, -0.8416,\n",
       "          1.1067, -2.5834,  1.7590,  1.9643],\n",
       "        [-0.0000, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,\n",
       "         -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "          0.0000, -0.0000, -0.0000,  0.0000],\n",
       "        [-0.7371,  1.1480, -1.0144,  0.0642,  4.2318, -1.9866,  0.7480, -0.7119,\n",
       "         -5.6169,  0.6574,  2.2582,  3.7214,  1.7813, -4.0784,  4.2789, -1.3116,\n",
       "         -1.4390, -0.3338,  2.4260, -2.9036]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tst_input.clone()\n",
    "enc_dp(x, dropout=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New EmbeddingDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_mask(x, sz, p):\n",
    "    \"Returns a dropout mask of the same type as x, size sz, with probability p to cancel an element.\"\n",
    "    return x.new(*sz).bernoulli_(1-p)/(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDropout1(nn.Module):\n",
    "\n",
    "    \"Applies dropout in the embedding layer by zeroing out some elements of the embedding vector.\"\n",
    "    def __init__(self, emb, dropout):\n",
    "        super().__init__()\n",
    "        self.emb,self.dropout = emb,dropout\n",
    "        self.pad_idx = self.emb.padding_idx\n",
    "        if self.pad_idx is None: self.pad_idx = -1\n",
    "\n",
    "    def forward(self, words, dropout=0.1, scale=None):\n",
    "        if self.training and self.dropout != 0:\n",
    "            size = (self.emb.weight.size(0),1)\n",
    "            mask = dropout_mask(self.emb.weight.data, size, self.dropout)\n",
    "            masked_emb_weight = mask * self.emb.weight\n",
    "        else: masked_emb_weight = self.emb.weight\n",
    "        if scale: masked_emb_weight = scale * masked_emb_weight\n",
    "        return F.embedding(words, masked_emb_weight, self.pad_idx, self.emb.max_norm,\n",
    "                           self.emb.norm_type, self.emb.scale_grad_by_freq, self.emb.sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = nn.Embedding(100,20, padding_idx=0)\n",
    "enc.weight = nn.Parameter(save_params.clone())\n",
    "enc_dp = EmbeddingDropout1(enc, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x267b3a7b390>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2839,  0.2721,  0.0570,  0.0656,  1.4972,  0.2437,  1.8152, -2.6273,\n",
       "          1.2273,  1.1763,  0.5037,  4.9464,  3.2505,  3.5982,  1.2784, -0.7848,\n",
       "         -1.1731, -1.4113,  0.7130, -2.2369],\n",
       "        [ 0.3309, -1.4314,  2.4850, -2.6664,  0.5921, -0.1873,  3.9878, -1.4402,\n",
       "          1.9089,  0.2984,  3.2444,  0.3894, -3.1906,  1.1718, -2.1071, -2.0537,\n",
       "          0.5844,  2.9225,  2.0132,  1.9562],\n",
       "        [-2.8601,  0.7630,  0.6362,  2.8698,  1.2215,  0.0995,  2.7534, -0.8016,\n",
       "         -0.7123, -1.2020, -0.9800,  3.4296, -0.7056, -0.7452, -1.9312,  3.8816,\n",
       "         -2.9207,  3.0680,  0.9727, -0.3739],\n",
       "        [-0.2838, -3.5902,  0.4280, -0.5449,  0.6160, -1.7927,  0.9662, -3.0062,\n",
       "         -0.4531,  1.5771,  1.3366,  0.9028, -1.7587, -1.4735, -2.4497, -0.2795,\n",
       "          1.9607,  0.1777,  0.2684,  1.2090],\n",
       "        [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
       "          0.0000, -0.0000, -0.0000,  0.0000],\n",
       "        [ 0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
       "          0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
       "         -0.0000, -0.0000,  0.0000, -0.0000],\n",
       "        [-0.0000, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          0.0000,  0.0000, -0.0000,  0.0000],\n",
       "        [ 2.0005,  2.9300,  0.6409,  1.5333,  4.2490, -1.3660, -1.1211, -3.2661,\n",
       "         -7.7377, -2.0532,  1.3431, -3.5391, -0.6202, -2.2379, -0.7048, -4.5230,\n",
       "          1.7494, -3.8439, -0.5866,  2.7993],\n",
       "        [ 0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000, -0.0000, -0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,\n",
       "         -0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 3.5037,  1.9591,  0.8210,  3.5350, -0.1664,  1.0174,  2.2356,  2.2571,\n",
       "          1.0025,  2.8411,  2.3084, -3.0731, -1.1154, -0.8767,  2.3144,  0.1779,\n",
       "         -0.8145,  1.0634, -1.4839, -1.2751],\n",
       "        [ 0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "         -0.0000,  0.0000, -0.0000, -0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000,  0.0000,  0.0000],\n",
       "        [ 0.5661,  2.3709, -2.5959, -1.5745,  3.4844,  1.1760,  0.5510, -1.8673,\n",
       "         -4.2679, -1.4985,  1.2679,  2.0073, -4.3761, -1.9854,  1.7770, -2.9734,\n",
       "         -1.8254,  2.5432,  0.2903,  2.7410],\n",
       "        [ 1.2366,  1.3392, -1.4387,  0.4750, -1.3065, -1.6107,  1.9977,  0.2763,\n",
       "         -0.2550,  0.8700, -2.3916, -2.3863,  0.8446,  1.9074, -0.4997, -0.2728,\n",
       "         -2.0631,  0.0751,  0.2417, -1.4114],\n",
       "        [ 3.2241,  3.1342, -1.8777, -2.4739, -1.1648, -1.2307,  3.0992,  1.1978,\n",
       "         -1.2753, -4.5716, -0.7353, -1.7644, -2.0740,  1.1841, -1.5113,  0.7835,\n",
       "          1.4940,  2.7595,  2.5754,  1.7369],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,\n",
       "          0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-2.3153, -1.6892,  0.7396,  1.2826, -3.4070,  0.3343, -3.9851,  1.4646,\n",
       "         -0.5102,  2.8714, -2.8153, -1.1707,  2.6719,  1.4754, -1.7049,  0.7048,\n",
       "         -0.9525, -2.2271,  0.5412, -1.0625],\n",
       "        [ 0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "          0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
       "         -0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [ 0.8225, -1.0743, -0.0485,  2.3570, -0.0004, -0.6308, -2.3086, -1.1489,\n",
       "         -0.4389, -0.7562,  1.1551, -1.3846, -1.4227, -1.1548, -0.2256, -0.3646,\n",
       "         -1.6049,  0.4017, -4.7985, -3.3314],\n",
       "        [ 0.2826, -1.4568, -1.4407, -0.9941,  1.8913,  0.8736,  1.8730, -3.3958,\n",
       "         -1.3067,  0.9059, -2.5514,  3.2087,  2.9153,  0.3965,  0.1945, -0.8416,\n",
       "          1.1067, -2.5834,  1.7590,  1.9643],\n",
       "        [-0.0000, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,\n",
       "         -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "          0.0000, -0.0000, -0.0000,  0.0000],\n",
       "        [-0.7371,  1.1480, -1.0144,  0.0642,  4.2318, -1.9866,  0.7480, -0.7119,\n",
       "         -5.6169,  0.6574,  2.2582,  3.7214,  1.7813, -4.0784,  4.2789, -1.3116,\n",
       "         -1.4390, -0.3338,  2.4260, -2.9036]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tst_input.clone()\n",
    "enc_dp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a bunch of parameters for deterministic testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_model = get_language_model(500, 20, 100, 2, 0, bias=True)\n",
    "save_parameters = {}\n",
    "for n,p in tst_model.state_dict().items(): save_parameters[n] = p.clone()\n",
    "tst_input = torch.randint(0, 500, (10,5)).long()\n",
    "tst_output = torch.randint(0, 500, (50,)).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_model = get_language_model(500, 20, 100, 2, 0, bias=True, dropout=0.4, dropoute=0.1, dropouth=0.2, \n",
    "                               dropouti=0.6, wdrop=0.5)\n",
    "state_dict = OrderedDict()\n",
    "for n,p in save_parameters.items(): state_dict[n] = p.clone()\n",
    "tst_model.load_state_dict(state_dict)\n",
    "opt = optim.SGD(tst_model.parameters(), lr=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x267b3a7b390>"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0005, -0.0192, -0.0097,  ...,  0.0120, -0.0285,  0.0068],\n",
       "         [-0.0041, -0.0030, -0.0108,  ...,  0.0085, -0.0356,  0.0088],\n",
       "         [-0.0015, -0.0161, -0.0064,  ...,  0.0086, -0.0198, -0.0061],\n",
       "         ...,\n",
       "         [ 0.0008, -0.0327, -0.0184,  ...,  0.0314, -0.0460, -0.0368],\n",
       "         [-0.0005, -0.0168, -0.0430,  ...,  0.0091, -0.0292, -0.0235],\n",
       "         [ 0.0047, -0.0315, -0.0145,  ...,  0.0085, -0.0557, -0.0512]],\n",
       "        grad_fn=<ViewBackward>),\n",
       " [tensor([[[-0.0070,  0.0093, -0.0127,  ..., -0.0127,  0.0019, -0.0122],\n",
       "           [-0.0068,  0.0088, -0.0119,  ..., -0.0070,  0.0131, -0.0127],\n",
       "           [-0.0110,  0.0003, -0.0091,  ..., -0.0199,  0.0036, -0.0174],\n",
       "           [-0.0074,  0.0093, -0.0167,  ..., -0.0118,  0.0063, -0.0096],\n",
       "           [-0.0122,  0.0024, -0.0095,  ..., -0.0059,  0.0143, -0.0146]],\n",
       "  \n",
       "          [[-0.0131,  0.0122, -0.0341,  ..., -0.0250,  0.0075, -0.0314],\n",
       "           [-0.0305,  0.0160, -0.0145,  ..., -0.0261,  0.0096, -0.0248],\n",
       "           [-0.0156,  0.0060, -0.0250,  ..., -0.0289,  0.0052, -0.0264],\n",
       "           [-0.0252,  0.0162, -0.0231,  ..., -0.0226, -0.0059, -0.0227],\n",
       "           [-0.0122,  0.0075, -0.0188,  ..., -0.0197,  0.0179, -0.0317]],\n",
       "  \n",
       "          [[-0.0364,  0.0204, -0.0375,  ..., -0.0202,  0.0093, -0.0545],\n",
       "           [-0.0378,  0.0034, -0.0357,  ..., -0.0222,  0.0020, -0.0243],\n",
       "           [-0.0384,  0.0205, -0.0362,  ..., -0.0225,  0.0057, -0.0340],\n",
       "           [-0.0288,  0.0173, -0.0345,  ..., -0.0204,  0.0023, -0.0248],\n",
       "           [-0.0439,  0.0311, -0.0301,  ..., -0.0237,  0.0070, -0.0424]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-0.0371,  0.0248, -0.0613,  ..., -0.0040,  0.0092, -0.0508],\n",
       "           [-0.0551,  0.0169, -0.0547,  ..., -0.0137, -0.0230, -0.0119],\n",
       "           [-0.0498,  0.0377, -0.0509,  ..., -0.0042,  0.0015, -0.0453],\n",
       "           [-0.0260,  0.0238, -0.0565,  ..., -0.0023,  0.0011, -0.0342],\n",
       "           [-0.0308,  0.0279, -0.0596,  ..., -0.0109,  0.0051, -0.0586]],\n",
       "  \n",
       "          [[-0.0317,  0.0273, -0.0557,  ...,  0.0014,  0.0064, -0.0592],\n",
       "           [-0.0408,  0.0299, -0.0561,  ..., -0.0096, -0.0044, -0.0348],\n",
       "           [-0.0495,  0.0350, -0.0518,  ..., -0.0054,  0.0018, -0.0491],\n",
       "           [-0.0316,  0.0234, -0.0572,  ..., -0.0048,  0.0033, -0.0400],\n",
       "           [-0.0321,  0.0256, -0.0598,  ..., -0.0088,  0.0040, -0.0531]],\n",
       "  \n",
       "          [[-0.0402,  0.0201, -0.0639,  ...,  0.0014, -0.0010, -0.0491],\n",
       "           [-0.0397,  0.0223, -0.0510,  ..., -0.0090, -0.0068, -0.0331],\n",
       "           [-0.0475,  0.0322, -0.0564,  ..., -0.0061,  0.0039, -0.0451],\n",
       "           [-0.0406,  0.0212, -0.0570,  ..., -0.0085,  0.0095, -0.0397],\n",
       "           [-0.0424,  0.0363, -0.0562,  ..., -0.0074, -0.0058, -0.0479]]],\n",
       "         grad_fn=<CatBackward>),\n",
       "  tensor([[[ 0.0117, -0.0472,  0.0226,  0.0451,  0.0607,  0.0681,  0.0104,\n",
       "             0.0026,  0.0244,  0.0238,  0.0170,  0.0170,  0.0718, -0.0289,\n",
       "             0.0440, -0.0112, -0.0432, -0.0339, -0.0070, -0.0299],\n",
       "           [ 0.0083, -0.0503,  0.0170,  0.0470,  0.0546,  0.0663,  0.0029,\n",
       "             0.0080,  0.0247,  0.0184,  0.0155,  0.0130,  0.0723, -0.0325,\n",
       "             0.0396, -0.0100, -0.0479, -0.0293, -0.0057, -0.0225],\n",
       "           [ 0.0172, -0.0480,  0.0234,  0.0450,  0.0669,  0.0664,  0.0093,\n",
       "             0.0118,  0.0216,  0.0148,  0.0185,  0.0172,  0.0762, -0.0335,\n",
       "             0.0421, -0.0090, -0.0400, -0.0285, -0.0091, -0.0158],\n",
       "           [ 0.0099, -0.0532,  0.0251,  0.0441,  0.0599,  0.0721,  0.0087,\n",
       "             0.0099,  0.0297,  0.0121,  0.0210,  0.0186,  0.0632, -0.0298,\n",
       "             0.0400, -0.0039, -0.0437, -0.0351, -0.0034, -0.0140],\n",
       "           [ 0.0117, -0.0458,  0.0224,  0.0519,  0.0641,  0.0720,  0.0023,\n",
       "            -0.0003,  0.0171,  0.0194,  0.0227,  0.0136,  0.0684, -0.0322,\n",
       "             0.0400, -0.0070, -0.0448, -0.0311,  0.0014, -0.0276]],\n",
       "  \n",
       "          [[ 0.0090, -0.0780,  0.0383,  0.0749,  0.0917,  0.1076,  0.0121,\n",
       "             0.0066,  0.0218,  0.0330,  0.0267,  0.0272,  0.1038, -0.0276,\n",
       "             0.0663, -0.0140, -0.0723, -0.0486,  0.0023, -0.0364],\n",
       "           [ 0.0086, -0.0865,  0.0290,  0.0805,  0.0853,  0.0988, -0.0051,\n",
       "             0.0194,  0.0168,  0.0240,  0.0255,  0.0187,  0.1086, -0.0298,\n",
       "             0.0537, -0.0182, -0.0787, -0.0447,  0.0047, -0.0223],\n",
       "           [ 0.0238, -0.0835,  0.0372,  0.0721,  0.0984,  0.0928,  0.0051,\n",
       "             0.0198,  0.0151,  0.0177,  0.0286,  0.0256,  0.1141, -0.0368,\n",
       "             0.0604, -0.0161, -0.0702, -0.0390, -0.0025, -0.0097],\n",
       "           [ 0.0094, -0.0896,  0.0355,  0.0680,  0.0865,  0.1035,  0.0016,\n",
       "             0.0174,  0.0303,  0.0161,  0.0331,  0.0249,  0.0952, -0.0318,\n",
       "             0.0602, -0.0079, -0.0737, -0.0501,  0.0081, -0.0083],\n",
       "           [ 0.0080, -0.0781,  0.0379,  0.0825,  0.0991,  0.1106, -0.0040,\n",
       "             0.0038,  0.0102,  0.0237,  0.0336,  0.0235,  0.1048, -0.0320,\n",
       "             0.0586, -0.0123, -0.0757, -0.0469,  0.0117, -0.0313]],\n",
       "  \n",
       "          [[ 0.0093, -0.0981,  0.0456,  0.0935,  0.1054,  0.1293,  0.0038,\n",
       "             0.0099,  0.0112,  0.0316,  0.0375,  0.0301,  0.1218, -0.0180,\n",
       "             0.0729, -0.0177, -0.0886, -0.0619,  0.0127, -0.0387],\n",
       "           [ 0.0085, -0.1053,  0.0301,  0.1032,  0.1001,  0.1138, -0.0158,\n",
       "             0.0238,  0.0017,  0.0263,  0.0357,  0.0156,  0.1252, -0.0216,\n",
       "             0.0585, -0.0252, -0.0986, -0.0561,  0.0163, -0.0218],\n",
       "           [ 0.0247, -0.1070,  0.0476,  0.0852,  0.1125,  0.1026, -0.0028,\n",
       "             0.0188,  0.0023,  0.0131,  0.0353,  0.0279,  0.1282, -0.0341,\n",
       "             0.0680, -0.0210, -0.0898, -0.0447,  0.0107, -0.0034],\n",
       "           [ 0.0083, -0.1125,  0.0399,  0.0803,  0.0984,  0.1178, -0.0084,\n",
       "             0.0217,  0.0256,  0.0182,  0.0415,  0.0236,  0.1094, -0.0266,\n",
       "             0.0664, -0.0092, -0.0925, -0.0615,  0.0232,  0.0018],\n",
       "           [ 0.0032, -0.0954,  0.0434,  0.0952,  0.1064,  0.1317, -0.0108,\n",
       "             0.0035, -0.0025,  0.0219,  0.0435,  0.0226,  0.1152, -0.0243,\n",
       "             0.0645, -0.0145, -0.0890, -0.0564,  0.0247, -0.0313]],\n",
       "  \n",
       "          [[ 0.0111, -0.1127,  0.0492,  0.1071,  0.1136,  0.1375, -0.0077,\n",
       "             0.0111,  0.0013,  0.0334,  0.0478,  0.0271,  0.1303, -0.0105,\n",
       "             0.0752, -0.0249, -0.0976, -0.0725,  0.0206, -0.0395],\n",
       "           [ 0.0095, -0.1161,  0.0289,  0.1178,  0.1029,  0.1209, -0.0257,\n",
       "             0.0272, -0.0131,  0.0260,  0.0454,  0.0127,  0.1328, -0.0132,\n",
       "             0.0566, -0.0318, -0.1086, -0.0617,  0.0249, -0.0173],\n",
       "           [ 0.0281, -0.1151,  0.0481,  0.0984,  0.1145,  0.1094, -0.0133,\n",
       "             0.0212, -0.0109,  0.0131,  0.0467,  0.0274,  0.1408, -0.0303,\n",
       "             0.0711, -0.0299, -0.1000, -0.0545,  0.0087, -0.0011],\n",
       "           [ 0.0065, -0.1209,  0.0394,  0.0876,  0.1045,  0.1244, -0.0193,\n",
       "             0.0243,  0.0185,  0.0182,  0.0494,  0.0214,  0.1135, -0.0213,\n",
       "             0.0678, -0.0114, -0.1039, -0.0715,  0.0329,  0.0082],\n",
       "           [ 0.0030, -0.0994,  0.0423,  0.1048,  0.1062,  0.1444, -0.0226,\n",
       "             0.0054, -0.0150,  0.0198,  0.0536,  0.0197,  0.1251, -0.0187,\n",
       "             0.0648, -0.0213, -0.1005, -0.0620,  0.0292, -0.0306]],\n",
       "  \n",
       "          [[ 0.0103, -0.1177,  0.0475,  0.1156,  0.1147,  0.1433, -0.0161,\n",
       "             0.0125, -0.0063,  0.0339,  0.0547,  0.0256,  0.1353, -0.0047,\n",
       "             0.0756, -0.0309, -0.1034, -0.0826,  0.0244, -0.0410],\n",
       "           [ 0.0138, -0.1144,  0.0271,  0.1244,  0.1089,  0.1256, -0.0323,\n",
       "             0.0340, -0.0256,  0.0307,  0.0512,  0.0094,  0.1392, -0.0072,\n",
       "             0.0575, -0.0362, -0.1155, -0.0641,  0.0270, -0.0111],\n",
       "           [ 0.0287, -0.1190,  0.0461,  0.1061,  0.1107,  0.1135, -0.0253,\n",
       "             0.0222, -0.0209,  0.0082,  0.0549,  0.0254,  0.1476, -0.0269,\n",
       "             0.0706, -0.0369, -0.1075, -0.0576,  0.0123,  0.0044],\n",
       "           [ 0.0053, -0.1193,  0.0366,  0.0936,  0.1059,  0.1295, -0.0311,\n",
       "             0.0237,  0.0137,  0.0200,  0.0633,  0.0177,  0.1147, -0.0184,\n",
       "             0.0673, -0.0160, -0.1091, -0.0768,  0.0359,  0.0097],\n",
       "           [ 0.0023, -0.1008,  0.0408,  0.1071,  0.1081,  0.1501, -0.0327,\n",
       "             0.0096, -0.0249,  0.0200,  0.0584,  0.0144,  0.1246, -0.0177,\n",
       "             0.0642, -0.0255, -0.1047, -0.0708,  0.0347, -0.0297]],\n",
       "  \n",
       "          [[ 0.0075, -0.1199,  0.0457,  0.1209,  0.1145,  0.1483, -0.0208,\n",
       "             0.0147, -0.0097,  0.0342,  0.0587,  0.0260,  0.1361, -0.0012,\n",
       "             0.0754, -0.0320, -0.1052, -0.0891,  0.0278, -0.0370],\n",
       "           [ 0.0169, -0.1124,  0.0190,  0.1276,  0.1009,  0.1280, -0.0399,\n",
       "             0.0348, -0.0339,  0.0316,  0.0565,  0.0027,  0.1431, -0.0080,\n",
       "             0.0546, -0.0403, -0.1233, -0.0635,  0.0265, -0.0108],\n",
       "           [ 0.0293, -0.1132,  0.0405,  0.1103,  0.1103,  0.1196, -0.0321,\n",
       "             0.0249, -0.0270,  0.0019,  0.0586,  0.0228,  0.1504, -0.0275,\n",
       "             0.0720, -0.0375, -0.1143, -0.0631,  0.0162,  0.0065],\n",
       "           [ 0.0024, -0.1118,  0.0333,  0.0961,  0.1083,  0.1317, -0.0414,\n",
       "             0.0254,  0.0082,  0.0201,  0.0720,  0.0177,  0.1151, -0.0164,\n",
       "             0.0655, -0.0177, -0.1117, -0.0826,  0.0357,  0.0068],\n",
       "           [ 0.0055, -0.1032,  0.0384,  0.1129,  0.1097,  0.1513, -0.0381,\n",
       "             0.0062, -0.0314,  0.0188,  0.0679,  0.0100,  0.1262, -0.0154,\n",
       "             0.0586, -0.0305, -0.1029, -0.0724,  0.0371, -0.0310]],\n",
       "  \n",
       "          [[ 0.0052, -0.1146,  0.0416,  0.1232,  0.1120,  0.1530, -0.0216,\n",
       "             0.0150, -0.0126,  0.0339,  0.0606,  0.0283,  0.1380, -0.0007,\n",
       "             0.0764, -0.0360, -0.1074, -0.0946,  0.0277, -0.0369],\n",
       "           [ 0.0189, -0.1085,  0.0191,  0.1333,  0.1010,  0.1302, -0.0453,\n",
       "             0.0385, -0.0351,  0.0301,  0.0605, -0.0003,  0.1457, -0.0063,\n",
       "             0.0496, -0.0424, -0.1236, -0.0670,  0.0273, -0.0099],\n",
       "           [ 0.0311, -0.1065,  0.0375,  0.1151,  0.1135,  0.1227, -0.0360,\n",
       "             0.0319, -0.0279,  0.0002,  0.0600,  0.0227,  0.1557, -0.0287,\n",
       "             0.0713, -0.0385, -0.1161, -0.0706,  0.0123,  0.0119],\n",
       "           [ 0.0027, -0.1085,  0.0291,  0.0965,  0.1085,  0.1327, -0.0467,\n",
       "             0.0266,  0.0099,  0.0192,  0.0772,  0.0175,  0.1175, -0.0177,\n",
       "             0.0613, -0.0206, -0.1152, -0.0900,  0.0378,  0.0048],\n",
       "           [ 0.0095, -0.0943,  0.0385,  0.1167,  0.1090,  0.1562, -0.0400,\n",
       "             0.0018, -0.0337,  0.0172,  0.0741,  0.0106,  0.1282, -0.0131,\n",
       "             0.0557, -0.0320, -0.1054, -0.0769,  0.0396, -0.0335]],\n",
       "  \n",
       "          [[ 0.0062, -0.1137,  0.0350,  0.1260,  0.1096,  0.1565, -0.0238,\n",
       "             0.0183, -0.0154,  0.0331,  0.0615,  0.0278,  0.1376,  0.0014,\n",
       "             0.0759, -0.0372, -0.1133, -0.0949,  0.0261, -0.0338],\n",
       "           [ 0.0200, -0.1061,  0.0220,  0.1373,  0.1007,  0.1310, -0.0492,\n",
       "             0.0415, -0.0332,  0.0294,  0.0632, -0.0019,  0.1485, -0.0059,\n",
       "             0.0429, -0.0454, -0.1194, -0.0726,  0.0278, -0.0102],\n",
       "           [ 0.0326, -0.1084,  0.0401,  0.1212,  0.1132,  0.1206, -0.0391,\n",
       "             0.0302, -0.0300, -0.0003,  0.0666,  0.0228,  0.1575, -0.0280,\n",
       "             0.0700, -0.0418, -0.1145, -0.0759,  0.0107,  0.0105],\n",
       "           [ 0.0030, -0.1093,  0.0267,  0.0967,  0.1084,  0.1328, -0.0506,\n",
       "             0.0282,  0.0069,  0.0178,  0.0800,  0.0181,  0.1191, -0.0193,\n",
       "             0.0610, -0.0231, -0.1160, -0.0918,  0.0355,  0.0052],\n",
       "           [ 0.0082, -0.0856,  0.0389,  0.1170,  0.1137,  0.1605, -0.0392,\n",
       "             0.0023, -0.0334,  0.0179,  0.0761,  0.0109,  0.1329, -0.0133,\n",
       "             0.0562, -0.0353, -0.1054, -0.0784,  0.0367, -0.0356]],\n",
       "  \n",
       "          [[ 0.0069, -0.1052,  0.0329,  0.1239,  0.1102,  0.1594, -0.0243,\n",
       "             0.0205, -0.0172,  0.0316,  0.0619,  0.0292,  0.1411,  0.0019,\n",
       "             0.0765, -0.0400, -0.1167, -0.0963,  0.0244, -0.0335],\n",
       "           [ 0.0206, -0.0994,  0.0201,  0.1342,  0.0978,  0.1344, -0.0517,\n",
       "             0.0436, -0.0326,  0.0299,  0.0603, -0.0018,  0.1514, -0.0122,\n",
       "             0.0432, -0.0454, -0.1185, -0.0757,  0.0268, -0.0147],\n",
       "           [ 0.0333, -0.1060,  0.0360,  0.1247,  0.1109,  0.1212, -0.0407,\n",
       "             0.0319, -0.0311, -0.0005,  0.0676,  0.0231,  0.1583, -0.0279,\n",
       "             0.0693, -0.0423, -0.1156, -0.0794,  0.0092,  0.0139],\n",
       "           [ 0.0042, -0.1095,  0.0254,  0.0981,  0.1099,  0.1327, -0.0517,\n",
       "             0.0304,  0.0055,  0.0159,  0.0785,  0.0197,  0.1210, -0.0201,\n",
       "             0.0611, -0.0252, -0.1159, -0.0938,  0.0359,  0.0067],\n",
       "           [ 0.0075, -0.0833,  0.0398,  0.1182,  0.1139,  0.1600, -0.0410,\n",
       "             0.0042, -0.0328,  0.0175,  0.0771,  0.0117,  0.1339, -0.0135,\n",
       "             0.0567, -0.0371, -0.1066, -0.0812,  0.0347, -0.0351]],\n",
       "  \n",
       "          [[ 0.0063, -0.1013,  0.0349,  0.1234,  0.1120,  0.1582, -0.0251,\n",
       "             0.0191, -0.0154,  0.0291,  0.0661,  0.0268,  0.1419,  0.0040,\n",
       "             0.0770, -0.0407, -0.1125, -0.1028,  0.0260, -0.0374],\n",
       "           [ 0.0226, -0.0979,  0.0188,  0.1351,  0.1006,  0.1347, -0.0524,\n",
       "             0.0448, -0.0372,  0.0329,  0.0625, -0.0015,  0.1541, -0.0118,\n",
       "             0.0447, -0.0468, -0.1215, -0.0732,  0.0240, -0.0134],\n",
       "           [ 0.0349, -0.1033,  0.0350,  0.1270,  0.1119,  0.1213, -0.0419,\n",
       "             0.0336, -0.0300,  0.0005,  0.0685,  0.0230,  0.1595, -0.0264,\n",
       "             0.0693, -0.0436, -0.1159, -0.0805,  0.0105,  0.0150],\n",
       "           [ 0.0072, -0.1132,  0.0256,  0.0983,  0.1125,  0.1303, -0.0499,\n",
       "             0.0323,  0.0045,  0.0141,  0.0703,  0.0219,  0.1239, -0.0195,\n",
       "             0.0611, -0.0239, -0.1143, -0.0954,  0.0398,  0.0111],\n",
       "           [ 0.0085, -0.0816,  0.0389,  0.1172,  0.1104,  0.1571, -0.0470,\n",
       "             0.0063, -0.0333,  0.0199,  0.0799,  0.0083,  0.1328, -0.0147,\n",
       "             0.0547, -0.0404, -0.1035, -0.0844,  0.0334, -0.0373]]],\n",
       "         grad_fn=<CatBackward>)],\n",
       " [tensor([[[-0.0088,  0.0116, -0.0000,  ..., -0.0159,  0.0024, -0.0152],\n",
       "           [-0.0085,  0.0109, -0.0000,  ..., -0.0087,  0.0164, -0.0000],\n",
       "           [-0.0000,  0.0000, -0.0000,  ..., -0.0249,  0.0045, -0.0000],\n",
       "           [-0.0093,  0.0117, -0.0209,  ..., -0.0147,  0.0000, -0.0120],\n",
       "           [-0.0153,  0.0030, -0.0119,  ..., -0.0074,  0.0000, -0.0183]],\n",
       "  \n",
       "          [[-0.0164,  0.0152, -0.0000,  ..., -0.0312,  0.0093, -0.0392],\n",
       "           [-0.0381,  0.0200, -0.0000,  ..., -0.0326,  0.0120, -0.0000],\n",
       "           [-0.0000,  0.0000, -0.0000,  ..., -0.0362,  0.0065, -0.0000],\n",
       "           [-0.0316,  0.0203, -0.0289,  ..., -0.0282, -0.0000, -0.0283],\n",
       "           [-0.0152,  0.0094, -0.0235,  ..., -0.0246,  0.0000, -0.0396]],\n",
       "  \n",
       "          [[-0.0455,  0.0255, -0.0000,  ..., -0.0253,  0.0116, -0.0681],\n",
       "           [-0.0472,  0.0042, -0.0000,  ..., -0.0277,  0.0025, -0.0000],\n",
       "           [-0.0000,  0.0000, -0.0000,  ..., -0.0281,  0.0071, -0.0000],\n",
       "           [-0.0360,  0.0217, -0.0432,  ..., -0.0255,  0.0000, -0.0310],\n",
       "           [-0.0548,  0.0389, -0.0376,  ..., -0.0296,  0.0000, -0.0530]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-0.0463,  0.0310, -0.0000,  ..., -0.0049,  0.0116, -0.0635],\n",
       "           [-0.0689,  0.0212, -0.0000,  ..., -0.0171, -0.0287, -0.0000],\n",
       "           [-0.0000,  0.0000, -0.0000,  ..., -0.0052,  0.0019, -0.0000],\n",
       "           [-0.0325,  0.0297, -0.0706,  ..., -0.0029,  0.0000, -0.0427],\n",
       "           [-0.0385,  0.0349, -0.0745,  ..., -0.0137,  0.0000, -0.0732]],\n",
       "  \n",
       "          [[-0.0396,  0.0342, -0.0000,  ...,  0.0017,  0.0080, -0.0740],\n",
       "           [-0.0510,  0.0374, -0.0000,  ..., -0.0120, -0.0056, -0.0000],\n",
       "           [-0.0000,  0.0000, -0.0000,  ..., -0.0067,  0.0022, -0.0000],\n",
       "           [-0.0394,  0.0292, -0.0715,  ..., -0.0060,  0.0000, -0.0500],\n",
       "           [-0.0402,  0.0321, -0.0747,  ..., -0.0110,  0.0000, -0.0664]],\n",
       "  \n",
       "          [[-0.0502,  0.0251, -0.0000,  ...,  0.0017, -0.0013, -0.0613],\n",
       "           [-0.0496,  0.0278, -0.0000,  ..., -0.0113, -0.0084, -0.0000],\n",
       "           [-0.0000,  0.0000, -0.0000,  ..., -0.0076,  0.0049, -0.0000],\n",
       "           [-0.0508,  0.0265, -0.0713,  ..., -0.0106,  0.0000, -0.0496],\n",
       "           [-0.0530,  0.0454, -0.0703,  ..., -0.0092, -0.0000, -0.0598]]],\n",
       "         grad_fn=<ThMulBackward>),\n",
       "  tensor([[[ 0.0117, -0.0472,  0.0226,  0.0451,  0.0607,  0.0681,  0.0104,\n",
       "             0.0026,  0.0244,  0.0238,  0.0170,  0.0170,  0.0718, -0.0289,\n",
       "             0.0440, -0.0112, -0.0432, -0.0339, -0.0070, -0.0299],\n",
       "           [ 0.0083, -0.0503,  0.0170,  0.0470,  0.0546,  0.0663,  0.0029,\n",
       "             0.0080,  0.0247,  0.0184,  0.0155,  0.0130,  0.0723, -0.0325,\n",
       "             0.0396, -0.0100, -0.0479, -0.0293, -0.0057, -0.0225],\n",
       "           [ 0.0172, -0.0480,  0.0234,  0.0450,  0.0669,  0.0664,  0.0093,\n",
       "             0.0118,  0.0216,  0.0148,  0.0185,  0.0172,  0.0762, -0.0335,\n",
       "             0.0421, -0.0090, -0.0400, -0.0285, -0.0091, -0.0158],\n",
       "           [ 0.0099, -0.0532,  0.0251,  0.0441,  0.0599,  0.0721,  0.0087,\n",
       "             0.0099,  0.0297,  0.0121,  0.0210,  0.0186,  0.0632, -0.0298,\n",
       "             0.0400, -0.0039, -0.0437, -0.0351, -0.0034, -0.0140],\n",
       "           [ 0.0117, -0.0458,  0.0224,  0.0519,  0.0641,  0.0720,  0.0023,\n",
       "            -0.0003,  0.0171,  0.0194,  0.0227,  0.0136,  0.0684, -0.0322,\n",
       "             0.0400, -0.0070, -0.0448, -0.0311,  0.0014, -0.0276]],\n",
       "  \n",
       "          [[ 0.0090, -0.0780,  0.0383,  0.0749,  0.0917,  0.1076,  0.0121,\n",
       "             0.0066,  0.0218,  0.0330,  0.0267,  0.0272,  0.1038, -0.0276,\n",
       "             0.0663, -0.0140, -0.0723, -0.0486,  0.0023, -0.0364],\n",
       "           [ 0.0086, -0.0865,  0.0290,  0.0805,  0.0853,  0.0988, -0.0051,\n",
       "             0.0194,  0.0168,  0.0240,  0.0255,  0.0187,  0.1086, -0.0298,\n",
       "             0.0537, -0.0182, -0.0787, -0.0447,  0.0047, -0.0223],\n",
       "           [ 0.0238, -0.0835,  0.0372,  0.0721,  0.0984,  0.0928,  0.0051,\n",
       "             0.0198,  0.0151,  0.0177,  0.0286,  0.0256,  0.1141, -0.0368,\n",
       "             0.0604, -0.0161, -0.0702, -0.0390, -0.0025, -0.0097],\n",
       "           [ 0.0094, -0.0896,  0.0355,  0.0680,  0.0865,  0.1035,  0.0016,\n",
       "             0.0174,  0.0303,  0.0161,  0.0331,  0.0249,  0.0952, -0.0318,\n",
       "             0.0602, -0.0079, -0.0737, -0.0501,  0.0081, -0.0083],\n",
       "           [ 0.0080, -0.0781,  0.0379,  0.0825,  0.0991,  0.1106, -0.0040,\n",
       "             0.0038,  0.0102,  0.0237,  0.0336,  0.0235,  0.1048, -0.0320,\n",
       "             0.0586, -0.0123, -0.0757, -0.0469,  0.0117, -0.0313]],\n",
       "  \n",
       "          [[ 0.0093, -0.0981,  0.0456,  0.0935,  0.1054,  0.1293,  0.0038,\n",
       "             0.0099,  0.0112,  0.0316,  0.0375,  0.0301,  0.1218, -0.0180,\n",
       "             0.0729, -0.0177, -0.0886, -0.0619,  0.0127, -0.0387],\n",
       "           [ 0.0085, -0.1053,  0.0301,  0.1032,  0.1001,  0.1138, -0.0158,\n",
       "             0.0238,  0.0017,  0.0263,  0.0357,  0.0156,  0.1252, -0.0216,\n",
       "             0.0585, -0.0252, -0.0986, -0.0561,  0.0163, -0.0218],\n",
       "           [ 0.0247, -0.1070,  0.0476,  0.0852,  0.1125,  0.1026, -0.0028,\n",
       "             0.0188,  0.0023,  0.0131,  0.0353,  0.0279,  0.1282, -0.0341,\n",
       "             0.0680, -0.0210, -0.0898, -0.0447,  0.0107, -0.0034],\n",
       "           [ 0.0083, -0.1125,  0.0399,  0.0803,  0.0984,  0.1178, -0.0084,\n",
       "             0.0217,  0.0256,  0.0182,  0.0415,  0.0236,  0.1094, -0.0266,\n",
       "             0.0664, -0.0092, -0.0925, -0.0615,  0.0232,  0.0018],\n",
       "           [ 0.0032, -0.0954,  0.0434,  0.0952,  0.1064,  0.1317, -0.0108,\n",
       "             0.0035, -0.0025,  0.0219,  0.0435,  0.0226,  0.1152, -0.0243,\n",
       "             0.0645, -0.0145, -0.0890, -0.0564,  0.0247, -0.0313]],\n",
       "  \n",
       "          [[ 0.0111, -0.1127,  0.0492,  0.1071,  0.1136,  0.1375, -0.0077,\n",
       "             0.0111,  0.0013,  0.0334,  0.0478,  0.0271,  0.1303, -0.0105,\n",
       "             0.0752, -0.0249, -0.0976, -0.0725,  0.0206, -0.0395],\n",
       "           [ 0.0095, -0.1161,  0.0289,  0.1178,  0.1029,  0.1209, -0.0257,\n",
       "             0.0272, -0.0131,  0.0260,  0.0454,  0.0127,  0.1328, -0.0132,\n",
       "             0.0566, -0.0318, -0.1086, -0.0617,  0.0249, -0.0173],\n",
       "           [ 0.0281, -0.1151,  0.0481,  0.0984,  0.1145,  0.1094, -0.0133,\n",
       "             0.0212, -0.0109,  0.0131,  0.0467,  0.0274,  0.1408, -0.0303,\n",
       "             0.0711, -0.0299, -0.1000, -0.0545,  0.0087, -0.0011],\n",
       "           [ 0.0065, -0.1209,  0.0394,  0.0876,  0.1045,  0.1244, -0.0193,\n",
       "             0.0243,  0.0185,  0.0182,  0.0494,  0.0214,  0.1135, -0.0213,\n",
       "             0.0678, -0.0114, -0.1039, -0.0715,  0.0329,  0.0082],\n",
       "           [ 0.0030, -0.0994,  0.0423,  0.1048,  0.1062,  0.1444, -0.0226,\n",
       "             0.0054, -0.0150,  0.0198,  0.0536,  0.0197,  0.1251, -0.0187,\n",
       "             0.0648, -0.0213, -0.1005, -0.0620,  0.0292, -0.0306]],\n",
       "  \n",
       "          [[ 0.0103, -0.1177,  0.0475,  0.1156,  0.1147,  0.1433, -0.0161,\n",
       "             0.0125, -0.0063,  0.0339,  0.0547,  0.0256,  0.1353, -0.0047,\n",
       "             0.0756, -0.0309, -0.1034, -0.0826,  0.0244, -0.0410],\n",
       "           [ 0.0138, -0.1144,  0.0271,  0.1244,  0.1089,  0.1256, -0.0323,\n",
       "             0.0340, -0.0256,  0.0307,  0.0512,  0.0094,  0.1392, -0.0072,\n",
       "             0.0575, -0.0362, -0.1155, -0.0641,  0.0270, -0.0111],\n",
       "           [ 0.0287, -0.1190,  0.0461,  0.1061,  0.1107,  0.1135, -0.0253,\n",
       "             0.0222, -0.0209,  0.0082,  0.0549,  0.0254,  0.1476, -0.0269,\n",
       "             0.0706, -0.0369, -0.1075, -0.0576,  0.0123,  0.0044],\n",
       "           [ 0.0053, -0.1193,  0.0366,  0.0936,  0.1059,  0.1295, -0.0311,\n",
       "             0.0237,  0.0137,  0.0200,  0.0633,  0.0177,  0.1147, -0.0184,\n",
       "             0.0673, -0.0160, -0.1091, -0.0768,  0.0359,  0.0097],\n",
       "           [ 0.0023, -0.1008,  0.0408,  0.1071,  0.1081,  0.1501, -0.0327,\n",
       "             0.0096, -0.0249,  0.0200,  0.0584,  0.0144,  0.1246, -0.0177,\n",
       "             0.0642, -0.0255, -0.1047, -0.0708,  0.0347, -0.0297]],\n",
       "  \n",
       "          [[ 0.0075, -0.1199,  0.0457,  0.1209,  0.1145,  0.1483, -0.0208,\n",
       "             0.0147, -0.0097,  0.0342,  0.0587,  0.0260,  0.1361, -0.0012,\n",
       "             0.0754, -0.0320, -0.1052, -0.0891,  0.0278, -0.0370],\n",
       "           [ 0.0169, -0.1124,  0.0190,  0.1276,  0.1009,  0.1280, -0.0399,\n",
       "             0.0348, -0.0339,  0.0316,  0.0565,  0.0027,  0.1431, -0.0080,\n",
       "             0.0546, -0.0403, -0.1233, -0.0635,  0.0265, -0.0108],\n",
       "           [ 0.0293, -0.1132,  0.0405,  0.1103,  0.1103,  0.1196, -0.0321,\n",
       "             0.0249, -0.0270,  0.0019,  0.0586,  0.0228,  0.1504, -0.0275,\n",
       "             0.0720, -0.0375, -0.1143, -0.0631,  0.0162,  0.0065],\n",
       "           [ 0.0024, -0.1118,  0.0333,  0.0961,  0.1083,  0.1317, -0.0414,\n",
       "             0.0254,  0.0082,  0.0201,  0.0720,  0.0177,  0.1151, -0.0164,\n",
       "             0.0655, -0.0177, -0.1117, -0.0826,  0.0357,  0.0068],\n",
       "           [ 0.0055, -0.1032,  0.0384,  0.1129,  0.1097,  0.1513, -0.0381,\n",
       "             0.0062, -0.0314,  0.0188,  0.0679,  0.0100,  0.1262, -0.0154,\n",
       "             0.0586, -0.0305, -0.1029, -0.0724,  0.0371, -0.0310]],\n",
       "  \n",
       "          [[ 0.0052, -0.1146,  0.0416,  0.1232,  0.1120,  0.1530, -0.0216,\n",
       "             0.0150, -0.0126,  0.0339,  0.0606,  0.0283,  0.1380, -0.0007,\n",
       "             0.0764, -0.0360, -0.1074, -0.0946,  0.0277, -0.0369],\n",
       "           [ 0.0189, -0.1085,  0.0191,  0.1333,  0.1010,  0.1302, -0.0453,\n",
       "             0.0385, -0.0351,  0.0301,  0.0605, -0.0003,  0.1457, -0.0063,\n",
       "             0.0496, -0.0424, -0.1236, -0.0670,  0.0273, -0.0099],\n",
       "           [ 0.0311, -0.1065,  0.0375,  0.1151,  0.1135,  0.1227, -0.0360,\n",
       "             0.0319, -0.0279,  0.0002,  0.0600,  0.0227,  0.1557, -0.0287,\n",
       "             0.0713, -0.0385, -0.1161, -0.0706,  0.0123,  0.0119],\n",
       "           [ 0.0027, -0.1085,  0.0291,  0.0965,  0.1085,  0.1327, -0.0467,\n",
       "             0.0266,  0.0099,  0.0192,  0.0772,  0.0175,  0.1175, -0.0177,\n",
       "             0.0613, -0.0206, -0.1152, -0.0900,  0.0378,  0.0048],\n",
       "           [ 0.0095, -0.0943,  0.0385,  0.1167,  0.1090,  0.1562, -0.0400,\n",
       "             0.0018, -0.0337,  0.0172,  0.0741,  0.0106,  0.1282, -0.0131,\n",
       "             0.0557, -0.0320, -0.1054, -0.0769,  0.0396, -0.0335]],\n",
       "  \n",
       "          [[ 0.0062, -0.1137,  0.0350,  0.1260,  0.1096,  0.1565, -0.0238,\n",
       "             0.0183, -0.0154,  0.0331,  0.0615,  0.0278,  0.1376,  0.0014,\n",
       "             0.0759, -0.0372, -0.1133, -0.0949,  0.0261, -0.0338],\n",
       "           [ 0.0200, -0.1061,  0.0220,  0.1373,  0.1007,  0.1310, -0.0492,\n",
       "             0.0415, -0.0332,  0.0294,  0.0632, -0.0019,  0.1485, -0.0059,\n",
       "             0.0429, -0.0454, -0.1194, -0.0726,  0.0278, -0.0102],\n",
       "           [ 0.0326, -0.1084,  0.0401,  0.1212,  0.1132,  0.1206, -0.0391,\n",
       "             0.0302, -0.0300, -0.0003,  0.0666,  0.0228,  0.1575, -0.0280,\n",
       "             0.0700, -0.0418, -0.1145, -0.0759,  0.0107,  0.0105],\n",
       "           [ 0.0030, -0.1093,  0.0267,  0.0967,  0.1084,  0.1328, -0.0506,\n",
       "             0.0282,  0.0069,  0.0178,  0.0800,  0.0181,  0.1191, -0.0193,\n",
       "             0.0610, -0.0231, -0.1160, -0.0918,  0.0355,  0.0052],\n",
       "           [ 0.0082, -0.0856,  0.0389,  0.1170,  0.1137,  0.1605, -0.0392,\n",
       "             0.0023, -0.0334,  0.0179,  0.0761,  0.0109,  0.1329, -0.0133,\n",
       "             0.0562, -0.0353, -0.1054, -0.0784,  0.0367, -0.0356]],\n",
       "  \n",
       "          [[ 0.0069, -0.1052,  0.0329,  0.1239,  0.1102,  0.1594, -0.0243,\n",
       "             0.0205, -0.0172,  0.0316,  0.0619,  0.0292,  0.1411,  0.0019,\n",
       "             0.0765, -0.0400, -0.1167, -0.0963,  0.0244, -0.0335],\n",
       "           [ 0.0206, -0.0994,  0.0201,  0.1342,  0.0978,  0.1344, -0.0517,\n",
       "             0.0436, -0.0326,  0.0299,  0.0603, -0.0018,  0.1514, -0.0122,\n",
       "             0.0432, -0.0454, -0.1185, -0.0757,  0.0268, -0.0147],\n",
       "           [ 0.0333, -0.1060,  0.0360,  0.1247,  0.1109,  0.1212, -0.0407,\n",
       "             0.0319, -0.0311, -0.0005,  0.0676,  0.0231,  0.1583, -0.0279,\n",
       "             0.0693, -0.0423, -0.1156, -0.0794,  0.0092,  0.0139],\n",
       "           [ 0.0042, -0.1095,  0.0254,  0.0981,  0.1099,  0.1327, -0.0517,\n",
       "             0.0304,  0.0055,  0.0159,  0.0785,  0.0197,  0.1210, -0.0201,\n",
       "             0.0611, -0.0252, -0.1159, -0.0938,  0.0359,  0.0067],\n",
       "           [ 0.0075, -0.0833,  0.0398,  0.1182,  0.1139,  0.1600, -0.0410,\n",
       "             0.0042, -0.0328,  0.0175,  0.0771,  0.0117,  0.1339, -0.0135,\n",
       "             0.0567, -0.0371, -0.1066, -0.0812,  0.0347, -0.0351]],\n",
       "  \n",
       "          [[ 0.0063, -0.1013,  0.0349,  0.1234,  0.1120,  0.1582, -0.0251,\n",
       "             0.0191, -0.0154,  0.0291,  0.0661,  0.0268,  0.1419,  0.0040,\n",
       "             0.0770, -0.0407, -0.1125, -0.1028,  0.0260, -0.0374],\n",
       "           [ 0.0226, -0.0979,  0.0188,  0.1351,  0.1006,  0.1347, -0.0524,\n",
       "             0.0448, -0.0372,  0.0329,  0.0625, -0.0015,  0.1541, -0.0118,\n",
       "             0.0447, -0.0468, -0.1215, -0.0732,  0.0240, -0.0134],\n",
       "           [ 0.0349, -0.1033,  0.0350,  0.1270,  0.1119,  0.1213, -0.0419,\n",
       "             0.0336, -0.0300,  0.0005,  0.0685,  0.0230,  0.1595, -0.0264,\n",
       "             0.0693, -0.0436, -0.1159, -0.0805,  0.0105,  0.0150],\n",
       "           [ 0.0072, -0.1132,  0.0256,  0.0983,  0.1125,  0.1303, -0.0499,\n",
       "             0.0323,  0.0045,  0.0141,  0.0703,  0.0219,  0.1239, -0.0195,\n",
       "             0.0611, -0.0239, -0.1143, -0.0954,  0.0398,  0.0111],\n",
       "           [ 0.0085, -0.0816,  0.0389,  0.1172,  0.1104,  0.1571, -0.0470,\n",
       "             0.0063, -0.0333,  0.0199,  0.0799,  0.0083,  0.1328, -0.0147,\n",
       "             0.0547, -0.0404, -0.1035, -0.0844,  0.0334, -0.0373]]],\n",
       "         grad_fn=<CatBackward>)])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tst_input.clone()\n",
    "z = tst_model(x)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tst_output.clone()\n",
    "loss = F.nll_loss(z[0], y)\n",
    "loss.backward()\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0771, -0.0582, -0.0595,  ..., -0.0704,  0.0910, -0.0049],\n",
       "        [ 0.0232,  0.0282,  0.0036,  ...,  0.0123,  0.0911, -0.0684],\n",
       "        [ 0.0752, -0.0123,  0.0452,  ..., -0.0631, -0.0344,  0.0208],\n",
       "        ...,\n",
       "        [-0.0841, -0.0302,  0.0260,  ...,  0.0346, -0.0877, -0.0890],\n",
       "        [-0.0016,  0.0072,  0.0175,  ...,  0.0442,  0.0095,  0.0981],\n",
       "        [ 0.0968,  0.0940, -0.0924,  ..., -0.0098,  0.0201, -0.0284]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_model[0].rnns[0].module._parameters['weight_hh_l0_raw']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNDropout(nn.Module):\n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__()\n",
    "        self.p=p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.training or not self.p: return x\n",
    "        m = dropout_mask(x.data, (1, x.size(1), x.size(2)), self.p)\n",
    "        return m * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repackage_var1(h):\n",
    "    \"Detaches h from its history.\"\n",
    "    return h.detach() if type(h) == torch.Tensor else tuple(repackage_var(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCore(nn.Module):\n",
    "    \"AWD-LSTM/QRNN inspired by https://arxiv.org/abs/1708.02182\"\n",
    "\n",
    "    initrange=0.1\n",
    "\n",
    "    def __init__(self, vocab_sz, emb_sz, n_hid, n_layers, pad_token, bidir=False,\n",
    "                 hidden_p=0.2, input_p=0.6, embed_p=0.1, weight_p=0.5, qrnn=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.bs,self.qrnn,self.ndir = 1, qrnn,(2 if bidir else 1)\n",
    "        self.emb_sz,self.n_hid,self.n_layers = emb_sz,n_hid,n_layers\n",
    "        self.encoder = nn.Embedding(vocab_sz, emb_sz, padding_idx=pad_token)\n",
    "        self.dp_encoder = EmbeddingDropout1(self.encoder, embed_p)\n",
    "        if self.qrnn:\n",
    "            #Using QRNN requires cupy: https://github.com/cupy/cupy\n",
    "            from .torchqrnn.qrnn import QRNNLayer\n",
    "            self.rnns = [QRNNLayer(emb_sz if l == 0 else n_hid, (n_hid if l != n_layers - 1 else emb_sz)//self.ndir,\n",
    "                save_prev_x=True, zoneout=0, window=2 if l == 0 else 1, output_gate=True) for l in range(n_layers)]\n",
    "            if weight_p != 0.:\n",
    "                for rnn in self.rnns:\n",
    "                    rnn.linear = WeightDropout(rnn.linear, weight_p, layer_names=['weight'])\n",
    "        else:\n",
    "            self.rnns = [nn.LSTM(emb_sz if l == 0 else n_hid, (n_hid if l != n_layers - 1 else emb_sz)//self.ndir,\n",
    "                1, bidirectional=bidir) for l in range(n_layers)]\n",
    "            if weight_p != 0.: self.rnns = [WeightDropout(rnn, weight_p) for rnn in self.rnns]\n",
    "        self.rnns = torch.nn.ModuleList(self.rnns)\n",
    "        self.encoder.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.dropouti = RNNDropout(input_p)\n",
    "        self.dropouths = nn.ModuleList([RNNDropout(hidden_p) for l in range(n_layers)])\n",
    "\n",
    "    def forward(self, input):\n",
    "        sl,bs = input.size()\n",
    "        if bs!=self.bs:\n",
    "            self.bs=bs\n",
    "            self.reset()\n",
    "        raw_output = self.dropouti(self.dp_encoder(input))\n",
    "        new_hidden,raw_outputs,outputs = [],[],[]\n",
    "        for l, (rnn,drop) in enumerate(zip(self.rnns, self.dropouths)):\n",
    "            with warnings.catch_warnings():\n",
    "                #To avoid the warning that comes because the weights aren't flattened.\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                raw_output, new_h = rnn(raw_output, self.hidden[l])\n",
    "            new_hidden.append(new_h)\n",
    "            raw_outputs.append(raw_output)\n",
    "            if l != self.n_layers - 1: raw_output = drop(raw_output)\n",
    "            outputs.append(raw_output)\n",
    "        self.hidden = repackage_var1(new_hidden)\n",
    "        return raw_outputs, outputs\n",
    "\n",
    "    def one_hidden(self, l):\n",
    "        nh = (self.n_hid if l != self.n_layers - 1 else self.emb_sz)//self.ndir\n",
    "        return self.weights.new(self.ndir, self.bs, nh).zero_()\n",
    "\n",
    "    def reset(self):\n",
    "        [r.reset() for r in self.rnns if hasattr(r, 'reset')]\n",
    "        self.weights = next(self.parameters()).data\n",
    "        if self.qrnn: self.hidden = [self.one_hidden(l) for l in range(self.n_layers)]\n",
    "        else: self.hidden = [(self.one_hidden(l), self.one_hidden(l)) for l in range(self.n_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearDecoder1(nn.Module):\n",
    "    \"To go on top of a RNN_Core module\"\n",
    "    \n",
    "    initrange=0.1\n",
    "    \n",
    "    def __init__(self, n_out, n_hid, output_p, tie_encoder=None, bias=True):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Linear(n_hid, n_out, bias=bias)\n",
    "        self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.dropout = RNNDropout(output_p)\n",
    "        if bias: self.decoder.bias.data.zero_()\n",
    "        if tie_encoder: self.decoder.weight = tie_encoder.weight\n",
    "\n",
    "    def forward(self, input):\n",
    "        raw_outputs, outputs = input\n",
    "        output = self.dropout(outputs[-1])\n",
    "        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n",
    "        return decoded, raw_outputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialRNN1(nn.Sequential):\n",
    "    def reset(self):\n",
    "        for c in self.children():\n",
    "            if hasattr(c, 'reset'): c.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language_model1(vocab_sz, emb_sz, n_hid, n_layers, pad_token, tie_weights=True, qrnn=False, bias=True,\n",
    "                 output_p=0.4, hidden_p=0.2, input_p=0.6, embed_p=0.1, weight_p=0.5):\n",
    "    \"To create a full AWD-LSTM\"\n",
    "    rnn_enc = RNNCore(vocab_sz, emb_sz, n_hid=n_hid, n_layers=n_layers, pad_token=pad_token, qrnn=qrnn,\n",
    "                 hidden_p=hidden_p, input_p=input_p, embed_p=embed_p, weight_p=weight_p)\n",
    "    enc = rnn_enc.encoder if tie_weights else None\n",
    "    return SequentialRNN1(rnn_enc, LinearDecoder1(vocab_sz, emb_sz, output_p, tie_encoder=enc, bias=bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new model has weights that are organized a bit differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_parameters1 = {}\n",
    "for n,p in save_parameters.items(): \n",
    "    if 'weight_hh_l0' not in n and n!='0.encoder_with_dropout.embed.weight':  save_parameters1[n] = p.clone()\n",
    "    elif n=='0.encoder_with_dropout.embed.weight': save_parameters1['0.dp_encoder.emb.weight'] = p.clone()\n",
    "    else: \n",
    "        save_parameters1[n[:-4]] = p.clone()\n",
    "        splits = n.split('.')\n",
    "        splits.remove(splits[-2])\n",
    "        n1 = '.'.join(splits)\n",
    "        save_parameters1[n1] = p.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_model = get_language_model1(500, 20, 100, 2, 0)\n",
    "tst_model.load_state_dict(save_parameters1)\n",
    "opt = optim.SGD(tst_model.parameters(), lr=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x267b3a7b390>"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0005, -0.0192, -0.0097,  ...,  0.0120, -0.0285,  0.0068],\n",
       "         [-0.0041, -0.0030, -0.0108,  ...,  0.0085, -0.0356,  0.0088],\n",
       "         [-0.0015, -0.0161, -0.0064,  ...,  0.0086, -0.0198, -0.0061],\n",
       "         ...,\n",
       "         [ 0.0008, -0.0327, -0.0184,  ...,  0.0314, -0.0460, -0.0368],\n",
       "         [-0.0005, -0.0168, -0.0430,  ...,  0.0091, -0.0292, -0.0235],\n",
       "         [ 0.0047, -0.0315, -0.0145,  ...,  0.0085, -0.0557, -0.0512]],\n",
       "        grad_fn=<ThAddmmBackward>),\n",
       " [tensor([[[-0.0070,  0.0093, -0.0127,  ..., -0.0127,  0.0019, -0.0122],\n",
       "           [-0.0068,  0.0088, -0.0119,  ..., -0.0070,  0.0131, -0.0127],\n",
       "           [-0.0110,  0.0003, -0.0091,  ..., -0.0199,  0.0036, -0.0174],\n",
       "           [-0.0074,  0.0093, -0.0167,  ..., -0.0118,  0.0063, -0.0096],\n",
       "           [-0.0122,  0.0024, -0.0095,  ..., -0.0059,  0.0143, -0.0146]],\n",
       "  \n",
       "          [[-0.0131,  0.0122, -0.0341,  ..., -0.0250,  0.0075, -0.0314],\n",
       "           [-0.0305,  0.0160, -0.0145,  ..., -0.0261,  0.0096, -0.0248],\n",
       "           [-0.0156,  0.0060, -0.0250,  ..., -0.0289,  0.0052, -0.0264],\n",
       "           [-0.0252,  0.0162, -0.0231,  ..., -0.0226, -0.0059, -0.0227],\n",
       "           [-0.0122,  0.0075, -0.0188,  ..., -0.0197,  0.0179, -0.0317]],\n",
       "  \n",
       "          [[-0.0364,  0.0204, -0.0375,  ..., -0.0202,  0.0093, -0.0545],\n",
       "           [-0.0378,  0.0034, -0.0357,  ..., -0.0222,  0.0020, -0.0243],\n",
       "           [-0.0384,  0.0205, -0.0362,  ..., -0.0225,  0.0057, -0.0340],\n",
       "           [-0.0288,  0.0173, -0.0345,  ..., -0.0204,  0.0023, -0.0248],\n",
       "           [-0.0439,  0.0311, -0.0301,  ..., -0.0237,  0.0070, -0.0424]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-0.0371,  0.0248, -0.0613,  ..., -0.0040,  0.0092, -0.0508],\n",
       "           [-0.0551,  0.0169, -0.0547,  ..., -0.0137, -0.0230, -0.0119],\n",
       "           [-0.0498,  0.0377, -0.0509,  ..., -0.0042,  0.0015, -0.0453],\n",
       "           [-0.0260,  0.0238, -0.0565,  ..., -0.0023,  0.0011, -0.0342],\n",
       "           [-0.0308,  0.0279, -0.0596,  ..., -0.0109,  0.0051, -0.0586]],\n",
       "  \n",
       "          [[-0.0317,  0.0273, -0.0557,  ...,  0.0014,  0.0064, -0.0592],\n",
       "           [-0.0408,  0.0299, -0.0561,  ..., -0.0096, -0.0044, -0.0348],\n",
       "           [-0.0495,  0.0350, -0.0518,  ..., -0.0054,  0.0018, -0.0491],\n",
       "           [-0.0316,  0.0234, -0.0572,  ..., -0.0048,  0.0033, -0.0400],\n",
       "           [-0.0321,  0.0256, -0.0598,  ..., -0.0088,  0.0040, -0.0531]],\n",
       "  \n",
       "          [[-0.0402,  0.0201, -0.0639,  ...,  0.0014, -0.0010, -0.0491],\n",
       "           [-0.0397,  0.0223, -0.0510,  ..., -0.0090, -0.0068, -0.0331],\n",
       "           [-0.0475,  0.0322, -0.0564,  ..., -0.0061,  0.0039, -0.0451],\n",
       "           [-0.0406,  0.0212, -0.0570,  ..., -0.0085,  0.0095, -0.0397],\n",
       "           [-0.0424,  0.0363, -0.0562,  ..., -0.0074, -0.0058, -0.0479]]],\n",
       "         grad_fn=<CatBackward>),\n",
       "  tensor([[[ 0.0117, -0.0472,  0.0226,  0.0451,  0.0607,  0.0681,  0.0104,\n",
       "             0.0026,  0.0244,  0.0238,  0.0170,  0.0170,  0.0718, -0.0289,\n",
       "             0.0440, -0.0112, -0.0432, -0.0339, -0.0070, -0.0299],\n",
       "           [ 0.0083, -0.0503,  0.0170,  0.0470,  0.0546,  0.0663,  0.0029,\n",
       "             0.0080,  0.0247,  0.0184,  0.0155,  0.0130,  0.0723, -0.0325,\n",
       "             0.0396, -0.0100, -0.0479, -0.0293, -0.0057, -0.0225],\n",
       "           [ 0.0172, -0.0480,  0.0234,  0.0450,  0.0669,  0.0664,  0.0093,\n",
       "             0.0118,  0.0216,  0.0148,  0.0185,  0.0172,  0.0762, -0.0335,\n",
       "             0.0421, -0.0090, -0.0400, -0.0285, -0.0091, -0.0158],\n",
       "           [ 0.0099, -0.0532,  0.0251,  0.0441,  0.0599,  0.0721,  0.0087,\n",
       "             0.0099,  0.0297,  0.0121,  0.0210,  0.0186,  0.0632, -0.0298,\n",
       "             0.0400, -0.0039, -0.0437, -0.0351, -0.0034, -0.0140],\n",
       "           [ 0.0117, -0.0458,  0.0224,  0.0519,  0.0641,  0.0720,  0.0023,\n",
       "            -0.0003,  0.0171,  0.0194,  0.0227,  0.0136,  0.0684, -0.0322,\n",
       "             0.0400, -0.0070, -0.0448, -0.0311,  0.0014, -0.0276]],\n",
       "  \n",
       "          [[ 0.0090, -0.0780,  0.0383,  0.0749,  0.0917,  0.1076,  0.0121,\n",
       "             0.0066,  0.0218,  0.0330,  0.0267,  0.0272,  0.1038, -0.0276,\n",
       "             0.0663, -0.0140, -0.0723, -0.0486,  0.0023, -0.0364],\n",
       "           [ 0.0086, -0.0865,  0.0290,  0.0805,  0.0853,  0.0988, -0.0051,\n",
       "             0.0194,  0.0168,  0.0240,  0.0255,  0.0187,  0.1086, -0.0298,\n",
       "             0.0537, -0.0182, -0.0787, -0.0447,  0.0047, -0.0223],\n",
       "           [ 0.0238, -0.0835,  0.0372,  0.0721,  0.0984,  0.0928,  0.0051,\n",
       "             0.0198,  0.0151,  0.0177,  0.0286,  0.0256,  0.1141, -0.0368,\n",
       "             0.0604, -0.0161, -0.0702, -0.0390, -0.0025, -0.0097],\n",
       "           [ 0.0094, -0.0896,  0.0355,  0.0680,  0.0865,  0.1035,  0.0016,\n",
       "             0.0174,  0.0303,  0.0161,  0.0331,  0.0249,  0.0952, -0.0318,\n",
       "             0.0602, -0.0079, -0.0737, -0.0501,  0.0081, -0.0083],\n",
       "           [ 0.0080, -0.0781,  0.0379,  0.0825,  0.0991,  0.1106, -0.0040,\n",
       "             0.0038,  0.0102,  0.0237,  0.0336,  0.0235,  0.1048, -0.0320,\n",
       "             0.0586, -0.0123, -0.0757, -0.0469,  0.0117, -0.0313]],\n",
       "  \n",
       "          [[ 0.0093, -0.0981,  0.0456,  0.0935,  0.1054,  0.1293,  0.0038,\n",
       "             0.0099,  0.0112,  0.0316,  0.0375,  0.0301,  0.1218, -0.0180,\n",
       "             0.0729, -0.0177, -0.0886, -0.0619,  0.0127, -0.0387],\n",
       "           [ 0.0085, -0.1053,  0.0301,  0.1032,  0.1001,  0.1138, -0.0158,\n",
       "             0.0238,  0.0017,  0.0263,  0.0357,  0.0156,  0.1252, -0.0216,\n",
       "             0.0585, -0.0252, -0.0986, -0.0561,  0.0163, -0.0218],\n",
       "           [ 0.0247, -0.1070,  0.0476,  0.0852,  0.1125,  0.1026, -0.0028,\n",
       "             0.0188,  0.0023,  0.0131,  0.0353,  0.0279,  0.1282, -0.0341,\n",
       "             0.0680, -0.0210, -0.0898, -0.0447,  0.0107, -0.0034],\n",
       "           [ 0.0083, -0.1125,  0.0399,  0.0803,  0.0984,  0.1178, -0.0084,\n",
       "             0.0217,  0.0256,  0.0182,  0.0415,  0.0236,  0.1094, -0.0266,\n",
       "             0.0664, -0.0092, -0.0925, -0.0615,  0.0232,  0.0018],\n",
       "           [ 0.0032, -0.0954,  0.0434,  0.0952,  0.1064,  0.1317, -0.0108,\n",
       "             0.0035, -0.0025,  0.0219,  0.0435,  0.0226,  0.1152, -0.0243,\n",
       "             0.0645, -0.0145, -0.0890, -0.0564,  0.0247, -0.0313]],\n",
       "  \n",
       "          [[ 0.0111, -0.1127,  0.0492,  0.1071,  0.1136,  0.1375, -0.0077,\n",
       "             0.0111,  0.0013,  0.0334,  0.0478,  0.0271,  0.1303, -0.0105,\n",
       "             0.0752, -0.0249, -0.0976, -0.0725,  0.0206, -0.0395],\n",
       "           [ 0.0095, -0.1161,  0.0289,  0.1178,  0.1029,  0.1209, -0.0257,\n",
       "             0.0272, -0.0131,  0.0260,  0.0454,  0.0127,  0.1328, -0.0132,\n",
       "             0.0566, -0.0318, -0.1086, -0.0617,  0.0249, -0.0173],\n",
       "           [ 0.0281, -0.1151,  0.0481,  0.0984,  0.1145,  0.1094, -0.0133,\n",
       "             0.0212, -0.0109,  0.0131,  0.0467,  0.0274,  0.1408, -0.0303,\n",
       "             0.0711, -0.0299, -0.1000, -0.0545,  0.0087, -0.0011],\n",
       "           [ 0.0065, -0.1209,  0.0394,  0.0876,  0.1045,  0.1244, -0.0193,\n",
       "             0.0243,  0.0185,  0.0182,  0.0494,  0.0214,  0.1135, -0.0213,\n",
       "             0.0678, -0.0114, -0.1039, -0.0715,  0.0329,  0.0082],\n",
       "           [ 0.0030, -0.0994,  0.0423,  0.1048,  0.1062,  0.1444, -0.0226,\n",
       "             0.0054, -0.0150,  0.0198,  0.0536,  0.0197,  0.1251, -0.0187,\n",
       "             0.0648, -0.0213, -0.1005, -0.0620,  0.0292, -0.0306]],\n",
       "  \n",
       "          [[ 0.0103, -0.1177,  0.0475,  0.1156,  0.1147,  0.1433, -0.0161,\n",
       "             0.0125, -0.0063,  0.0339,  0.0547,  0.0256,  0.1353, -0.0047,\n",
       "             0.0756, -0.0309, -0.1034, -0.0826,  0.0244, -0.0410],\n",
       "           [ 0.0138, -0.1144,  0.0271,  0.1244,  0.1089,  0.1256, -0.0323,\n",
       "             0.0340, -0.0256,  0.0307,  0.0512,  0.0094,  0.1392, -0.0072,\n",
       "             0.0575, -0.0362, -0.1155, -0.0641,  0.0270, -0.0111],\n",
       "           [ 0.0287, -0.1190,  0.0461,  0.1061,  0.1107,  0.1135, -0.0253,\n",
       "             0.0222, -0.0209,  0.0082,  0.0549,  0.0254,  0.1476, -0.0269,\n",
       "             0.0706, -0.0369, -0.1075, -0.0576,  0.0123,  0.0044],\n",
       "           [ 0.0053, -0.1193,  0.0366,  0.0936,  0.1059,  0.1295, -0.0311,\n",
       "             0.0237,  0.0137,  0.0200,  0.0633,  0.0177,  0.1147, -0.0184,\n",
       "             0.0673, -0.0160, -0.1091, -0.0768,  0.0359,  0.0097],\n",
       "           [ 0.0023, -0.1008,  0.0408,  0.1071,  0.1081,  0.1501, -0.0327,\n",
       "             0.0096, -0.0249,  0.0200,  0.0584,  0.0144,  0.1246, -0.0177,\n",
       "             0.0642, -0.0255, -0.1047, -0.0708,  0.0347, -0.0297]],\n",
       "  \n",
       "          [[ 0.0075, -0.1199,  0.0457,  0.1209,  0.1145,  0.1483, -0.0208,\n",
       "             0.0147, -0.0097,  0.0342,  0.0587,  0.0260,  0.1361, -0.0012,\n",
       "             0.0754, -0.0320, -0.1052, -0.0891,  0.0278, -0.0370],\n",
       "           [ 0.0169, -0.1124,  0.0190,  0.1276,  0.1009,  0.1280, -0.0399,\n",
       "             0.0348, -0.0339,  0.0316,  0.0565,  0.0027,  0.1431, -0.0080,\n",
       "             0.0546, -0.0403, -0.1233, -0.0635,  0.0265, -0.0108],\n",
       "           [ 0.0293, -0.1132,  0.0405,  0.1103,  0.1103,  0.1196, -0.0321,\n",
       "             0.0249, -0.0270,  0.0019,  0.0586,  0.0228,  0.1504, -0.0275,\n",
       "             0.0720, -0.0375, -0.1143, -0.0631,  0.0162,  0.0065],\n",
       "           [ 0.0024, -0.1118,  0.0333,  0.0961,  0.1083,  0.1317, -0.0414,\n",
       "             0.0254,  0.0082,  0.0201,  0.0720,  0.0177,  0.1151, -0.0164,\n",
       "             0.0655, -0.0177, -0.1117, -0.0826,  0.0357,  0.0068],\n",
       "           [ 0.0055, -0.1032,  0.0384,  0.1129,  0.1097,  0.1513, -0.0381,\n",
       "             0.0062, -0.0314,  0.0188,  0.0679,  0.0100,  0.1262, -0.0154,\n",
       "             0.0586, -0.0305, -0.1029, -0.0724,  0.0371, -0.0310]],\n",
       "  \n",
       "          [[ 0.0052, -0.1146,  0.0416,  0.1232,  0.1120,  0.1530, -0.0216,\n",
       "             0.0150, -0.0126,  0.0339,  0.0606,  0.0283,  0.1380, -0.0007,\n",
       "             0.0764, -0.0360, -0.1074, -0.0946,  0.0277, -0.0369],\n",
       "           [ 0.0189, -0.1085,  0.0191,  0.1333,  0.1010,  0.1302, -0.0453,\n",
       "             0.0385, -0.0351,  0.0301,  0.0605, -0.0003,  0.1457, -0.0063,\n",
       "             0.0496, -0.0424, -0.1236, -0.0670,  0.0273, -0.0099],\n",
       "           [ 0.0311, -0.1065,  0.0375,  0.1151,  0.1135,  0.1227, -0.0360,\n",
       "             0.0319, -0.0279,  0.0002,  0.0600,  0.0227,  0.1557, -0.0287,\n",
       "             0.0713, -0.0385, -0.1161, -0.0706,  0.0123,  0.0119],\n",
       "           [ 0.0027, -0.1085,  0.0291,  0.0965,  0.1085,  0.1327, -0.0467,\n",
       "             0.0266,  0.0099,  0.0192,  0.0772,  0.0175,  0.1175, -0.0177,\n",
       "             0.0613, -0.0206, -0.1152, -0.0900,  0.0378,  0.0048],\n",
       "           [ 0.0095, -0.0943,  0.0385,  0.1167,  0.1090,  0.1562, -0.0400,\n",
       "             0.0018, -0.0337,  0.0172,  0.0741,  0.0106,  0.1282, -0.0131,\n",
       "             0.0557, -0.0320, -0.1054, -0.0769,  0.0396, -0.0335]],\n",
       "  \n",
       "          [[ 0.0062, -0.1137,  0.0350,  0.1260,  0.1096,  0.1565, -0.0238,\n",
       "             0.0183, -0.0154,  0.0331,  0.0615,  0.0278,  0.1376,  0.0014,\n",
       "             0.0759, -0.0372, -0.1133, -0.0949,  0.0261, -0.0338],\n",
       "           [ 0.0200, -0.1061,  0.0220,  0.1373,  0.1007,  0.1310, -0.0492,\n",
       "             0.0415, -0.0332,  0.0294,  0.0632, -0.0019,  0.1485, -0.0059,\n",
       "             0.0429, -0.0454, -0.1194, -0.0726,  0.0278, -0.0102],\n",
       "           [ 0.0326, -0.1084,  0.0401,  0.1212,  0.1132,  0.1206, -0.0391,\n",
       "             0.0302, -0.0300, -0.0003,  0.0666,  0.0228,  0.1575, -0.0280,\n",
       "             0.0700, -0.0418, -0.1145, -0.0759,  0.0107,  0.0105],\n",
       "           [ 0.0030, -0.1093,  0.0267,  0.0967,  0.1084,  0.1328, -0.0506,\n",
       "             0.0282,  0.0069,  0.0178,  0.0800,  0.0181,  0.1191, -0.0193,\n",
       "             0.0610, -0.0231, -0.1160, -0.0918,  0.0355,  0.0052],\n",
       "           [ 0.0082, -0.0856,  0.0389,  0.1170,  0.1137,  0.1605, -0.0392,\n",
       "             0.0023, -0.0334,  0.0179,  0.0761,  0.0109,  0.1329, -0.0133,\n",
       "             0.0562, -0.0353, -0.1054, -0.0784,  0.0367, -0.0356]],\n",
       "  \n",
       "          [[ 0.0069, -0.1052,  0.0329,  0.1239,  0.1102,  0.1594, -0.0243,\n",
       "             0.0205, -0.0172,  0.0316,  0.0619,  0.0292,  0.1411,  0.0019,\n",
       "             0.0765, -0.0400, -0.1167, -0.0963,  0.0244, -0.0335],\n",
       "           [ 0.0206, -0.0994,  0.0201,  0.1342,  0.0978,  0.1344, -0.0517,\n",
       "             0.0436, -0.0326,  0.0299,  0.0603, -0.0018,  0.1514, -0.0122,\n",
       "             0.0432, -0.0454, -0.1185, -0.0757,  0.0268, -0.0147],\n",
       "           [ 0.0333, -0.1060,  0.0360,  0.1247,  0.1109,  0.1212, -0.0407,\n",
       "             0.0319, -0.0311, -0.0005,  0.0676,  0.0231,  0.1583, -0.0279,\n",
       "             0.0693, -0.0423, -0.1156, -0.0794,  0.0092,  0.0139],\n",
       "           [ 0.0042, -0.1095,  0.0254,  0.0981,  0.1099,  0.1327, -0.0517,\n",
       "             0.0304,  0.0055,  0.0159,  0.0785,  0.0197,  0.1210, -0.0201,\n",
       "             0.0611, -0.0252, -0.1159, -0.0938,  0.0359,  0.0067],\n",
       "           [ 0.0075, -0.0833,  0.0398,  0.1182,  0.1139,  0.1600, -0.0410,\n",
       "             0.0042, -0.0328,  0.0175,  0.0771,  0.0117,  0.1339, -0.0135,\n",
       "             0.0567, -0.0371, -0.1066, -0.0812,  0.0347, -0.0351]],\n",
       "  \n",
       "          [[ 0.0063, -0.1013,  0.0349,  0.1234,  0.1120,  0.1582, -0.0251,\n",
       "             0.0191, -0.0154,  0.0291,  0.0661,  0.0268,  0.1419,  0.0040,\n",
       "             0.0770, -0.0407, -0.1125, -0.1028,  0.0260, -0.0374],\n",
       "           [ 0.0226, -0.0979,  0.0188,  0.1351,  0.1006,  0.1347, -0.0524,\n",
       "             0.0448, -0.0372,  0.0329,  0.0625, -0.0015,  0.1541, -0.0118,\n",
       "             0.0447, -0.0468, -0.1215, -0.0732,  0.0240, -0.0134],\n",
       "           [ 0.0349, -0.1033,  0.0350,  0.1270,  0.1119,  0.1213, -0.0419,\n",
       "             0.0336, -0.0300,  0.0005,  0.0685,  0.0230,  0.1595, -0.0264,\n",
       "             0.0693, -0.0436, -0.1159, -0.0805,  0.0105,  0.0150],\n",
       "           [ 0.0072, -0.1132,  0.0256,  0.0983,  0.1125,  0.1303, -0.0499,\n",
       "             0.0323,  0.0045,  0.0141,  0.0703,  0.0219,  0.1239, -0.0195,\n",
       "             0.0611, -0.0239, -0.1143, -0.0954,  0.0398,  0.0111],\n",
       "           [ 0.0085, -0.0816,  0.0389,  0.1172,  0.1104,  0.1571, -0.0470,\n",
       "             0.0063, -0.0333,  0.0199,  0.0799,  0.0083,  0.1328, -0.0147,\n",
       "             0.0547, -0.0404, -0.1035, -0.0844,  0.0334, -0.0373]]],\n",
       "         grad_fn=<CatBackward>)],\n",
       " [tensor([[[-0.0088,  0.0116, -0.0000,  ..., -0.0159,  0.0024, -0.0152],\n",
       "           [-0.0085,  0.0109, -0.0000,  ..., -0.0087,  0.0164, -0.0000],\n",
       "           [-0.0000,  0.0000, -0.0000,  ..., -0.0249,  0.0045, -0.0000],\n",
       "           [-0.0093,  0.0117, -0.0209,  ..., -0.0147,  0.0000, -0.0120],\n",
       "           [-0.0153,  0.0030, -0.0119,  ..., -0.0074,  0.0000, -0.0183]],\n",
       "  \n",
       "          [[-0.0164,  0.0152, -0.0000,  ..., -0.0312,  0.0093, -0.0392],\n",
       "           [-0.0381,  0.0200, -0.0000,  ..., -0.0326,  0.0120, -0.0000],\n",
       "           [-0.0000,  0.0000, -0.0000,  ..., -0.0362,  0.0065, -0.0000],\n",
       "           [-0.0316,  0.0203, -0.0289,  ..., -0.0282, -0.0000, -0.0283],\n",
       "           [-0.0152,  0.0094, -0.0235,  ..., -0.0246,  0.0000, -0.0396]],\n",
       "  \n",
       "          [[-0.0455,  0.0255, -0.0000,  ..., -0.0253,  0.0116, -0.0681],\n",
       "           [-0.0472,  0.0042, -0.0000,  ..., -0.0277,  0.0025, -0.0000],\n",
       "           [-0.0000,  0.0000, -0.0000,  ..., -0.0281,  0.0071, -0.0000],\n",
       "           [-0.0360,  0.0217, -0.0432,  ..., -0.0255,  0.0000, -0.0310],\n",
       "           [-0.0548,  0.0389, -0.0376,  ..., -0.0296,  0.0000, -0.0530]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-0.0463,  0.0310, -0.0000,  ..., -0.0049,  0.0116, -0.0635],\n",
       "           [-0.0689,  0.0212, -0.0000,  ..., -0.0171, -0.0287, -0.0000],\n",
       "           [-0.0000,  0.0000, -0.0000,  ..., -0.0052,  0.0019, -0.0000],\n",
       "           [-0.0325,  0.0297, -0.0706,  ..., -0.0029,  0.0000, -0.0427],\n",
       "           [-0.0385,  0.0349, -0.0745,  ..., -0.0137,  0.0000, -0.0732]],\n",
       "  \n",
       "          [[-0.0396,  0.0342, -0.0000,  ...,  0.0017,  0.0080, -0.0740],\n",
       "           [-0.0510,  0.0374, -0.0000,  ..., -0.0120, -0.0056, -0.0000],\n",
       "           [-0.0000,  0.0000, -0.0000,  ..., -0.0067,  0.0022, -0.0000],\n",
       "           [-0.0394,  0.0292, -0.0715,  ..., -0.0060,  0.0000, -0.0500],\n",
       "           [-0.0402,  0.0321, -0.0747,  ..., -0.0110,  0.0000, -0.0664]],\n",
       "  \n",
       "          [[-0.0502,  0.0251, -0.0000,  ...,  0.0017, -0.0013, -0.0613],\n",
       "           [-0.0496,  0.0278, -0.0000,  ..., -0.0113, -0.0084, -0.0000],\n",
       "           [-0.0000,  0.0000, -0.0000,  ..., -0.0076,  0.0049, -0.0000],\n",
       "           [-0.0508,  0.0265, -0.0713,  ..., -0.0106,  0.0000, -0.0496],\n",
       "           [-0.0530,  0.0454, -0.0703,  ..., -0.0092, -0.0000, -0.0598]]],\n",
       "         grad_fn=<ThMulBackward>),\n",
       "  tensor([[[ 0.0117, -0.0472,  0.0226,  0.0451,  0.0607,  0.0681,  0.0104,\n",
       "             0.0026,  0.0244,  0.0238,  0.0170,  0.0170,  0.0718, -0.0289,\n",
       "             0.0440, -0.0112, -0.0432, -0.0339, -0.0070, -0.0299],\n",
       "           [ 0.0083, -0.0503,  0.0170,  0.0470,  0.0546,  0.0663,  0.0029,\n",
       "             0.0080,  0.0247,  0.0184,  0.0155,  0.0130,  0.0723, -0.0325,\n",
       "             0.0396, -0.0100, -0.0479, -0.0293, -0.0057, -0.0225],\n",
       "           [ 0.0172, -0.0480,  0.0234,  0.0450,  0.0669,  0.0664,  0.0093,\n",
       "             0.0118,  0.0216,  0.0148,  0.0185,  0.0172,  0.0762, -0.0335,\n",
       "             0.0421, -0.0090, -0.0400, -0.0285, -0.0091, -0.0158],\n",
       "           [ 0.0099, -0.0532,  0.0251,  0.0441,  0.0599,  0.0721,  0.0087,\n",
       "             0.0099,  0.0297,  0.0121,  0.0210,  0.0186,  0.0632, -0.0298,\n",
       "             0.0400, -0.0039, -0.0437, -0.0351, -0.0034, -0.0140],\n",
       "           [ 0.0117, -0.0458,  0.0224,  0.0519,  0.0641,  0.0720,  0.0023,\n",
       "            -0.0003,  0.0171,  0.0194,  0.0227,  0.0136,  0.0684, -0.0322,\n",
       "             0.0400, -0.0070, -0.0448, -0.0311,  0.0014, -0.0276]],\n",
       "  \n",
       "          [[ 0.0090, -0.0780,  0.0383,  0.0749,  0.0917,  0.1076,  0.0121,\n",
       "             0.0066,  0.0218,  0.0330,  0.0267,  0.0272,  0.1038, -0.0276,\n",
       "             0.0663, -0.0140, -0.0723, -0.0486,  0.0023, -0.0364],\n",
       "           [ 0.0086, -0.0865,  0.0290,  0.0805,  0.0853,  0.0988, -0.0051,\n",
       "             0.0194,  0.0168,  0.0240,  0.0255,  0.0187,  0.1086, -0.0298,\n",
       "             0.0537, -0.0182, -0.0787, -0.0447,  0.0047, -0.0223],\n",
       "           [ 0.0238, -0.0835,  0.0372,  0.0721,  0.0984,  0.0928,  0.0051,\n",
       "             0.0198,  0.0151,  0.0177,  0.0286,  0.0256,  0.1141, -0.0368,\n",
       "             0.0604, -0.0161, -0.0702, -0.0390, -0.0025, -0.0097],\n",
       "           [ 0.0094, -0.0896,  0.0355,  0.0680,  0.0865,  0.1035,  0.0016,\n",
       "             0.0174,  0.0303,  0.0161,  0.0331,  0.0249,  0.0952, -0.0318,\n",
       "             0.0602, -0.0079, -0.0737, -0.0501,  0.0081, -0.0083],\n",
       "           [ 0.0080, -0.0781,  0.0379,  0.0825,  0.0991,  0.1106, -0.0040,\n",
       "             0.0038,  0.0102,  0.0237,  0.0336,  0.0235,  0.1048, -0.0320,\n",
       "             0.0586, -0.0123, -0.0757, -0.0469,  0.0117, -0.0313]],\n",
       "  \n",
       "          [[ 0.0093, -0.0981,  0.0456,  0.0935,  0.1054,  0.1293,  0.0038,\n",
       "             0.0099,  0.0112,  0.0316,  0.0375,  0.0301,  0.1218, -0.0180,\n",
       "             0.0729, -0.0177, -0.0886, -0.0619,  0.0127, -0.0387],\n",
       "           [ 0.0085, -0.1053,  0.0301,  0.1032,  0.1001,  0.1138, -0.0158,\n",
       "             0.0238,  0.0017,  0.0263,  0.0357,  0.0156,  0.1252, -0.0216,\n",
       "             0.0585, -0.0252, -0.0986, -0.0561,  0.0163, -0.0218],\n",
       "           [ 0.0247, -0.1070,  0.0476,  0.0852,  0.1125,  0.1026, -0.0028,\n",
       "             0.0188,  0.0023,  0.0131,  0.0353,  0.0279,  0.1282, -0.0341,\n",
       "             0.0680, -0.0210, -0.0898, -0.0447,  0.0107, -0.0034],\n",
       "           [ 0.0083, -0.1125,  0.0399,  0.0803,  0.0984,  0.1178, -0.0084,\n",
       "             0.0217,  0.0256,  0.0182,  0.0415,  0.0236,  0.1094, -0.0266,\n",
       "             0.0664, -0.0092, -0.0925, -0.0615,  0.0232,  0.0018],\n",
       "           [ 0.0032, -0.0954,  0.0434,  0.0952,  0.1064,  0.1317, -0.0108,\n",
       "             0.0035, -0.0025,  0.0219,  0.0435,  0.0226,  0.1152, -0.0243,\n",
       "             0.0645, -0.0145, -0.0890, -0.0564,  0.0247, -0.0313]],\n",
       "  \n",
       "          [[ 0.0111, -0.1127,  0.0492,  0.1071,  0.1136,  0.1375, -0.0077,\n",
       "             0.0111,  0.0013,  0.0334,  0.0478,  0.0271,  0.1303, -0.0105,\n",
       "             0.0752, -0.0249, -0.0976, -0.0725,  0.0206, -0.0395],\n",
       "           [ 0.0095, -0.1161,  0.0289,  0.1178,  0.1029,  0.1209, -0.0257,\n",
       "             0.0272, -0.0131,  0.0260,  0.0454,  0.0127,  0.1328, -0.0132,\n",
       "             0.0566, -0.0318, -0.1086, -0.0617,  0.0249, -0.0173],\n",
       "           [ 0.0281, -0.1151,  0.0481,  0.0984,  0.1145,  0.1094, -0.0133,\n",
       "             0.0212, -0.0109,  0.0131,  0.0467,  0.0274,  0.1408, -0.0303,\n",
       "             0.0711, -0.0299, -0.1000, -0.0545,  0.0087, -0.0011],\n",
       "           [ 0.0065, -0.1209,  0.0394,  0.0876,  0.1045,  0.1244, -0.0193,\n",
       "             0.0243,  0.0185,  0.0182,  0.0494,  0.0214,  0.1135, -0.0213,\n",
       "             0.0678, -0.0114, -0.1039, -0.0715,  0.0329,  0.0082],\n",
       "           [ 0.0030, -0.0994,  0.0423,  0.1048,  0.1062,  0.1444, -0.0226,\n",
       "             0.0054, -0.0150,  0.0198,  0.0536,  0.0197,  0.1251, -0.0187,\n",
       "             0.0648, -0.0213, -0.1005, -0.0620,  0.0292, -0.0306]],\n",
       "  \n",
       "          [[ 0.0103, -0.1177,  0.0475,  0.1156,  0.1147,  0.1433, -0.0161,\n",
       "             0.0125, -0.0063,  0.0339,  0.0547,  0.0256,  0.1353, -0.0047,\n",
       "             0.0756, -0.0309, -0.1034, -0.0826,  0.0244, -0.0410],\n",
       "           [ 0.0138, -0.1144,  0.0271,  0.1244,  0.1089,  0.1256, -0.0323,\n",
       "             0.0340, -0.0256,  0.0307,  0.0512,  0.0094,  0.1392, -0.0072,\n",
       "             0.0575, -0.0362, -0.1155, -0.0641,  0.0270, -0.0111],\n",
       "           [ 0.0287, -0.1190,  0.0461,  0.1061,  0.1107,  0.1135, -0.0253,\n",
       "             0.0222, -0.0209,  0.0082,  0.0549,  0.0254,  0.1476, -0.0269,\n",
       "             0.0706, -0.0369, -0.1075, -0.0576,  0.0123,  0.0044],\n",
       "           [ 0.0053, -0.1193,  0.0366,  0.0936,  0.1059,  0.1295, -0.0311,\n",
       "             0.0237,  0.0137,  0.0200,  0.0633,  0.0177,  0.1147, -0.0184,\n",
       "             0.0673, -0.0160, -0.1091, -0.0768,  0.0359,  0.0097],\n",
       "           [ 0.0023, -0.1008,  0.0408,  0.1071,  0.1081,  0.1501, -0.0327,\n",
       "             0.0096, -0.0249,  0.0200,  0.0584,  0.0144,  0.1246, -0.0177,\n",
       "             0.0642, -0.0255, -0.1047, -0.0708,  0.0347, -0.0297]],\n",
       "  \n",
       "          [[ 0.0075, -0.1199,  0.0457,  0.1209,  0.1145,  0.1483, -0.0208,\n",
       "             0.0147, -0.0097,  0.0342,  0.0587,  0.0260,  0.1361, -0.0012,\n",
       "             0.0754, -0.0320, -0.1052, -0.0891,  0.0278, -0.0370],\n",
       "           [ 0.0169, -0.1124,  0.0190,  0.1276,  0.1009,  0.1280, -0.0399,\n",
       "             0.0348, -0.0339,  0.0316,  0.0565,  0.0027,  0.1431, -0.0080,\n",
       "             0.0546, -0.0403, -0.1233, -0.0635,  0.0265, -0.0108],\n",
       "           [ 0.0293, -0.1132,  0.0405,  0.1103,  0.1103,  0.1196, -0.0321,\n",
       "             0.0249, -0.0270,  0.0019,  0.0586,  0.0228,  0.1504, -0.0275,\n",
       "             0.0720, -0.0375, -0.1143, -0.0631,  0.0162,  0.0065],\n",
       "           [ 0.0024, -0.1118,  0.0333,  0.0961,  0.1083,  0.1317, -0.0414,\n",
       "             0.0254,  0.0082,  0.0201,  0.0720,  0.0177,  0.1151, -0.0164,\n",
       "             0.0655, -0.0177, -0.1117, -0.0826,  0.0357,  0.0068],\n",
       "           [ 0.0055, -0.1032,  0.0384,  0.1129,  0.1097,  0.1513, -0.0381,\n",
       "             0.0062, -0.0314,  0.0188,  0.0679,  0.0100,  0.1262, -0.0154,\n",
       "             0.0586, -0.0305, -0.1029, -0.0724,  0.0371, -0.0310]],\n",
       "  \n",
       "          [[ 0.0052, -0.1146,  0.0416,  0.1232,  0.1120,  0.1530, -0.0216,\n",
       "             0.0150, -0.0126,  0.0339,  0.0606,  0.0283,  0.1380, -0.0007,\n",
       "             0.0764, -0.0360, -0.1074, -0.0946,  0.0277, -0.0369],\n",
       "           [ 0.0189, -0.1085,  0.0191,  0.1333,  0.1010,  0.1302, -0.0453,\n",
       "             0.0385, -0.0351,  0.0301,  0.0605, -0.0003,  0.1457, -0.0063,\n",
       "             0.0496, -0.0424, -0.1236, -0.0670,  0.0273, -0.0099],\n",
       "           [ 0.0311, -0.1065,  0.0375,  0.1151,  0.1135,  0.1227, -0.0360,\n",
       "             0.0319, -0.0279,  0.0002,  0.0600,  0.0227,  0.1557, -0.0287,\n",
       "             0.0713, -0.0385, -0.1161, -0.0706,  0.0123,  0.0119],\n",
       "           [ 0.0027, -0.1085,  0.0291,  0.0965,  0.1085,  0.1327, -0.0467,\n",
       "             0.0266,  0.0099,  0.0192,  0.0772,  0.0175,  0.1175, -0.0177,\n",
       "             0.0613, -0.0206, -0.1152, -0.0900,  0.0378,  0.0048],\n",
       "           [ 0.0095, -0.0943,  0.0385,  0.1167,  0.1090,  0.1562, -0.0400,\n",
       "             0.0018, -0.0337,  0.0172,  0.0741,  0.0106,  0.1282, -0.0131,\n",
       "             0.0557, -0.0320, -0.1054, -0.0769,  0.0396, -0.0335]],\n",
       "  \n",
       "          [[ 0.0062, -0.1137,  0.0350,  0.1260,  0.1096,  0.1565, -0.0238,\n",
       "             0.0183, -0.0154,  0.0331,  0.0615,  0.0278,  0.1376,  0.0014,\n",
       "             0.0759, -0.0372, -0.1133, -0.0949,  0.0261, -0.0338],\n",
       "           [ 0.0200, -0.1061,  0.0220,  0.1373,  0.1007,  0.1310, -0.0492,\n",
       "             0.0415, -0.0332,  0.0294,  0.0632, -0.0019,  0.1485, -0.0059,\n",
       "             0.0429, -0.0454, -0.1194, -0.0726,  0.0278, -0.0102],\n",
       "           [ 0.0326, -0.1084,  0.0401,  0.1212,  0.1132,  0.1206, -0.0391,\n",
       "             0.0302, -0.0300, -0.0003,  0.0666,  0.0228,  0.1575, -0.0280,\n",
       "             0.0700, -0.0418, -0.1145, -0.0759,  0.0107,  0.0105],\n",
       "           [ 0.0030, -0.1093,  0.0267,  0.0967,  0.1084,  0.1328, -0.0506,\n",
       "             0.0282,  0.0069,  0.0178,  0.0800,  0.0181,  0.1191, -0.0193,\n",
       "             0.0610, -0.0231, -0.1160, -0.0918,  0.0355,  0.0052],\n",
       "           [ 0.0082, -0.0856,  0.0389,  0.1170,  0.1137,  0.1605, -0.0392,\n",
       "             0.0023, -0.0334,  0.0179,  0.0761,  0.0109,  0.1329, -0.0133,\n",
       "             0.0562, -0.0353, -0.1054, -0.0784,  0.0367, -0.0356]],\n",
       "  \n",
       "          [[ 0.0069, -0.1052,  0.0329,  0.1239,  0.1102,  0.1594, -0.0243,\n",
       "             0.0205, -0.0172,  0.0316,  0.0619,  0.0292,  0.1411,  0.0019,\n",
       "             0.0765, -0.0400, -0.1167, -0.0963,  0.0244, -0.0335],\n",
       "           [ 0.0206, -0.0994,  0.0201,  0.1342,  0.0978,  0.1344, -0.0517,\n",
       "             0.0436, -0.0326,  0.0299,  0.0603, -0.0018,  0.1514, -0.0122,\n",
       "             0.0432, -0.0454, -0.1185, -0.0757,  0.0268, -0.0147],\n",
       "           [ 0.0333, -0.1060,  0.0360,  0.1247,  0.1109,  0.1212, -0.0407,\n",
       "             0.0319, -0.0311, -0.0005,  0.0676,  0.0231,  0.1583, -0.0279,\n",
       "             0.0693, -0.0423, -0.1156, -0.0794,  0.0092,  0.0139],\n",
       "           [ 0.0042, -0.1095,  0.0254,  0.0981,  0.1099,  0.1327, -0.0517,\n",
       "             0.0304,  0.0055,  0.0159,  0.0785,  0.0197,  0.1210, -0.0201,\n",
       "             0.0611, -0.0252, -0.1159, -0.0938,  0.0359,  0.0067],\n",
       "           [ 0.0075, -0.0833,  0.0398,  0.1182,  0.1139,  0.1600, -0.0410,\n",
       "             0.0042, -0.0328,  0.0175,  0.0771,  0.0117,  0.1339, -0.0135,\n",
       "             0.0567, -0.0371, -0.1066, -0.0812,  0.0347, -0.0351]],\n",
       "  \n",
       "          [[ 0.0063, -0.1013,  0.0349,  0.1234,  0.1120,  0.1582, -0.0251,\n",
       "             0.0191, -0.0154,  0.0291,  0.0661,  0.0268,  0.1419,  0.0040,\n",
       "             0.0770, -0.0407, -0.1125, -0.1028,  0.0260, -0.0374],\n",
       "           [ 0.0226, -0.0979,  0.0188,  0.1351,  0.1006,  0.1347, -0.0524,\n",
       "             0.0448, -0.0372,  0.0329,  0.0625, -0.0015,  0.1541, -0.0118,\n",
       "             0.0447, -0.0468, -0.1215, -0.0732,  0.0240, -0.0134],\n",
       "           [ 0.0349, -0.1033,  0.0350,  0.1270,  0.1119,  0.1213, -0.0419,\n",
       "             0.0336, -0.0300,  0.0005,  0.0685,  0.0230,  0.1595, -0.0264,\n",
       "             0.0693, -0.0436, -0.1159, -0.0805,  0.0105,  0.0150],\n",
       "           [ 0.0072, -0.1132,  0.0256,  0.0983,  0.1125,  0.1303, -0.0499,\n",
       "             0.0323,  0.0045,  0.0141,  0.0703,  0.0219,  0.1239, -0.0195,\n",
       "             0.0611, -0.0239, -0.1143, -0.0954,  0.0398,  0.0111],\n",
       "           [ 0.0085, -0.0816,  0.0389,  0.1172,  0.1104,  0.1571, -0.0470,\n",
       "             0.0063, -0.0333,  0.0199,  0.0799,  0.0083,  0.1328, -0.0147,\n",
       "             0.0547, -0.0404, -0.1035, -0.0844,  0.0334, -0.0373]]],\n",
       "         grad_fn=<CatBackward>)])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tst_input.clone()\n",
    "z = tst_model(x)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tst_output.clone()\n",
    "loss = F.nll_loss(z[0], y)\n",
    "loss.backward()\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0771, -0.0582, -0.0595,  ..., -0.0704,  0.0910, -0.0049],\n",
       "        [ 0.0232,  0.0282,  0.0036,  ...,  0.0123,  0.0911, -0.0684],\n",
       "        [ 0.0752, -0.0123,  0.0452,  ..., -0.0631, -0.0344,  0.0208],\n",
       "        ...,\n",
       "        [-0.0841, -0.0302,  0.0260,  ...,  0.0346, -0.0877, -0.0890],\n",
       "        [-0.0016,  0.0072,  0.0175,  ...,  0.0442,  0.0095,  0.0981],\n",
       "        [ 0.0968,  0.0940, -0.0924,  ..., -0.0098,  0.0201, -0.0284]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_model[0].rnns[0]._parameters['weight_hh_l0_raw']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll keep the same param as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_model = get_language_model(500, 20, 100, 2, 0, bias=True, dropout=0.4, dropoute=0.1, dropouth=0.2, \n",
    "                               dropouti=0.6, wdrop=0.5)\n",
    "state_dict = OrderedDict()\n",
    "for n,p in save_parameters.items(): state_dict[n] = p.clone()\n",
    "tst_model.load_state_dict(state_dict)\n",
    "opt = optim.SGD(tst_model.parameters(), lr=10, weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x267b3a7b390>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tst_input.clone()\n",
    "z = tst_model(x)\n",
    "y = tst_output.clone()\n",
    "loss = F.nll_loss(z[0], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01827934943139553"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = seq2seq_reg(z[0], z[1:], loss, 2, 1)\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "nn.utils.clip_grad_norm_(tst_model.parameters(), 0.1)\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.8528,  0.3268, -0.1945,  ..., -0.7425, -0.5671, -0.5097],\n",
       "        [ 0.0168, -0.8864,  0.7456,  ...,  0.1414, -0.6313, -0.8001],\n",
       "        [-0.4075,  0.5643,  0.0247,  ...,  0.3236, -0.4726, -0.4496],\n",
       "        ...,\n",
       "        [-0.6785,  0.6084, -0.0387,  ...,  0.4916, -0.6366,  0.7781],\n",
       "        [ 0.0696,  0.3158,  0.6227,  ...,  0.6792, -0.3027,  0.7779],\n",
       "        [-0.8144,  0.5334,  0.0538,  ...,  0.3347, -0.5188,  0.1718]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_model[0].rnns[0].module._parameters['weight_hh_l0_raw']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RNNTrainer(Callback):\n",
    "    model:nn.Module\n",
    "    bptt:int\n",
    "    clip:float=None\n",
    "    alpha:float=0.\n",
    "    beta:float=0.\n",
    "    \n",
    "    def on_loss_begin(self, last_output, **kwargs):\n",
    "        #Save the extra outputs for later and only returns the true output.\n",
    "        self.raw_out,self.out = last_output[1],last_output[2]\n",
    "        return last_output[0]\n",
    "    \n",
    "    def on_backward_begin(self, last_loss, last_input, last_output, **kwargs):\n",
    "        #Adjusts the lr to the bptt selected\n",
    "        #self.learn.opt.lr *= last_input.size(0) / self.bptt\n",
    "        #AR and TAR\n",
    "        if self.alpha != 0.:  last_loss += (self.alpha * self.out[-1].pow(2).mean()).sum()\n",
    "        if self.beta != 0.:\n",
    "            h = self.raw_out[-1]\n",
    "            if len(h)>1: last_loss += (self.beta * (h[1:] - h[:-1]).pow(2).mean()).sum()\n",
    "        return last_loss\n",
    "    \n",
    "    def on_backward_end(self, **kwargs):\n",
    "        if self.clip:  nn.utils.clip_grad_norm_(self.model.parameters(), self.clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_parameters1 = {}\n",
    "for n,p in save_parameters.items(): \n",
    "    if 'weight_hh_l0' not in n and n!='0.encoder_with_dropout.embed.weight':  save_parameters1[n] = p.clone()\n",
    "    elif n=='0.encoder_with_dropout.embed.weight': save_parameters1['0.dp_encoder.embed.weight'] = p.clone()\n",
    "    else: \n",
    "        save_parameters1[n[:-4]] = p.clone()\n",
    "        splits = n.split('.')\n",
    "        splits.remove(splits[-2])\n",
    "        n1 = '.'.join(splits)\n",
    "        save_parameters1[n1] = p.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_model = get_language_model1(500, 20, 100, 2, 0)\n",
    "tst_model.load_state_dict(save_parameters1)\n",
    "opt = optim.SGD(tst_model.parameters(), lr=10, weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x267b3a7b390>"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = RNNTrainer(tst_model, 10, 0.1, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01827934943139553"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tst_input.clone()\n",
    "z = tst_model(x)\n",
    "y = tst_output.clone()\n",
    "z = cb.on_loss_begin(z)\n",
    "loss = F.nll_loss(z, y)\n",
    "loss = cb.on_backward_begin(loss, x, z)\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "cb.on_backward_end()\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.8528,  0.3268, -0.1945,  ..., -0.7425, -0.5671, -0.5097],\n",
       "        [ 0.0168, -0.8864,  0.7456,  ...,  0.1414, -0.6313, -0.8001],\n",
       "        [-0.4075,  0.5643,  0.0247,  ...,  0.3236, -0.4726, -0.4496],\n",
       "        ...,\n",
       "        [-0.6785,  0.6084, -0.0387,  ...,  0.4916, -0.6366,  0.7781],\n",
       "        [ 0.0696,  0.3158,  0.6227,  ...,  0.6792, -0.3027,  0.7779],\n",
       "        [-0.8144,  0.5334,  0.0538,  ...,  0.3347, -0.5188,  0.1718]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_model[0].rnns[0]._parameters['weight_hh_l0_raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment to create the random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_PATH = Path('../data')\n",
    "#PATH = DATA_PATH/'imagenet'\n",
    "#list_classes = find_classes(PATH/'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_select = np.random.permutation(list_classes)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_val_folders(class_folders):\n",
    "#    names = [f.name for f in class_folders]\n",
    "#    return [PATH/'val'/name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def create_new(class_folders):\n",
    "#    path = Path('../data/sample_imagenet/')\n",
    "#    os.makedirs(path, exist_ok=True)\n",
    "#    for mode in ['train', 'val']:\n",
    "#        p = path/mode\n",
    "#        os.makedirs(p, exist_ok=True)\n",
    "#        for f in class_folders:\n",
    "#            os.makedirs(p/f.name, exist_ok=True)\n",
    "#            list_images = (PATH/mode/f.name).glob('*')\n",
    "#            for img in list_images:\n",
    "#                shutil.copy(img, p/f.name/img.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_new(random_select)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nb_002 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('../data')\n",
    "PATH = DATA_PATH/'sample_imagenet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of all the different possiblities for a pipeline on imagenet including:\n",
    "- resizing the image so that the lower dimension is 224\n",
    "- random rotate -10 to 10 degrees\n",
    "- random scale 0.9 to 1.1\n",
    "- random flip\n",
    "- random crop\n",
    "\n",
    "Test on the first 100 batches of imagenet (with shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TVFilesDataset(Dataset):\n",
    "    def __init__(self, folder, tfms):\n",
    "        cls_dirs = find_classes(folder)\n",
    "        self.fns, self.y = [], []\n",
    "        self.classes = [cls.name for cls in cls_dirs]\n",
    "        for i, cls_dir in enumerate(cls_dirs):\n",
    "            fnames = get_image_files(cls_dir)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.tfms = torchvision.transforms.Compose(tfms)\n",
    "        \n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = Image.open(self.fns[i]).convert('RGB')\n",
    "        x = self.tfms(x)\n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device, stats):\n",
    "        self.dl,self.device = dl,device\n",
    "        self.m, self.s = map(lambda x:torch.tensor(x, dtype=torch.float32, device=device), stats)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            x, y = b[0].to(self.device),b[1].to(self.device)\n",
    "            x = (x - self.m[None,:,None,None]) / self.s[None,:,None,None]\n",
    "            yield x,y\n",
    "    \n",
    "    def __len__(self): return (len(self.dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(ds, bs, shuffle, stats, device = None, sampler=None):\n",
    "    if device is None: device = default_device\n",
    "    dl = DataLoader(ds, batch_size=bs, shuffle=shuffle,num_workers=8, sampler=sampler, pin_memory=True)\n",
    "    return DeviceDataLoader(dl, device, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz, bs = 224, 192\n",
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [torchvision.transforms.RandomResizedCrop(sz),\n",
    "              torchvision.transforms.RandomHorizontalFlip(),\n",
    "              torchvision.transforms.ToTensor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TVFilesDataset(PATH/'train', train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_device = default_device = torch.device('cuda', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:18<00:00,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.23 s, sys: 3.43 s, total: 9.66 s\n",
      "Wall time: 18.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_dl)\n",
    "%time for i in tqdm(range(100)): x,y = next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.6s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline with grid_sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needs the PR https://github.com/pytorch/pytorch/pull/10051/files to make grid_sample fast and support reflect padding/nearest interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_groupby(iterable, key=None):\n",
    "    return {k:list(v) for k,v in itertools.groupby(sorted(iterable, key=key), key=key)}\n",
    "\n",
    "def resolve_pipeline(tfms, **kwargs):\n",
    "    tfms = listify(tfms)\n",
    "    if len(tfms)==0: return noop\n",
    "    grouped_tfms = dict_groupby(tfms, lambda o: o.__annotations__['return'])\n",
    "    lighting_tfms,coord_tfms,affine_tfms,pixel_tfms,final_tfms = map(grouped_tfms.get, TfmType)\n",
    "    lighting_tfm = apply_lighting_tfms(lighting_tfms)\n",
    "    affine_tfm = compose_affine_tfms(affine_tfms, funcs=coord_tfms, **kwargs)\n",
    "    pixel_tfm = compose_tfms(pixel_tfms)\n",
    "    final_tfm = compose_tfms(final_tfms)\n",
    "    return lambda x,**k: final_tfm(affine_tfm(lighting_tfm(pixel_tfm(x)), **k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rrc_params(img, scale, ratio):\n",
    "    for attempt in range(10):\n",
    "        area = img.size[0] * img.size[1]\n",
    "        target_area = random.uniform(*scale) * area\n",
    "        aspect_ratio = random.uniform(*ratio)\n",
    "\n",
    "        w = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "        h = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            w, h = h, w\n",
    "\n",
    "        if w <= img.size[0] and h <= img.size[1]:\n",
    "            i = random.randint(0, img.size[1] - h)\n",
    "            j = random.randint(0, img.size[0] - w)\n",
    "            return i, j, h, w\n",
    "\n",
    "    w = min(img.size[0], img.size[1])\n",
    "    i = (img.size[1] - w) // 2\n",
    "    j = (img.size[0] - w) // 2\n",
    "    return i, j, w, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedFilesDataset(Dataset):\n",
    "    def __init__(self, folder, sz, tfms=None, classes=None):\n",
    "        self.fns, self.y = [], []\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "        self.classes = classes\n",
    "        for i, cls in enumerate(classes):\n",
    "            fnames = get_image_files(folder/cls)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.sz, self.tfms = sz, tfms\n",
    "\n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        i,j,h,w = get_rrc_params(x, (0.8,1), (3/4,4/3))\n",
    "        x = pil2tensor(x)\n",
    "        x = x[:,i:i+h,j:j+w]\n",
    "        if self.tfms is not None:\n",
    "            x = resolve_pipeline(self.tfms, size=self.sz)(x) \n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz, bs = 224, 64\n",
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [flip_lr_tfm(p=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TransformedFilesDataset(PATH/'train', sz, train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:30<00:00,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.15 s, sys: 1.11 s, total: 3.26 s\n",
      "Wall time: 30.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_dl)\n",
    "%time for i in tqdm(range(100)): x,y = next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31.2s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if ToTensor() is faster then our pil2tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedFilesDataset(Dataset):\n",
    "    def __init__(self, folder, sz, tfms=None, classes=None):\n",
    "        self.fns, self.y = [], []\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "        self.classes = classes\n",
    "        for i, cls in enumerate(classes):\n",
    "            fnames = get_image_files(folder/cls)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.sz, self.tfms = sz, tfms\n",
    "\n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        i,j,h,w = get_rrc_params(x, (0.8,1), (3/4,4/3))\n",
    "        x = torchvision.transforms.ToTensor()(x)\n",
    "        x = x[:,i:i+h,j:j+w]\n",
    "        if self.tfms is not None:\n",
    "            x = resolve_pipeline(self.tfms, size=self.sz)(x) \n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz, bs = 224, 64\n",
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [flip_lr_tfm(p=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TransformedFilesDataset(PATH/'train', sz, train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:32<00:00,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.09 s, sys: 1.08 s, total: 3.18 s\n",
      "Wall time: 32.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_dl)\n",
    "%time for i in tqdm(range(100)): x,y = next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32.2s, no it's not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedFilesDataset(Dataset):\n",
    "    def __init__(self, folder, sz, tfms=None, classes=None):\n",
    "        self.fns, self.y = [], []\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "        self.classes = classes\n",
    "        for i, cls in enumerate(classes):\n",
    "            fnames = get_image_files(folder/cls)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.sz, self.tfms = sz, tfms\n",
    "\n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        i,j,h,w = get_rrc_params(x, (0.8,1), (3/4,4/3))\n",
    "        x = x.crop((j,i,j+w,i+h))\n",
    "        x = x.resize((self.sz,self.sz), Image.BILINEAR)\n",
    "        x = pil2tensor(x)\n",
    "        if self.tfms is not None:\n",
    "            x = resolve_pipeline(self.tfms)(x)\n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz, bs = 224, 64\n",
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [flip_lr_tfm(p=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TransformedFilesDataset(PATH/'train', sz, train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 13.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.11 s, sys: 1.31 s, total: 3.42 s\n",
      "Wall time: 7.68 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_dl)\n",
    "%time for i in tqdm(range(100)): x,y = next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.7s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just F.interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedFilesDataset(Dataset):\n",
    "    def __init__(self, folder, sz, tfms=None, classes=None):\n",
    "        self.fns, self.y = [], []\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "        self.classes = classes\n",
    "        for i, cls in enumerate(classes):\n",
    "            fnames = get_image_files(folder/cls)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.sz, self.tfms = sz, tfms\n",
    "\n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        i,j,h,w = get_rrc_params(x, (0.8,1), (3/4,4/3))\n",
    "        x = pil2tensor(x)\n",
    "        x = x[:,i:i+h,j:j+w]\n",
    "        x = F.interpolate(x[None], size=(self.sz,self.sz),mode='bilinear')\n",
    "        if self.tfms is not None:\n",
    "            x = resolve_pipeline(self.tfms)(x)\n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz, bs = 224, 64\n",
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [flip_lr_tfm(p=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TransformedFilesDataset(PATH/'train', sz, train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/ubuntu/anaconda3/envs/fastai1/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/envs/fastai1/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/envs/fastai1/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/envs/fastai1/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/envs/fastai1/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/envs/fastai1/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/envs/fastai1/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/envs/fastai1/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.21 s, sys: 1.24 s, total: 3.45 s\n",
      "Wall time: 11.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_dl)\n",
    "%time for i in tqdm(range(100)): x,y = next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.2s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nb_002 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('../data')\n",
    "PATH = DATA_PATH/'imagenet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of all the different possiblities for a pipeline on imagenet including:\n",
    "- resizing the image so that the lower dimension is 224\n",
    "- random rotate -10 to 10 degrees\n",
    "- random scale 0.9 to 1.1\n",
    "- random flip\n",
    "- random crop\n",
    "\n",
    "Test on the first 100 batches of imagenet (with shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TVFilesDataset(Dataset):\n",
    "    def __init__(self, folder, tfms):\n",
    "        cls_dirs = find_classes(folder)\n",
    "        self.fns, self.y = [], []\n",
    "        self.classes = [cls.name for cls in cls_dirs]\n",
    "        for i, cls_dir in enumerate(cls_dirs):\n",
    "            fnames = get_image_files(cls_dir)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.tfms = torchvision.transforms.Compose(tfms)\n",
    "        \n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = Image.open(self.fns[i]).convert('RGB')\n",
    "        x = self.tfms(x)\n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device, stats):\n",
    "        self.dl,self.device = dl,device\n",
    "        self.m, self.s = map(lambda x:torch.tensor(x, dtype=torch.float32, device=device), stats)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            x, y = b[0].to(self.device),b[1].to(self.device)\n",
    "            x = (x - self.m[None,:,None,None]) / self.s[None,:,None,None]\n",
    "            yield x,y\n",
    "    \n",
    "    def __len__(self): return (len(self.dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(ds, bs, shuffle, stats, device = None, sampler=None):\n",
    "    if device is None: device = default_device\n",
    "    dl = DataLoader(ds, batch_size=bs, shuffle=shuffle,num_workers=8, sampler=sampler, pin_memory=True)\n",
    "    return DeviceDataLoader(dl, device, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz, bs = 224, 192\n",
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [torchvision.transforms.RandomRotation(10),\n",
    "              torchvision.transforms.RandomResizedCrop(sz, scale=(0.5, 1.0), ratio=(1.,1.)),\n",
    "              torchvision.transforms.RandomHorizontalFlip(),\n",
    "              torchvision.transforms.ToTensor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TVFilesDataset(PATH/'train', train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_device = default_device = torch.device('cuda', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:37<00:00,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.02 s, sys: 3.12 s, total: 9.15 s\n",
      "Wall time: 37.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_dl)\n",
    "%time for i in tqdm(range(100)): x,y = next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "37.3s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline with grid_sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needs the PR https://github.com/pytorch/pytorch/pull/9961/files to make grid_sample fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_groupby(iterable, key=None):\n",
    "    return {k:list(v) for k,v in itertools.groupby(sorted(iterable, key=key), key=key)}\n",
    "\n",
    "def resolve_pipeline(tfms, **kwargs):\n",
    "    tfms = listify(tfms)\n",
    "    if len(tfms)==0: return noop\n",
    "    grouped_tfms = dict_groupby(tfms, lambda o: o.__annotations__['return'])\n",
    "    lighting_tfms,coord_tfms,affine_tfms,pixel_tfms,final_tfms = map(grouped_tfms.get, TfmType)\n",
    "    lighting_tfm = apply_lighting_tfms(lighting_tfms)\n",
    "    affine_tfm = compose_affine_tfms(affine_tfms, funcs=coord_tfms, **kwargs)\n",
    "    pixel_tfm = compose_tfms(pixel_tfms)\n",
    "    final_tfm = compose_tfms(final_tfms)\n",
    "    return lambda x,**k: final_tfm(affine_tfm(lighting_tfm(pixel_tfm(x)), **k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedFilesDataset(Dataset):\n",
    "    def __init__(self, folder, sz, tfms=None, classes=None):\n",
    "        self.fns, self.y = [], []\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "        self.classes = classes\n",
    "        for i, cls in enumerate(classes):\n",
    "            fnames = get_image_files(folder/cls)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.sz, self.tfms = sz, tfms\n",
    "\n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        x = pil2tensor(x)\n",
    "        if self.tfms is not None:\n",
    "            x = resolve_pipeline(self.tfms, size=self.sz)(x) \n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz, bs = 224, 64\n",
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [flip_lr_tfm(p=0.5),\n",
    "              zoom_tfm(scale=(0.9,1.1),p=0.75),\n",
    "              rotate_tfm(degrees=(-10,10.),p=0.75),\n",
    "              crop_tfm(size=sz)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TransformedFilesDataset(PATH/'train', sz, train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:31<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.14 s, sys: 1.31 s, total: 3.45 s\n",
      "Wall time: 31.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_dl)\n",
    "%time for i in tqdm(range(100)): x,y = next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31.5s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now without affine augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz, bs = 224, 64\n",
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [flip_lr_tfm(p=0.5),\n",
    "              #zoom_tfm(scale=(0.9,1.1),p=0.75),\n",
    "              #rotate_tfm(degrees=(-10,10.),p=0.75),\n",
    "              crop_tfm(size=sz)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TransformedFilesDataset(PATH/'train', sz, train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:28<00:00,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.15 s, sys: 1.31 s, total: 3.46 s\n",
      "Wall time: 28 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_dl)\n",
    "%time for i in tqdm(range(100)): x,y = next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedFilesDataset(Dataset):\n",
    "    def __init__(self, folder, sz, tfms=None, classes=None):\n",
    "        self.fns, self.y = [], []\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "        self.classes = classes\n",
    "        for i, cls in enumerate(classes):\n",
    "            fnames = get_image_files(folder/cls)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.sz, self.tfms = sz, tfms\n",
    "\n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        w,h = x.size\n",
    "        if w < h: w,h = self.sz,int(self.sz * h / w)\n",
    "        else:     w,h = int(self.sz * w / h),self.sz\n",
    "        theta = random.uniform(-10,10) * math.pi / 180 if random.random() < 0.75 else 0\n",
    "        scale = random.uniform(0.9,1.1) if random.random() < 0.75 else 1\n",
    "        x = x.transform((w,h), Image.AFFINE, (cos(theta)/scale, -sin(theta), 0, sin(theta), cos(theta)/scale, 0), Image.BILINEAR)\n",
    "        x = pil2tensor(x)\n",
    "        if self.tfms is not None:\n",
    "            x = resolve_pipeline(self.tfms)(x) \n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz, bs = 224, 64\n",
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [flip_lr_tfm(p=0.5),\n",
    "              #zoom_tfm(scale=(0.9,1.1),p=0.75), Those are done in the dataset\n",
    "              #rotate_tfm(degrees=(-10,10.),p=0.75),\n",
    "              crop_tfm(size=sz)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TransformedFilesDataset(PATH/'train', sz, train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:15<00:00,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.1 s, sys: 1.22 s, total: 3.33 s\n",
      "Wall time: 15.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_dl)\n",
    "%time for i in tqdm(range(100)): x,y = next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.8s ^^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just PIL resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedFilesDataset(Dataset):\n",
    "    def __init__(self, folder, sz, tfms=None, classes=None):\n",
    "        self.fns, self.y = [], []\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "        self.classes = classes\n",
    "        for i, cls in enumerate(classes):\n",
    "            fnames = get_image_files(folder/cls)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.sz, self.tfms = sz, tfms\n",
    "\n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        w,h = x.size\n",
    "        if w < h: w,h = self.sz,int(self.sz * h / w)\n",
    "        else:     w,h = int(self.sz * w / h),self.sz\n",
    "        x = x.resize((w,h))\n",
    "        x = pil2tensor(x)\n",
    "        x = F.interpolate(x[None], size=(self.sz,self.sz),mode='bilinear')\n",
    "        if self.tfms is not None:\n",
    "            x = resolve_pipeline(self.tfms)(x[0]) \n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz, bs = 224, 64\n",
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [flip_lr_tfm(p=0.5),\n",
    "              #zoom_tfm(scale=(0.9,1.1),p=0.75),\n",
    "              #rotate_tfm(degrees=(-10,10.),p=0.75),\n",
    "              crop_tfm(size=sz)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TransformedFilesDataset(PATH/'train', sz, train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.1 s, sys: 1.39 s, total: 3.49 s\n",
      "Wall time: 11.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_dl)\n",
    "%time for i in tqdm(range(100)): x,y = next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.6s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just F.interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedFilesDataset(Dataset):\n",
    "    def __init__(self, folder, sz, tfms=None, classes=None):\n",
    "        self.fns, self.y = [], []\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "        self.classes = classes\n",
    "        for i, cls in enumerate(classes):\n",
    "            fnames = get_image_files(folder/cls)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.sz, self.tfms = sz, tfms\n",
    "\n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        x = pil2tensor(x)\n",
    "        x = F.interpolate(x[None], size=(self.sz,self.sz),mode='bilinear')\n",
    "        if self.tfms is not None:\n",
    "            x = resolve_pipeline(self.tfms)(x[0]) \n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz, bs = 224, 64\n",
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [flip_lr_tfm(p=0.5),\n",
    "              #zoom_tfm(scale=(0.9,1.1),p=0.75),\n",
    "              #rotate_tfm(degrees=(-10,10.),p=0.75),\n",
    "              crop_tfm(size=sz)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TransformedFilesDataset(PATH/'train', sz, train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "100%|██████████| 100/100 [00:13<00:00,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.14 s, sys: 1.36 s, total: 3.5 s\n",
      "Wall time: 13.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_dl)\n",
    "%time for i in tqdm(range(100)): x,y = next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.3s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid_sample used to be faster on the GPU so let's try to do that step there by moving the image on the GPU during the affine transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_affine(img, m=None, func=None, size=None, **kwargs):\n",
    "    img = img.cuda(non_blocking=True)\n",
    "    if size is None: size = img.size()\n",
    "    elif isinstance(size, int):\n",
    "        if img.size(1) < img.size(2): size = (img.size(0),size,int(img.size(2)*size/img.size(1)))\n",
    "        else: size = (img.size(0),int(img.size(1)*size/img.size(2)),size)\n",
    "    if m is None:\n",
    "        if img.shape==size: return img\n",
    "        else: m=eye_new(img, 3)\n",
    "    m = m.cuda(non_blocking=True)\n",
    "    c = affine_grid(img,  img.new_tensor(m), size=size)\n",
    "    if func is not None: c = func(c)\n",
    "    return grid_sample(img, c, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_groupby(iterable, key=None):\n",
    "    return {k:list(v) for k,v in itertools.groupby(sorted(iterable, key=key), key=key)}\n",
    "\n",
    "def resolve_pipeline(tfms, **kwargs):\n",
    "    tfms = listify(tfms)\n",
    "    if len(tfms)==0: return noop\n",
    "    grouped_tfms = dict_groupby(tfms, lambda o: o.__annotations__['return'])\n",
    "    lighting_tfms,coord_tfms,affine_tfms,pixel_tfms,final_tfms = map(grouped_tfms.get, TfmType)\n",
    "    lighting_tfm = apply_lighting_tfms(lighting_tfms)\n",
    "    affine_tfm = compose_affine_tfms(affine_tfms, funcs=coord_tfms, **kwargs)\n",
    "    pixel_tfm = compose_tfms(pixel_tfms)\n",
    "    final_tfm = compose_tfms(final_tfms)\n",
    "    return lambda x,**k: final_tfm(affine_tfm(lighting_tfm(pixel_tfm(x)), **k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedFilesDataset(Dataset):\n",
    "    def __init__(self, folder, sz, tfms=None, classes=None):\n",
    "        self.fns, self.y = [], []\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "        self.classes = classes\n",
    "        for i, cls in enumerate(classes):\n",
    "            fnames = get_image_files(folder/cls)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.sz, self.tfms = sz, tfms\n",
    "\n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        x = pil2tensor(x)\n",
    "        if self.tfms is not None:\n",
    "            x = resolve_pipeline(self.tfms, size=self.sz)(x) \n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz, bs = 224, 64\n",
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [flip_lr_tfm(p=0.5),\n",
    "              zoom_tfm(scale=(0.9,1.1),p=0.75),\n",
    "              rotate_tfm(degrees=(-10,10.),p=0.75),\n",
    "              crop_tfm(size=sz)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device, stats):\n",
    "        self.dl,self.device = dl,device\n",
    "        self.m, self.s = map(lambda x:torch.tensor(x, dtype=torch.float32, device=device), stats)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            #x, y = b[0].to(self.device),b[1].to(self.device)\n",
    "            x = (x - self.m[None,:,None,None]) / self.s[None,:,None,None]\n",
    "            yield x,y\n",
    "    \n",
    "    def __len__(self): return (len(self.dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(ds, bs, shuffle, stats, device = None, sampler=None):\n",
    "    if device is None: device = default_device\n",
    "    dl = DataLoader(ds, batch_size=bs, shuffle=shuffle,num_workers=8, sampler=sampler, pin_memory=True)\n",
    "    return DeviceDataLoader(dl, device, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device, stats):\n",
    "        self.dl,self.device = dl,device\n",
    "        self.m, self.s = map(lambda x:torch.tensor(x, dtype=torch.float32, device=device), stats)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            x, y = b[0].to(self.device),b[1].to(self.device)\n",
    "            x = (x - self.m[None,:,None,None]) / self.s[None,:,None,None]\n",
    "            yield x,y\n",
    "    \n",
    "    def __len__(self): return (len(self.dl))\n",
    "\n",
    "def get_dataloader(ds, bs, shuffle, stats, device = None, sampler=None):\n",
    "    if device is None: device = default_device\n",
    "    dl = DataLoader(ds, batch_size=bs, shuffle=shuffle,num_workers=8, sampler=sampler, pin_memory=True)\n",
    "    return DeviceDataLoader(dl, device, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TransformedFilesDataset(PATH/'train', sz, train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:31<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.17 s, sys: 1.22 s, total: 3.39 s\n",
      "Wall time: 31.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_dl)\n",
    "%time for i in tqdm(range(100)): x,y = next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No significant change from the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

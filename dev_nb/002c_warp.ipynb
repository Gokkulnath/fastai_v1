{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from nb_002b import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('data')\n",
    "PATH = DATA_PATH/'cifar10_dog_air'\n",
    "TRAIN_PATH = PATH/'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = FilesDataset(PATH/'train')\n",
    "valid_ds = FilesDataset(PATH/'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_ds[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perspective wrapping is all explained here: https://web.archive.org/web/20150222120106/xenia.media.mit.edu/~cwren/interpolator/\n",
    "\n",
    "Other source: http://www.math.ubc.ca/~cass/graphics/Perspective.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply the transformation:\n",
    "\n",
    "$$(x,y) \\rightarrow \\left ( \\frac{ax + by + c}{gx + hy + 1}, \\frac{dx + ey + f}{gx + hy + 1} \\right )$$\n",
    "\n",
    "to the coordinates, where (a,b,c,d,e,f,g,h) are 8 cofficients we need to find. To do this we solve a system of 8 equations given by where we want to send four points (with two coordinates each). Usually it will be the four corners of the picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def find_coeffs(ori_pts, targ_pts):\n",
    "    matrix = []\n",
    "    #The equations we'll need to solve.\n",
    "    for p1, p2 in zip(targ_pts, ori_pts):\n",
    "        matrix.append([p1[0], p1[1], 1, 0, 0, 0, -p2[0]*p1[0], -p2[0]*p1[1]])\n",
    "        matrix.append([0, 0, 0, p1[0], p1[1], 1, -p2[1]*p1[0], -p2[1]*p1[1]])\n",
    "\n",
    "    A = FloatTensor(matrix)\n",
    "    B = FloatTensor(ori_pts).view(8)\n",
    "    #The 8 scalars we seek are solution of AX = B, we use the pseudo inverse to compute them since it's more numerically stable.\n",
    "    \n",
    "    res = torch.mv(torch.mm(torch.inverse(torch.mm(A.t(),A)), A.t()), B)\n",
    "    #res = numpy.dot(numpy.linalg.inv(A.T * A) * A.T, B)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_pts = [[-1,-1], [1,-1], [-1,1], [1,1]]\n",
    "targ_pts = [[-1,-1], [1,-0.5], [-1,1], [1,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = find_coeffs(ori_pts, targ_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember we have to do\n",
    "$$(x,y) \\rightarrow \\left ( \\frac{ax + by + c}{gx + hy + 1}, \\frac{dx + ey + f}{gx + hy + 1} \\right )$$\n",
    "to a lot of (x,y) coordinates that will be in a matrix c. Let's say it's of shape N * 2 to be simpler. If we add ones to the second dimension to make the matrix N * 3, and if we rewrite the coeffs in a matrix\n",
    "$$\\left ( \\begin{array}{ccc} a & b & c \\\\ d & e & f \\\\ g & h & 1 \\end{array} \\right )$$\n",
    "then the matrix product c @ coeffs.t() will be N * 3, and it will be all the\n",
    "$$(ax + by + c, dx + ey + f, gx + hy + 1).$$\n",
    "We just need to divide the first two columns by the last one to get the new coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ones(coords):\n",
    "    coords = coords.view(-1,2)\n",
    "    ones = torch.ones(coords.size(0)).unsqueeze(1)\n",
    "    coords = torch.cat([coords, ones], 1)\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_perspective(coords, coeffs):\n",
    "    ori_size = coords.size()\n",
    "    #compress all the dims expect the last one ang adds ones, coords become N * 3\n",
    "    coords = add_ones(coords)\n",
    "    #Transform the coeffs in a 3*3 matrix with a 1 at the bottom left\n",
    "    coeffs = torch.cat([coeffs, FloatTensor([1])]).view(3,3)\n",
    "    coords = torch.mm(coords, coeffs.t())\n",
    "    coords.mul_(1/coords[:,2].unsqueeze(1))\n",
    "    return coords[:,:2].view(ori_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.eye(3)[:2]\n",
    "coords = F.affine_grid(m[None], torch.Size((1,) + x.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit res = apply_perspective(coords, coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = F.grid_sample(x[None], res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top right corner should be lowered by one quarter of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just checking if not adding ones is faster or slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def apply_perspective(coords, coeffs):\n",
    "    ori_size = coords.size()\n",
    "    #compress all the dims expect the last one ang adds ones, coords become N * 3\n",
    "    coords = coords.view(-1,2)\n",
    "    #Transform the coeffs in a 3*3 matrix with a 1 at the bottom left\n",
    "    coeffs = torch.cat([coeffs, FloatTensor([1])]).view(3,3)\n",
    "    coords = torch.addmm(coeffs[:,2], coords, coeffs[:,:2].t())\n",
    "    coords.mul_(1/coords[:,2].unsqueeze(1))\n",
    "    return coords[:,:2].view(ori_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit res = apply_perspective(coords, coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version is a bit faster (instead of adding the ones, we do coords = coords * (first two columns).t() + last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = F.grid_sample(x[None], res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing we can try, moving all the corners by different bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@reg_transform\n",
    "def perspective_warp(c, img_size, magnitude:uniform=0) -> TfmType.Coord:\n",
    "    magnitude = magnitude.view(4,2)\n",
    "    ori_pts = [[-1,-1], [-1,1], [1,-1], [1,1]]\n",
    "    targ_pts = [[x+m for x,m in zip(xs, ms)] for xs, ms in zip(ori_pts, magnitude)]\n",
    "    coeffs = find_coeffs(ori_pts, targ_pts)\n",
    "    return apply_perspective(c, coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [perspective_warp_tfm(magnitude=(-0.4,0.4,8))]\n",
    "_,axes = plt.subplots(4,4, figsize=(12,12))\n",
    "for ax in axes.flatten():\n",
    "    y = apply_tfms(tfms)(x, padding_mode='zeros')\n",
    "    show_image(y, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be a bit less messy, perspective wraps are of two type: tilt and skews. Tilt changes the perspective we see the image from (on the left, right, top or bottom), skex changes one corner only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def rand_int(low,high): return random.randint(low, high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@reg_transform\n",
    "def tilt(c, img_size, direction:rand_int, magnitude:uniform=0) -> TfmType.Coord:\n",
    "    ori_pts = [[-1,-1], [-1,1], [1,-1], [1,1]]\n",
    "    if direction == 0:   targ_pts = [[-1,-1], [-1,1], [1,-1-magnitude], [1,1+magnitude]]\n",
    "    elif direction == 1: targ_pts = [[-1,-1-magnitude], [-1,1+magnitude], [1,-1], [1,1]]\n",
    "    elif direction == 2: targ_pts = [[-1,-1], [-1-magnitude,1], [1,-1], [1+magnitude,1]]\n",
    "    elif direction == 3: targ_pts = [[-1-magnitude,-1], [-1,1], [1+magnitude,-1], [1,1]]  \n",
    "    coeffs = find_coeffs(ori_pts, targ_pts)\n",
    "    return apply_perspective(c, coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@reg_transform\n",
    "def skew(c, img_size, direction:rand_int, magnitude:uniform=0) -> TfmType.Coord:\n",
    "    ori_pts = [[-1,-1], [-1,1], [1,-1], [1,1]]\n",
    "    if direction == 0:   targ_pts = [[-1-magnitude,-1], [-1,1], [1,-1], [1,1]]\n",
    "    elif direction == 1: targ_pts = [[-1,-1-magnitude], [-1,1], [1,-1], [1,1]]\n",
    "    elif direction == 2: targ_pts = [[-1,-1], [-1-magnitude,1], [1,-1], [1,1]]\n",
    "    elif direction == 3: targ_pts = [[-1,-1], [-1,1+magnitude], [1,-1], [1,1]]\n",
    "    elif direction == 4: targ_pts = [[-1,-1], [-1,1], [1+magnitude,-1], [1,1]]\n",
    "    elif direction == 5: targ_pts = [[-1,-1], [-1,1], [1,-1-magnitude], [1,1]]\n",
    "    elif direction == 6: targ_pts = [[-1,-1], [-1,1], [1,-1], [1+magnitude,1]]\n",
    "    elif direction == 7: targ_pts = [[-1,-1], [-1,1], [1,-1], [1,1+magnitude]] \n",
    "    coeffs = find_coeffs(ori_pts, targ_pts)\n",
    "    return apply_perspective(c, coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_ds[1][0]\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four deterministic tilts, going to the back of the image on the first row, and to the front on the second one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(2,4, figsize=(12,6))\n",
    "for i,ax in enumerate(axes.flatten()):\n",
    "    magns = [-0.4,0.4]\n",
    "    y = apply_affine(m=None,func=partial(tilt, direction=i%4, magnitude=magns[i//4]))(x, padding_mode='zeros')\n",
    "    show_image(y, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 8 types of skew, again back or front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(4,4, figsize=(8,8))\n",
    "for i,ax in enumerate(axes.flatten()):\n",
    "    magns = [-0.4,0.4]\n",
    "    y = apply_affine(m=None,func=partial(skew, direction=i%8, magnitude=magns[i//8]))(x, padding_mode='zeros')\n",
    "    show_image(y, ax)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with a rectangular image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(DATA_PATH/'caltech101/airplanes/image_0054.jpg')\n",
    "x = pil2tensor(img)\n",
    "show_image(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(2,4, figsize=(12,3))\n",
    "for i,ax in enumerate(axes.flatten()):\n",
    "    magns = [-0.4,0.4]\n",
    "    y = apply_affine(m=None,func=partial(tilt, direction=i%4, magnitude=magns[i//4]))(x, padding_mode='zeros')\n",
    "    show_image(y, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(4,4, figsize=(12,6))\n",
    "for i,ax in enumerate(axes.flatten()):\n",
    "    magns = [-0.4,0.4]\n",
    "    y = apply_affine(m=None,func=partial(skew, direction=i%8, magnitude=magns[i//8]))(x, padding_mode='zeros')\n",
    "    show_image(y, ax)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

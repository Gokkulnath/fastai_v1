{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_004a import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress, HBox, HTML, VBox\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(t):\n",
    "    t = int(t)\n",
    "    h,m,s = t//3600, (t//60)%60, t%60\n",
    "    if h!= 0: return f'{h}:{m:02d}:{s:02d}'\n",
    "    else:     return f'{m:02d}:{s:02d}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressBar():\n",
    "    update_every = 0.2\n",
    "    \n",
    "    def __init__(self, gen, display=True, leave=True, parent=None):\n",
    "        self._gen,self.total = gen,len(gen)\n",
    "        self.progress,self.text = IntProgress(min=0, max=self.total), HTML()\n",
    "        self.box = HBox([self.progress, self.text])\n",
    "        if parent is None: self.leave,self.display = leave,display\n",
    "        else:\n",
    "            self.leave,self.display=False,False\n",
    "            parent.add_child(self)\n",
    "        self.comment = ''\n",
    "        \n",
    "    def __iter__(self):\n",
    "        if self.display: \n",
    "            display(self.box)\n",
    "        self.update(0)\n",
    "        try:\n",
    "            for i,o in enumerate(self._gen):\n",
    "                yield o\n",
    "                self.update(i+1)\n",
    "        except:\n",
    "            self.progress.bar_style = 'danger'\n",
    "        if not self.leave: self.box.close()\n",
    "    \n",
    "    def update(self, val):\n",
    "        if val == 0:\n",
    "            self.start_t = self.last_t = time()\n",
    "            self.pred_t = 0\n",
    "            self.last_v,self.wait_for = 0,1\n",
    "            self.update_bar(0)\n",
    "        elif val >= self.last_v + self.wait_for:\n",
    "            cur_t = time()\n",
    "            avg_t = (cur_t - self.start_t) / val\n",
    "            self.wait_for = max(int(self.update_every / avg_t),1)\n",
    "            self.pred_t = avg_t * self.total\n",
    "            self.last_v,self.last_t = val,cur_t\n",
    "            self.update_bar(val)\n",
    "    \n",
    "    def update_bar(self, val):\n",
    "        elapsed_t = self.last_t - self.start_t\n",
    "        remaining_t = format_time(self.pred_t - elapsed_t)\n",
    "        elapsed_t = format_time(elapsed_t)\n",
    "        end = '' if len(self.comment) == 0 else f' {self.comment}'\n",
    "        self.text.value = f'{100 * val/self.total:.2f}% [{val}/{self.total} {elapsed_t}<{remaining_t}{end}]'\n",
    "        self.progress.value = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MasterBar():\n",
    "    def __init__(self, gen):\n",
    "        self.first_bar = ProgressBar(gen, display=False)\n",
    "        self.text = HTML()\n",
    "        self.vbox = VBox([self.first_bar.box, self.text])\n",
    "    \n",
    "    def __iter__(self):\n",
    "        display(self.vbox)\n",
    "        for o in self.first_bar:\n",
    "            yield o\n",
    "    \n",
    "    def add_child(self, child):\n",
    "        self.child = child\n",
    "        self.vbox.children = [self.first_bar.box, self.text, child.box]\n",
    "    \n",
    "    def write(self, line):\n",
    "        self.text.value += line + '<p>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = MasterBar(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "for j in mb:\n",
    "    for i in ProgressBar(range(0, 100), parent=mb):\n",
    "        sleep(0.01)\n",
    "        mb.child.comment = str(i)\n",
    "    mb.text.value += f'Epoch {j+1}: accuracy: {7.5*j+5}%<p>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class DeviceDataLoader():\n",
    "    dl: DataLoader\n",
    "    device: torch.device\n",
    "    half: bool = False\n",
    "        \n",
    "    def __len__(self): return len(self.dl)\n",
    "    def __iter__(self):\n",
    "        self.gen = (to_device(self.device,o) for o in self.dl)\n",
    "        if self.half: self.gen = (to_half(o) for o in self.gen)\n",
    "        return iter(self.gen)\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, *args, device=default_device, **kwargs):\n",
    "        return cls(DataLoader(*args, **kwargs), device=device, half=False)\n",
    "\n",
    "nb_002b.DeviceDataLoader = DeviceDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_fn, opt, data, callbacks=None, metrics=None, pbar=None):\n",
    "    cb_handler = CallbackHandler(callbacks)\n",
    "    cb_handler.on_train_begin()\n",
    "    if pbar is None: pbar = MasterBar(range(epochs))\n",
    "    \n",
    "    for epoch in pbar:\n",
    "        model.train()\n",
    "        cb_handler.on_epoch_begin()\n",
    "        \n",
    "        for xb,yb in ProgressBar(data.train_dl, parent=pbar):\n",
    "            xb, yb = cb_handler.on_batch_begin(xb, yb)\n",
    "            loss,_ = loss_batch(model, xb, yb, loss_fn, opt, cb_handler)\n",
    "            if cb_handler.on_batch_end(loss): break\n",
    "        \n",
    "        if hasattr(data,'valid_dl') and data.valid_dl is not None:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                *val_metrics,nums = zip(*[loss_batch(model, xb, yb, loss_fn, cb_handler=cb_handler, metrics=metrics)\n",
    "                                for xb,yb in ProgressBar(data.valid_dl, parent=pbar)])\n",
    "            val_metrics = [np.sum(np.multiply(val,nums)) / np.sum(nums) for val in val_metrics]\n",
    "            \n",
    "        else: val_metrics=None\n",
    "        if cb_handler.on_epoch_end(val_metrics): break\n",
    "        \n",
    "    cb_handler.on_train_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Learner():\n",
    "    data: DataBunch\n",
    "    model: nn.Module\n",
    "    opt_fn: Callable = optim.SGD\n",
    "    loss_fn: Callable = F.cross_entropy\n",
    "    metrics: Collection[Callable] = None\n",
    "    true_wd: bool = False\n",
    "    def __post_init__(self): self.model = self.model.to(self.data.device)\n",
    "\n",
    "    def fit(self, epochs, lr, wd=0., callbacks=None):\n",
    "        self.opt = OptimWrapper(self.opt_fn(self.model.parameters(), lr), wd=wd, true_wd=self.true_wd)\n",
    "        pbar = MasterBar(range(epochs))\n",
    "        self.recorder = Recorder(self.opt, self.data.train_dl, pbar)\n",
    "        if callbacks is None: callbacks = []\n",
    "        callbacks = [self.recorder]+callbacks\n",
    "        fit(epochs, self.model, self.loss_fn, self.opt, self.data, callbacks=callbacks, metrics=self.metrics, pbar=pbar)\n",
    "        \n",
    "    def lr_find(self, start_lr=1e-5, end_lr=10, num_it=100):\n",
    "        cb = LRFinder(self, start_lr, end_lr, num_it)\n",
    "        a = int(np.ceil(num_it/len(self.data.train_dl)))\n",
    "        self.fit(a, start_lr, callbacks=[cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Recorder(Callback):\n",
    "    opt: torch.optim\n",
    "    train_dl: DeviceDataLoader = None\n",
    "    pbar: MasterBar = None\n",
    "\n",
    "    def on_train_begin(self, **kwargs):\n",
    "        self.losses,self.val_losses,self.lrs,self.moms,self.metrics,self.nb_batches = [],[],[],[],[],[]\n",
    "    \n",
    "    def on_batch_begin(self, **kwargs):\n",
    "        self.lrs.append(self.opt.lr)\n",
    "        self.moms.append(self.opt.mom)\n",
    "    \n",
    "    def on_backward_begin(self, smooth_loss, **kwargs):\n",
    "        #We record the loss here before any other callback has a chance to modify it.\n",
    "        self.losses.append(smooth_loss)\n",
    "        if self.pbar is not None and hasattr(self.pbar,'child'): \n",
    "            self.pbar.child.comment = f'{smooth_loss:.4f}'\n",
    "    \n",
    "    def on_epoch_end(self, epoch, num_batch, smooth_loss, last_metrics, **kwargs):\n",
    "        self.nb_batches.append(num_batch)\n",
    "        if last_metrics is not None:\n",
    "            self.val_losses.append(last_metrics[0])\n",
    "            if len(last_metrics) > 1: self.metrics.append(last_metrics[1:])\n",
    "            self.pbar.write(f'{epoch}, {smooth_loss}, {last_metrics}')\n",
    "        else:  self.pbar.write(f'{epoch}, {smooth_loss}')\n",
    "    \n",
    "    def plot_lr(self, show_moms=False):\n",
    "        iterations = list(range(len(learn.recorder.lrs)))\n",
    "        if show_moms:\n",
    "            _, axs = plt.subplots(1,2, figsize=(12,4))\n",
    "            axs[0].plot(iterations, self.lrs)\n",
    "            axs[1].plot(iterations, self.moms)\n",
    "        else: plt.plot(iterations, self.lrs)\n",
    "    \n",
    "    def plot(self, skip_start=10, skip_end=5):\n",
    "        lrs = self.lrs[skip_start:-skip_end] if skip_end > 0 else self.lrs[skip_start:]\n",
    "        losses = self.losses[skip_start:-skip_end] if skip_end > 0 else self.losses[skip_start:]\n",
    "        _, ax = plt.subplots(1,1)\n",
    "        ax.plot(lrs, losses)\n",
    "        ax.set_xscale('log')\n",
    "    \n",
    "    def plot_losses(self):\n",
    "        _, ax = plt.subplots(1,1)\n",
    "        iterations = list(range(len(self.losses)))\n",
    "        ax.plot(iterations, self.losses)\n",
    "        val_iter = self.nb_batches\n",
    "        val_iter = np.array(val_iter).cumsum()\n",
    "        ax.plot(val_iter, self.val_losses)\n",
    "    \n",
    "    def plot_metrics(self):\n",
    "        assert len(self.metrics) != 0, \"There is no metrics to plot.\"\n",
    "        _, axes = plt.subplots(len(self.metrics[0]),1,figsize=(6, 4*len(self.metrics[0])))\n",
    "        val_iter = self.nb_batches\n",
    "        val_iter = np.array(val_iter).cumsum()\n",
    "        axes = axes.flatten() if len(self.metrics[0]) != 1 else [axes]\n",
    "        for i, ax in enumerate(axes):\n",
    "            values = [met[i] for met in self.metrics]\n",
    "            ax.plot(val_iter, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('data')\n",
    "PATH = DATA_PATH/'cifar10'\n",
    "\n",
    "data_mean,data_std = map(tensor, ([0.491, 0.482, 0.447], [0.247, 0.243, 0.261]))\n",
    "cifar_norm = normalize_tfm(mean=data_mean,std=data_std)\n",
    "\n",
    "tfms = [flip_lr_tfm(p=0.5),\n",
    "        pad_tfm(padding=4),\n",
    "        crop_tfm(size=32, row_pct=(0,1.), col_pct=(0,1.))]\n",
    "\n",
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = FilesDataset.from_folder(PATH/'train', classes=['airplane','dog'])\n",
    "valid_ds = FilesDataset.from_folder(PATH/'test', classes=['airplane','dog'])\n",
    "data = DataBunch.create(train_ds, valid_ds, bs=bs, train_tfm=tfms, valid_tfm=[], num_workers=4)\n",
    "len(data.train_dl), len(data.valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet([1, 2, 2, 2, 2], num_classes=2, nf=16)\n",
    "learn = Learner(data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

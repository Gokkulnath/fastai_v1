{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_005 import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikitext 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset [here](https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip) and unzip it so it's in the folder wikitext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS = '<eos>'\n",
    "PATH=Path('data/wikitext')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small helper function to read the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    tokens = []\n",
    "    with open(PATH/filename, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            tokens.append(line.split() + [EOS])\n",
    "    return np.array(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_tok = read_file('wiki.train.tokens')\n",
    "val_tok = read_file('wiki.valid.tokens')\n",
    "tst_tok = read_file('wiki.test.tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36718, 3760, 4358)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_tok), len(val_tok), len(tst_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(trn_tok[4][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 113161),\n",
       " (',', 99913),\n",
       " ('.', 73388),\n",
       " ('of', 56889),\n",
       " ('<unk>', 54625),\n",
       " ('and', 50603),\n",
       " ('in', 39453),\n",
       " ('to', 39190),\n",
       " ('<eos>', 36718),\n",
       " ('a', 34237)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = Counter(word for sent in trn_tok for word in sent)\n",
    "cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give an id to each token and add the pad token (just in case we need it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = [o for o,c in cnt.most_common()]\n",
    "itos.insert(0,'<pad>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33279"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(itos); vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the mapping from token to id then numericalizing our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = collections.defaultdict(lambda : 5, {w:i for i,w in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ids = np.array([([stoi[w] for w in s]) for s in trn_tok])\n",
    "val_ids = np.array([([stoi[w] for w in s]) for s in val_tok])\n",
    "tst_ids = np.array([([stoi[w] for w in s]) for s in tst_tok])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use the AWD-LSTM from [Stephen Merity](https://arxiv.org/abs/1708.02182). First, we'll need all different kinds of dropouts. Dropout consists into replacing some coefficients by 0 with probability p. To ensure that the averga of the weights remains constant, we apply a correction to the weights that aren't nullified of a factor `1/(1-p)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_mask(x, sz, p):\n",
    "    \"Returns a dropout mask of the same type as x, size sz, with probability p to cancel an element.\"\n",
    "    return x.new(*sz).bernoulli_(1-p)/(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 0., 2., 0., 0., 2., 0., 2., 0.],\n",
       "        [2., 0., 0., 2., 0., 2., 0., 0., 0., 2.],\n",
       "        [2., 0., 2., 2., 0., 0., 2., 0., 0., 2.],\n",
       "        [0., 0., 2., 0., 0., 2., 2., 0., 0., 0.],\n",
       "        [2., 0., 2., 0., 2., 0., 0., 2., 2., 0.],\n",
       "        [0., 2., 2., 2., 0., 0., 2., 0., 2., 2.],\n",
       "        [0., 0., 2., 0., 0., 0., 2., 0., 0., 0.],\n",
       "        [2., 0., 2., 0., 0., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 0., 0., 0., 2., 2., 0.],\n",
       "        [0., 2., 2., 2., 2., 2., 0., 0., 2., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(10,10)\n",
    "dropout_mask(x, (10,10), 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once with have a dropout mask `m`, applying the dropout to `x` is simply done by `x = x * m`. We create our own dropout mask and don't rely on pytorch dropout because we want to nullify the coefficients on the batch dimension but not the token dimension (aka the same coefficients are replaced by zero for each word in the sentence). \n",
    "\n",
    "Inside a RNN, a tensor x will have three dimensions: seq_len, bs, vocab_size, so we create a dropout mask for the last two dimensions and broadcast it to the first dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNDropout(nn.Module):\n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__()\n",
    "        self.p=p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.training or not self.p: return x\n",
    "        m = dropout_mask(x.data, (1, x.size(1), x.size(2)), self.p)\n",
    "        return m * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.9901, -0.9491, -0.2538,  0.2669, -1.0387, -0.6803, -0.1309,\n",
       "            0.5409, -0.1089,  0.1139],\n",
       "          [-1.5815, -0.7023,  1.0417, -0.6517,  0.1800,  1.4703,  1.1635,\n",
       "            1.0649,  1.6631, -0.0459],\n",
       "          [ 1.8676, -0.8832, -0.8476,  0.3524,  2.6596,  1.2432, -0.3587,\n",
       "            1.3670, -0.5917,  1.0211],\n",
       "          [ 0.3662,  0.0283,  0.4290,  2.7126,  0.8004,  0.8621,  0.6163,\n",
       "            1.2706,  0.0633,  0.1964],\n",
       "          [ 0.7371,  0.2741,  0.4601, -0.0003,  0.2714, -0.2649,  0.7640,\n",
       "            1.8827, -1.1130,  1.5036]],\n",
       " \n",
       "         [[-1.2806, -0.0421,  0.3034,  0.3624,  0.2683, -0.0867, -1.6087,\n",
       "           -0.4795,  1.5125, -0.0765],\n",
       "          [ 0.1915,  1.5651, -0.7167, -0.0130, -0.9117,  0.0379,  0.2068,\n",
       "           -1.2578,  0.3432,  1.0319],\n",
       "          [ 0.8134, -0.8821, -0.1735,  1.4034,  1.6443, -0.6728,  0.2942,\n",
       "           -0.1264,  0.0781, -0.5670],\n",
       "          [ 1.3625,  0.7245,  1.8641, -1.8053,  0.3111, -0.0901,  0.5542,\n",
       "           -0.5308, -1.0046, -0.5563],\n",
       "          [ 1.4120,  0.3507,  1.8503,  0.0710,  0.0127, -1.1296, -0.0491,\n",
       "           -0.1605,  0.6586, -0.5012]]]),\n",
       " tensor([[[-0.0000, -1.8983, -0.5076,  0.0000, -2.0774, -0.0000, -0.0000,\n",
       "            0.0000, -0.0000,  0.0000],\n",
       "          [-3.1631, -1.4047,  0.0000, -1.3034,  0.0000,  0.0000,  2.3269,\n",
       "            0.0000,  0.0000, -0.0000],\n",
       "          [ 3.7351, -0.0000, -1.6953,  0.0000,  0.0000,  0.0000, -0.0000,\n",
       "            2.7340, -0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.8579,  5.4251,  1.6008,  0.0000,  0.0000,\n",
       "            2.5412,  0.0000,  0.0000],\n",
       "          [ 1.4742,  0.0000,  0.9202, -0.0006,  0.0000, -0.5297,  0.0000,\n",
       "            3.7654, -0.0000,  0.0000]],\n",
       " \n",
       "         [[-0.0000, -0.0842,  0.6068,  0.0000,  0.5367, -0.0000, -0.0000,\n",
       "           -0.0000,  0.0000, -0.0000],\n",
       "          [ 0.3830,  3.1303, -0.0000, -0.0259, -0.0000,  0.0000,  0.4137,\n",
       "           -0.0000,  0.0000,  0.0000],\n",
       "          [ 1.6268, -0.0000, -0.3470,  0.0000,  0.0000, -0.0000,  0.0000,\n",
       "           -0.2529,  0.0000, -0.0000],\n",
       "          [ 0.0000,  0.0000,  3.7283, -3.6105,  0.6221, -0.0000,  0.0000,\n",
       "           -1.0616, -0.0000, -0.0000],\n",
       "          [ 2.8240,  0.0000,  3.7007,  0.1420,  0.0000, -2.2592, -0.0000,\n",
       "           -0.3211,  0.0000, -0.0000]]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_test = RNNDropout(0.5)\n",
    "x = torch.randn(2,5,10)\n",
    "x, dp_test(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noop(x): return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightDropout(nn.Module):\n",
    "    \"A module that warps another layer in which some weights will be replaced by 0 during training.\"\n",
    "    \n",
    "    def __init__(self, module, dropout, layer_names=['weight_hh_l0']):\n",
    "        super().__init__()\n",
    "        self.module,self.dropout,self.layer_names = module,dropout,layer_names\n",
    "    \n",
    "    def _setweights(self):\n",
    "        for layer in self.layer_names:\n",
    "            raw_w = getattr(self, f'{layer}_raw')\n",
    "            w1 = F.dropout(raw_w, p=self.dropout, training=self.training)\n",
    "            setattr(self.module, layer, w1)\n",
    "    \n",
    "    def forward(self, *args):\n",
    "        self._setweights()\n",
    "        return self.module.forward(*args)\n",
    "    \n",
    "    def reset(self):\n",
    "        for layer in self.layer_names:\n",
    "            #Makes a copy of the weights of the selected layers.\n",
    "            w = getattr(self.module, layer)\n",
    "            self.register_parameter(f'{layer}_raw', nn.Parameter(w.data))\n",
    "            del self.module._parameters[layer]\n",
    "        if hasattr(self.module, 'reset'): self.module.reset()\n",
    "    \n",
    "    def update_raw(self):\n",
    "        for layer in self.layer_names:\n",
    "            w = getattr(self.module, layer)\n",
    "            mask = w != 0.\n",
    "            self.raw_weights[layer][mask] = w[mask] * (1-self.dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WeightDropout(\n",
       "  (module): LSTM(20, 20)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = nn.LSTM(20, 20)\n",
    "dp_module = WeightDropout(module, 0.5)\n",
    "dp_module.reset()\n",
    "opt = optim.SGD(dp_module.parameters(), 10)\n",
    "dp_module.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-2a05d5cec176>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_raw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'w_raw' is not defined"
     ]
    }
   ],
   "source": [
    "w = F.dropout(w_raw, p=0.5, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-74c7db5447c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'w' is not defined"
     ]
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "got an incorrect number of RNN parameters",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-c6d6c66756c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdp_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-cbe9a2ed2277>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setweights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai1\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 179\u001b[1;33m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mRuntimeError\u001b[0m: got an incorrect number of RNN parameters"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,5,20)\n",
    "x.requires_grad_(requires_grad=True)\n",
    "h = (torch.zeros(1,5,20), torch.zeros(1,5,20))\n",
    "for _ in range(5): x,h = dp_module(x,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2024, -0.1610,  0.0000,  ..., -0.1056,  0.0583, -0.0000],\n",
       "         [-0.0000,  0.0000,  0.4104,  ...,  0.2743,  0.0000,  0.0000],\n",
       "         [-0.0000,  0.1541,  0.0000,  ..., -0.2783,  0.0000,  0.0008],\n",
       "         ...,\n",
       "         [ 0.2867,  0.0000,  0.0668,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0588, -0.0000,  0.0000,  ...,  0.0000, -0.2593, -0.0000],\n",
       "         [ 0.3162,  0.0000,  0.3668,  ..., -0.0000, -0.0000, -0.0000]],\n",
       "        grad_fn=<DropoutBackward>), Parameter containing:\n",
       " tensor([[ 0.1012, -0.0805,  0.0896,  ..., -0.0528,  0.0291, -0.1451],\n",
       "         [-0.1924,  0.2114,  0.2052,  ...,  0.1372,  0.2105,  0.1657],\n",
       "         [-0.1455,  0.0771,  0.0892,  ..., -0.1391,  0.1880,  0.0004],\n",
       "         ...,\n",
       "         [ 0.1434,  0.2104,  0.0334,  ...,  0.2112,  0.1248,  0.1113],\n",
       "         [-0.0294, -0.0133,  0.1843,  ...,  0.0759, -0.1296, -0.1526],\n",
       "         [ 0.1581,  0.0990,  0.1834,  ..., -0.1259, -0.0425, -0.0921]],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(dp_module.module, 'weight_hh_l0'),getattr(dp_module,'weight_hh_l0_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.randint(0,20,(10,)).long()\n",
    "loss = F.nll_loss(x.view(-1,20), target)\n",
    "loss.backward()\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, tensor([[ 0.0003,  0.0005,  0.0002,  ...,  0.0001,  0.0005,  0.0001],\n",
       "         [-0.0000, -0.0003, -0.0001,  ..., -0.0000, -0.0008,  0.0002],\n",
       "         [ 0.0001,  0.0002, -0.0000,  ...,  0.0001,  0.0001, -0.0001],\n",
       "         ...,\n",
       "         [-0.0002, -0.0000,  0.0000,  ...,  0.0000, -0.0001, -0.0000],\n",
       "         [-0.0014,  0.0001,  0.0001,  ..., -0.0000, -0.0009,  0.0001],\n",
       "         [-0.0000, -0.0001, -0.0001,  ...,  0.0000, -0.0000,  0.0000]]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, w_raw = getattr(dp_module.module, 'weight_hh_l0'),getattr(dp_module,'weight_hh_l0_raw')\n",
    "w.grad, w_raw.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 0.1554, -0.0616,  0.2184,  ...,  0.2113,  0.0702,  0.1316],\n",
       "         [-0.1992, -0.0237,  0.0526,  ...,  0.1810,  0.1886, -0.2164],\n",
       "         [ 0.1710, -0.0467, -0.2082,  ...,  0.1273, -0.1579,  0.1089],\n",
       "         ...,\n",
       "         [ 0.0842, -0.0625, -0.1341,  ...,  0.1033,  0.1231,  0.0102],\n",
       "         [-0.1119, -0.0186,  0.1200,  ...,  0.0714,  0.0843, -0.0027],\n",
       "         [-0.1073,  0.1865,  0.1759,  ...,  0.0214, -0.2209,  0.0449]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.1554, -0.0616,  0.2184,  ...,  0.2113,  0.0702,  0.1316],\n",
       "         [-0.1992, -0.0237,  0.0526,  ...,  0.1810,  0.1886, -0.2164],\n",
       "         [ 0.1710, -0.0467, -0.2082,  ...,  0.1273, -0.1579,  0.1089],\n",
       "         ...,\n",
       "         [ 0.0842, -0.0625, -0.1341,  ...,  0.1033,  0.1231,  0.0102],\n",
       "         [-0.1119, -0.0186,  0.1200,  ...,  0.0714,  0.0843, -0.0027],\n",
       "         [-0.1073,  0.1865,  0.1759,  ...,  0.0214, -0.2209,  0.0449]],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(dp_module.module, 'weight_hh_l0'),getattr(dp_module,'weight_hh_l0_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [Parameter containing:\n",
       "   tensor([[ 0.1554, -0.0616,  0.2184,  ...,  0.2113,  0.0702,  0.1316],\n",
       "           [-0.1992, -0.0237,  0.0526,  ...,  0.1810,  0.1886, -0.2164],\n",
       "           [ 0.1710, -0.0467, -0.2082,  ...,  0.1273, -0.1579,  0.1089],\n",
       "           ...,\n",
       "           [ 0.0842, -0.0625, -0.1341,  ...,  0.1033,  0.1231,  0.0102],\n",
       "           [-0.1119, -0.0186,  0.1200,  ...,  0.0714,  0.0843, -0.0027],\n",
       "           [-0.1073,  0.1865,  0.1759,  ...,  0.0214, -0.2209,  0.0449]],\n",
       "          requires_grad=True), Parameter containing:\n",
       "   tensor([[ 0.0747,  0.0088,  0.1997,  ..., -0.0098, -0.1459, -0.1907],\n",
       "           [-0.1819,  0.2078, -0.0633,  ...,  0.0808, -0.0304, -0.1768],\n",
       "           [ 0.1626, -0.0114, -0.0725,  ...,  0.0376,  0.0046,  0.0529],\n",
       "           ...,\n",
       "           [-0.1112, -0.0902,  0.0758,  ..., -0.2081, -0.2276, -0.0936],\n",
       "           [ 0.0706, -0.0816,  0.2260,  ...,  0.0985,  0.2174,  0.1962],\n",
       "           [-0.1049, -0.1724, -0.0193,  ...,  0.1149,  0.1946,  0.1333]],\n",
       "          requires_grad=True), Parameter containing:\n",
       "   tensor([[ 0.1554, -0.0616,  0.2184,  ...,  0.2113,  0.0702,  0.1316],\n",
       "           [-0.1992, -0.0237,  0.0526,  ...,  0.1810,  0.1886, -0.2164],\n",
       "           [ 0.1710, -0.0467, -0.2082,  ...,  0.1273, -0.1579,  0.1089],\n",
       "           ...,\n",
       "           [ 0.0842, -0.0625, -0.1341,  ...,  0.1033,  0.1231,  0.0102],\n",
       "           [-0.1119, -0.0186,  0.1200,  ...,  0.0714,  0.0843, -0.0027],\n",
       "           [-0.1073,  0.1865,  0.1759,  ...,  0.0214, -0.2209,  0.0449]],\n",
       "          requires_grad=True), Parameter containing:\n",
       "   tensor([ 0.0444,  0.0791,  0.0841,  0.0582, -0.2282,  0.1387,  0.2405,  0.0495,\n",
       "           -0.0512, -0.1180,  0.1942, -0.2749,  0.0702, -0.0540,  0.2095, -0.0293,\n",
       "            0.0640,  0.1362, -0.1643,  0.1961, -0.0356,  0.0612,  0.0837,  0.1274,\n",
       "           -0.0054,  0.1342,  0.0156,  0.2105, -0.1520, -0.1494,  0.0797, -0.1437,\n",
       "            0.1463,  0.1023,  0.1793, -0.1820, -0.1511,  0.2543, -0.1578, -0.1804,\n",
       "            0.0008, -0.2370,  0.3417, -0.1310,  0.0005,  0.2680,  1.0072,  0.4012,\n",
       "           -0.3315,  0.5105,  0.7214,  0.8504,  0.3681,  0.9183,  0.5447,  0.1445,\n",
       "           -0.1769,  1.1115,  0.5499, -0.2375, -0.1999, -0.0690, -0.1481, -0.1879,\n",
       "           -0.0842,  0.0655, -0.0052, -0.0606,  0.0747,  0.2368, -0.0185, -0.0069,\n",
       "           -0.0646,  0.1703,  0.2900,  0.1093, -0.1083,  0.2869,  0.0821, -0.1535],\n",
       "          requires_grad=True), Parameter containing:\n",
       "   tensor([-0.2049,  0.0407,  0.0328, -0.1107, -0.0924,  0.0148,  0.0760, -0.0735,\n",
       "            0.0666,  0.1691,  0.0081, -0.1511, -0.2399,  0.3062, -0.1114, -0.1973,\n",
       "           -0.1027,  0.1152, -0.2006, -0.2006,  0.1398,  0.2113,  0.0499,  0.1271,\n",
       "            0.1017,  0.0152,  0.2154,  0.0202,  0.1986, -0.0669,  0.2688, -0.1419,\n",
       "           -0.0918,  0.1159,  0.3195,  0.1446, -0.0857,  0.2681,  0.1193, -0.0497,\n",
       "            0.0980, -0.2625,  0.1451, -0.1767,  0.0086,  0.3587,  0.8197,  0.6496,\n",
       "           -0.3831,  0.4416,  0.6532,  0.7431,  0.1252,  0.8742,  0.3746,  0.3482,\n",
       "           -0.0724,  1.1417,  0.2374, -0.0222,  0.0059,  0.0667, -0.0330,  0.0127,\n",
       "           -0.1280, -0.1181, -0.0300, -0.1381, -0.0465,  0.1322,  0.0439, -0.2245,\n",
       "            0.1497,  0.0424,  0.0193, -0.1006, -0.0168, -0.0833,  0.1574, -0.0337],\n",
       "          requires_grad=True)],\n",
       "  'lr': 10,\n",
       "  'momentum': 0,\n",
       "  'dampening': 0,\n",
       "  'weight_decay': 0,\n",
       "  'nesterov': False}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightDrop(torch.nn.Module):\n",
    "    def __init__(self, module, weights=['weight_hh_l0'], dropout=0, variational=False):\n",
    "        super(WeightDrop, self).__init__()\n",
    "        self.module = module\n",
    "        self.weights = weights\n",
    "        self.dropout = dropout\n",
    "        self.variational = variational\n",
    "        self._setup()\n",
    "\n",
    "    def widget_demagnetizer_y2k_edition(*args, **kwargs):\n",
    "        # We need to replace flatten_parameters with a nothing function\n",
    "        # It must be a function rather than a lambda as otherwise pickling explodes\n",
    "        # We can't write boring code though, so ... WIDGET DEMAGNETIZER Y2K EDITION!\n",
    "        # (╯°□°）╯︵ ┻━┻\n",
    "        return\n",
    "\n",
    "    def _setup(self):\n",
    "        # Terrible temporary solution to an issue regarding compacting weights re: CUDNN RNN\n",
    "        if issubclass(type(self.module), torch.nn.RNNBase):\n",
    "            self.module.flatten_parameters = self.widget_demagnetizer_y2k_edition\n",
    "\n",
    "        for name_w in self.weights:\n",
    "            print('Applying weight drop of {} to {}'.format(self.dropout, name_w))\n",
    "            w = getattr(self.module, name_w)\n",
    "            del self.module._parameters[name_w]\n",
    "            self.module.register_parameter(name_w + '_raw', nn.Parameter(w.data))\n",
    "\n",
    "    def _setweights(self):\n",
    "        for name_w in self.weights:\n",
    "            raw_w = getattr(self.module, name_w + '_raw')\n",
    "            w = None\n",
    "            if self.variational:\n",
    "                mask = torch.autograd.Variable(torch.ones(raw_w.size(0), 1))\n",
    "                if raw_w.is_cuda: mask = mask.cuda()\n",
    "                mask = torch.nn.functional.dropout(mask, p=self.dropout, training=True)\n",
    "                w = mask.expand_as(raw_w) * raw_w\n",
    "            else:\n",
    "                w = torch.nn.functional.dropout(raw_w, p=self.dropout, training=self.training)\n",
    "            setattr(self.module, name_w, w)\n",
    "\n",
    "    def forward(self, *args):\n",
    "        self._setweights()\n",
    "        return self.module.forward(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying weight drop of 0.9 to weight\n",
      "All items should be different\n",
      "Run 1: [tensor(-1.2833, device='cuda:0'), tensor(-4.5258, device='cuda:0')]\n",
      "Run 2: [tensor(3.3188, device='cuda:0'), tensor(-6.7075, device='cuda:0')]\n",
      "Testing WeightDrop with LSTM\n",
      "Applying weight drop of 0.9 to weight_hh_l0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sylvain\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py:477: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  result = self.forward(*input, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First timesteps should be equal, all others should differ\n",
      "Run 1: [tensor(-0.2832, device='cuda:0'), tensor(-0.4045, device='cuda:0')]\n",
      "Run 2: [tensor(-0.2832, device='cuda:0'), tensor(-0.3857, device='cuda:0')]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "x = torch.autograd.Variable(torch.randn(2, 1, 10)).cuda()\n",
    "h0 = None\n",
    "lin = WeightDrop(torch.nn.Linear(10, 10), ['weight'], dropout=0.9)\n",
    "lin.cuda()\n",
    "run1 = [x.sum() for x in lin(x).data]\n",
    "run2 = [x.sum() for x in lin(x).data]\n",
    "\n",
    "print('All items should be different')\n",
    "print('Run 1:', run1)\n",
    "print('Run 2:', run2)\n",
    "\n",
    "print('Testing WeightDrop with LSTM')\n",
    "\n",
    "wdrnn = WeightDrop(torch.nn.LSTM(10, 10), ['weight_hh_l0'], dropout=0.9)\n",
    "wdrnn.cuda()\n",
    "\n",
    "run1 = [x.sum() for x in wdrnn(x, h0)[0].data]\n",
    "run2 = [x.sum() for x in wdrnn(x, h0)[0].data]\n",
    "\n",
    "print('First timesteps should be equal, all others should differ')\n",
    "print('Run 1:', run1)\n",
    "print('Run 2:', run2)\n",
    "\n",
    "print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying weight drop of 0.5 to weight_hh_l0\n"
     ]
    }
   ],
   "source": [
    "module = nn.LSTM(10, 20)\n",
    "dp_module = WeightDrop(module, dropout=0.5)\n",
    "#dp_module.reset()\n",
    "opt = optim.SGD(dp_module.parameters(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LSTM' object has no attribute 'weight_hh_l0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-4673c00d09f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdp_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weight_hh_l0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdp_module\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'weight_hh_l0_raw'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 518\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LSTM' object has no attribute 'weight_hh_l0'"
     ]
    }
   ],
   "source": [
    "getattr(dp_module.module, 'weight_hh_l0'),getattr(dp_module,'weight_hh_l0_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2,5,10)\n",
    "x.requires_grad_(requires_grad=True)\n",
    "h = (torch.zeros(1,5,20), torch.zeros(1,5,20))\n",
    "out,h = dp_module(x,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(5, 3)  # Input dim is 3, output dim is 3\n",
    "inputs = torch.randn(7, 2, 5)  # make a sequence of length 5\n",
    "\n",
    "# initialize the hidden state.\n",
    "hidden = (torch.randn(1, 2, 3),\n",
    "          torch.randn(1, 2, 3))\n",
    "# Step through the sequence one element at a time.\n",
    "# after each step, hidden contains the hidden state.\n",
    "out, hidden = lstm(inputs.view(7, 2, -1), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

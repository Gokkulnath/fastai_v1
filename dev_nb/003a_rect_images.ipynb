{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from nb_002b import *\n",
    "\n",
    "import operator\n",
    "from random import sample\n",
    "from torch.utils.data.sampler import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('data')\n",
    "PATH = DATA_PATH/'caltech101'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caltech 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FilesDataset(Dataset):\n",
    "    def __init__(self, fns, labels, classes=None):\n",
    "        if classes is None: classes = list(set(labels))\n",
    "        self.classes = classes\n",
    "        self.class2idx = {v:k for k,v in enumerate(classes)}\n",
    "        self.fns = np.array(fns)\n",
    "        self.y = [self.class2idx[o] for o in labels]\n",
    "        \n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        return pil2tensor(x),self.y[i]\n",
    "    \n",
    "    @classmethod\n",
    "    def from_folder(cls, folder, classes=None, test_pct=0.):\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "            \n",
    "        fns,labels = [],[]\n",
    "        for cl in classes:\n",
    "            fnames = get_image_files(folder/cl)\n",
    "            fns += fnames\n",
    "            labels += [cl] * len(fnames)\n",
    "            \n",
    "        if test_pct==0.: return cls(fns, labels)\n",
    "        \n",
    "        fns,labels = np.array(fns),np.array(labels)\n",
    "        is_test = np.random.uniform(size=(len(fns),)) < test_pct\n",
    "        return cls(fns[~is_test], labels[~is_test]), cls(fns[is_test], labels[is_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"airplanes\", \"Motorbikes\", \"BACKGROUND_Google\", \"Faces\", \"watch\", \"Leopards\", \"bonsai\",\n",
    "    \"car_side\", \"ketch\", \"chandelier\", \"hawksbill\", \"grand_piano\", \"brain\", \"butterfly\", \"helicopter\", \"menorah\",\n",
    "    \"trilobite\", \"starfish\", \"kangaroo\", \"sunflower\", \"ewer\", \"buddha\", \"scorpion\", \"revolver\", \"laptop\", \"ibis\", \"llama\",\n",
    "    \"minaret\", \"umbrella\", \"electric_guitar\", \"crab\", \"crayfish\",]\n",
    "\n",
    "np.random.seed(42)\n",
    "train_ds,valid_ds = FilesDataset.from_folder(PATH, test_pct=0.2)\n",
    "\n",
    "x = train_ds[-1][0]\n",
    "classes = train_ds.classes\n",
    "c = len(classes)\n",
    "\n",
    "len(train_ds),len(valid_ds),c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Rectangular affine fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "show_image(x, figsize=(6,3), hide_axis=False)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rot_m = np.array(rotate(40.)); rot_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "show_image(apply_affine(rot_m)(x), figsize=(6,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def affine_grid(x, matrix, size=None):\n",
    "    h,w = x.shape[1:]\n",
    "    if size is None: size=x.shape\n",
    "    matrix[0,1] *= h/w; matrix[1,0] *= w/h\n",
    "    return F.affine_grid(matrix[None,:2], torch.Size((1,)+size))\n",
    "\n",
    "import nb_002\n",
    "nb_002.affine_grid = affine_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "show_image(apply_affine(rot_m)(x), figsize=(6,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Crop with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "TfmType = IntEnum('TfmType', 'Start Affine Coord Pixel Lighting Crop')\n",
    "\n",
    "@reg_transform\n",
    "def crop_pad(x, size, padding_mode='reflect',\n",
    "             row_pct:uniform = 0.5, col_pct:uniform = 0.5) -> TfmType.Crop:\n",
    "    size = listify(size,2)\n",
    "    rows,cols = size\n",
    "    if x.size(1)<rows or x.size(2)<cols:\n",
    "        row_pad = max((rows-x.size(1)+1)//2, 0)\n",
    "        col_pad = max((cols-x.size(2)+1)//2, 0)\n",
    "        x = F.pad(x[None], (col_pad,col_pad,row_pad,row_pad), mode=padding_mode)[0]\n",
    "    row = int((x.size(1)-rows)*row_pct)\n",
    "    col = int((x.size(2)-cols)*col_pct)\n",
    "\n",
    "    x = x[:, row:row+rows, col:col+cols]\n",
    "    return x.contiguous() # without this, get NaN later - don't know why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "show_image(crop_pad(x, 500, row_pct=0.,col_pct=0., padding_mode='constant'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "show_image(crop_pad(x, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "show_image(crop_pad(x, 200, row_pct=0.,col_pct=0.98, padding_mode='constant'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine crop/resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,r,c = x.shape; x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_crop_target(target_px, target_aspect=1.):\n",
    "    target_px = listify(target_px, 2)\n",
    "    target_r = int(math.sqrt(target_px[0]*target_px[1]/target_aspect))\n",
    "    target_c = int(target_r*target_aspect)\n",
    "    return target_r,target_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_crop_target(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_target = get_crop_target(200, 2.);\n",
    "target_r,target_c = crop_target\n",
    "crop_target, target_r*target_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ratio = r/target_r\n",
    "c_ratio = c/target_c\n",
    "# min -> crop; max -> pad\n",
    "ratio = max(r_ratio,c_ratio)\n",
    "r_ratio,c_ratio,ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2,c2 = round(r/ratio),round(c/ratio); r2,c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_resize_target(img, crop_target, do_crop=False):\n",
    "    if crop_target is None: return None\n",
    "    ch,r,c = img.shape\n",
    "    target_r,target_c = crop_target\n",
    "    ratio = (min if do_crop else max)(r/target_r, c/target_c)\n",
    "    return ch,round(r/ratio),round(c/ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_resize_target(x, crop_target, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_resize_target(x, crop_target, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def apply_affine(m=None, func=None, crop_func=None):\n",
    "    def _inner(img, size=None, padding_mode='reflect', do_crop=False, **kwargs):\n",
    "        if size is not None: size = listify(size,2)\n",
    "        if m is None:\n",
    "            if func is None and size is None: return img\n",
    "            else: m2=torch.eye(3)\n",
    "        else:\n",
    "            m2 = img.new_tensor(m)\n",
    "        resize_target = get_resize_target(img, size, do_crop=do_crop)\n",
    "        c = affine_grid(img, m2, size=resize_target)\n",
    "        if func is not None: c = func(c)\n",
    "        res = grid_sample(img, c, padding_mode=padding_mode, **kwargs)\n",
    "        if padding_mode=='zeros': padding_mode='constant'\n",
    "        if crop_func is not None: res = crop_func(res, size=size, padding_mode=padding_mode)\n",
    "        return res\n",
    "    return _inner\n",
    "\n",
    "nb_002.apply_affine = apply_affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = apply_affine(rot_m)(x, size=crop_target, do_crop=False)\n",
    "show_image(img, figsize=(6,3))\n",
    "crop_target, img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = apply_affine(rot_m, crop_func=crop_pad)(x, do_crop=False, size=crop_target)\n",
    "show_image(img, figsize=(6,3))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = apply_affine(rot_m, crop_func=crop_pad)(x, do_crop=False, size=crop_target, padding_mode='zeros')\n",
    "show_image(img, figsize=(6,3))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = apply_affine(rot_m, crop_func=crop_pad)(x, do_crop=True, size=crop_target)\n",
    "show_image(img, figsize=(6,3))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def apply_tfms(tfms):\n",
    "    grouped_tfms = dict_groupby(listify(tfms), lambda o: o.tfm_type)\n",
    "    start_tfms,affine_tfms,coord_tfms,pixel_tfms,lighting_tfms,crop_tfms = [\n",
    "        resolve_tfms(grouped_tfms.get(o)) for o in TfmType]\n",
    "    lighting_func = apply_lighting(compose(lighting_tfms))\n",
    "    affine_func = apply_affine(\n",
    "        affines_mat(affine_tfms), func=compose(coord_tfms), crop_func=compose(crop_tfms))\n",
    "    start_func = compose(start_tfms)\n",
    "    pixel_func = compose(pixel_tfms)\n",
    "    def _inner(x, **kwargs):\n",
    "        res = affine_func(start_func(x.clone()), **kwargs)\n",
    "        return pixel_func(lighting_func(res))\n",
    "    return _inner\n",
    "\n",
    "nb_002.apply_tfms = apply_tfms\n",
    "import nb_002b\n",
    "nb_002b.apply_tfms = apply_tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [\n",
    "    rotate_tfm(degrees=(-20,20.)),\n",
    "    zoom_tfm(scale=(1.,1.95)),\n",
    "]\n",
    "\n",
    "_,axes = plt.subplots(2,2, figsize=(12,5))\n",
    "for ax in axes.flat:\n",
    "    show_image(apply_tfms(tfms)(x, do_crop=True, size=(60,100)), ax, hide_axis=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [\n",
    "    rotate_tfm(degrees=(-20,20.)),\n",
    "    zoom_tfm(scale=(1.,1.95)),\n",
    "    crop_pad_tfm()\n",
    "]\n",
    "\n",
    "_,axes = plt.subplots(2,2, figsize=(6,6))\n",
    "for ax in axes.flat:\n",
    "    show_image(apply_tfms(tfms)(x, do_crop=False, size=100, padding_mode='zeros'), ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[Image.open(fn).size for fn in np.random.choice(train_ds.fns, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfms = [\n",
    "    rotate_tfm(degrees=(-20,20.)),\n",
    "    zoom_tfm(scale=(1.,1.5), row_pct=(0,1.), col_pct=(0,1.)),\n",
    "    crop_pad_tfm(row_pct=(0,1.), col_pct=(0,1.))\n",
    "]\n",
    "valid_tfms = [\n",
    "    zoom_tfm(),\n",
    "    crop_pad_tfm()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(1,4, figsize=(10,5))\n",
    "for ax in axes.flat:\n",
    "    show_image(apply_tfms(train_tfms)(x, do_crop=True, size=size), ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tds = TfmDataset(valid_ds, valid_tfms, size=150, padding_mode='zeros')\n",
    "data = DataBunch(valid_tds, valid_tds, bs=bs, num_workers=12)\n",
    "xb,yb = next(iter(data.train_dl))\n",
    "b = xb.transpose(1,0).reshape(3,-1)\n",
    "data_mean=b.mean(1).cpu()\n",
    "data_std=b.std(1).cpu()\n",
    "data_mean,data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_batch(data.train_dl, train_ds.classes, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_tfm = normalize_tfm(mean=data_mean, std=data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tds = TfmDataset(valid_ds, valid_tfms+[norm_tfm], size=150, padding_mode='zeros')\n",
    "train_tds = TfmDataset(train_ds, train_tfms+[norm_tfm], size=150, padding_mode='zeros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(train_tds, valid_tds, bs=bs, num_workers=12)\n",
    "len(data.train_dl),len(data.valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet([1, 2, 4, 4, 2], num_classes=c, nf=16)\n",
    "learn = Learner(data, model)\n",
    "opt_fn = partial(optim.SGD, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, 0.1, opt_fn=opt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, 0.2, opt_fn=opt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, 0.4, opt_fn=opt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, 0.1, opt_fn=opt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "# display predictions\n",
    "# wd\n",
    "# 1cycle\n",
    "# lr find"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "11px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

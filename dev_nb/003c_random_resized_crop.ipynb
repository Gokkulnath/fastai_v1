{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from nb_002b import *\n",
    "\n",
    "import operator\n",
    "from random import sample\n",
    "from torch.utils.data.sampler import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('data')\n",
    "PATH = DATA_PATH/'caltech101'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caltech 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FilesDataset(Dataset):\n",
    "    def __init__(self, fns, labels, classes=None):\n",
    "        if classes is None: classes = list(set(labels))\n",
    "        self.classes = classes\n",
    "        self.class2idx = {v:k for k,v in enumerate(classes)}\n",
    "        self.fns = np.array(fns)\n",
    "        self.y = [self.class2idx[o] for o in labels]\n",
    "        \n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        return pil2tensor(x),self.y[i]\n",
    "    \n",
    "    @classmethod\n",
    "    def from_folder(cls, folder, classes=None, test_pct=0.):\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "            \n",
    "        fns,labels = [],[]\n",
    "        for cl in classes:\n",
    "            fnames = get_image_files(folder/cl)\n",
    "            fns += fnames\n",
    "            labels += [cl] * len(fnames)\n",
    "            \n",
    "        if test_pct==0.: return cls(fns, labels)\n",
    "        \n",
    "        fns,labels = np.array(fns),np.array(labels)\n",
    "        is_test = np.random.uniform(size=(len(fns),)) < test_pct\n",
    "        return cls(fns[~is_test], labels[~is_test]), cls(fns[is_test], labels[is_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"airplanes\", \"Motorbikes\", \"BACKGROUND_Google\", \"Faces\", \"watch\", \"Leopards\", \"bonsai\",\n",
    "    \"car_side\", \"ketch\", \"chandelier\", \"hawksbill\", \"grand_piano\", \"brain\", \"butterfly\", \"helicopter\", \"menorah\",\n",
    "    \"trilobite\", \"starfish\", \"kangaroo\", \"sunflower\", \"ewer\", \"buddha\", \"scorpion\", \"revolver\", \"laptop\", \"ibis\", \"llama\",\n",
    "    \"minaret\", \"umbrella\", \"electric_guitar\", \"crab\", \"crayfish\",]\n",
    "\n",
    "np.random.seed(42)\n",
    "train_ds,valid_ds = FilesDataset.from_folder(PATH, test_pct=0.2)\n",
    "\n",
    "x = train_ds[15][0]\n",
    "classes = train_ds.classes\n",
    "c = len(classes)\n",
    "\n",
    "len(train_ds),len(valid_ds),c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rectangular affine fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(x, figsize=(6,3), hide_axis=False)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_m = np.array(rotate(40.)); rot_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(apply_affine(rot_m)(x), figsize=(6,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def affine_grid(x, matrix, size=None):\n",
    "    h,w = x.shape[1:]\n",
    "    if size is None: size=x.shape\n",
    "    matrix[0,1] *= h/w; matrix[1,0] *= w/h\n",
    "    return F.affine_grid(matrix[None,:2], torch.Size((1,)+size))\n",
    "\n",
    "import nb_002\n",
    "nb_002.affine_grid = affine_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(apply_affine(rot_m)(x), figsize=(6,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomResizedCrop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to replicate the RandomResizedCrop function from torchvision. First we take a crop of the picture that has a certain size and a certain ratio, then we resize it to the desired output size. This is their code to pick the crop area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crop(img, scale, ratio):\n",
    "    for attempt in range(10):\n",
    "        area = img.size[0] * img.size[1]\n",
    "        target_area = random.uniform(*scale) * area\n",
    "        aspect_ratio = random.uniform(*ratio)\n",
    "\n",
    "        w = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "        h = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            w, h = h, w\n",
    "\n",
    "        if w <= img.size[0] and h <= img.size[1]:\n",
    "            i = random.randint(0, img.size[1] - h)\n",
    "            j = random.randint(0, img.size[0] - w)\n",
    "            return i, j, h, w\n",
    "\n",
    "    # Fallback\n",
    "    w = min(img.size[0], img.size[1])\n",
    "    i = (img.size[1] - w) // 2\n",
    "    j = (img.size[0] - w) // 2\n",
    "    return i, j, w, w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rewritting it to take tensors with channel, height, width order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crop(t, scale, ratio):\n",
    "    for attempt in range(10):\n",
    "        area = t.size(1) * t.size(2)\n",
    "        target_area = random.uniform(*scale) * area\n",
    "        aspect_ratio = random.uniform(*ratio)\n",
    "\n",
    "        w = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "        h = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            w, h = h, w\n",
    "\n",
    "        if w <= t.size(2) and h <= t.size(1):\n",
    "            i = random.randint(0, t.size(1) - h)\n",
    "            j = random.randint(0, t.size(2) - w)\n",
    "            return i, j, h, w\n",
    "\n",
    "    # Fallback\n",
    "    w = min(t.size(1), t.size(2))\n",
    "    i = (t.size(1) - w) // 2\n",
    "    j = (t.size(2) - w) // 2\n",
    "    return i, j, w, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,4,figsize=(8,12))\n",
    "for ax in axs.flatten():\n",
    "    i,j,h,w = get_crop(x, (0.08,1.), (3./4.,4./3.))\n",
    "    #Crop\n",
    "    y = x[:,i:i+h,j:j+w]\n",
    "    #Then resize to the output size.\n",
    "    y = F.interpolate(y[None], size=(224,224), mode='bilinear')\n",
    "    show_image(y[0], ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. With a start tfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to do this is to create a transform of type start and then go through the pipeline with the target size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@reg_transform\n",
    "def crop_with_ratio(x, scale:uniform, ratio:uniform, invert:rand_bool, row_pct:uniform, col_pct:uniform) -> TfmType.Start:\n",
    "    #scale, ratio and invert are supposed to have a size corresponding to the number of attempts before fallback.\n",
    "    for s,r,i in zip(scale, ratio, invert):\n",
    "        area = x.size(1) * x.size(2)\n",
    "        target_area = area * s\n",
    "        cols = int(round(math.sqrt(target_area * r)))\n",
    "        rows = int(round(math.sqrt(target_area / r)))\n",
    "\n",
    "        if i: cols,rows = rows,cols\n",
    "\n",
    "        if cols <= x.size(2) and rows <= x.size(1):\n",
    "            row = int((x.size(1)-rows+1)*row_pct)\n",
    "            col = int((x.size(2)-cols+1)*col_pct)\n",
    "            return x[:, row:row+rows, col:col+cols].contiguous()\n",
    "    # Fallback\n",
    "    rows = min(x.size(1), x.size(2))\n",
    "    row = (x.size(1) - rows) // 2\n",
    "    col = (x.size(2) - rows) // 2\n",
    "    return x[:, row:row+rows, col:col+rows].contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_resized_crop = crop_with_ratio_tfm(scale=(0.08,1.,10), ratio=(0.75,1.33,10),invert=(0.5,10),\n",
    "                                          row_pct=(0,1.), col_pct=(0,1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,4,figsize=(8,12))\n",
    "for ax in axs.flatten():\n",
    "    #Crop\n",
    "    y = random_resized_crop()(x)\n",
    "    #Then resize to the output size.\n",
    "    y = F.interpolate(y[None], size=(224,224), mode='bilinear')\n",
    "    show_image(y[0], ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,4,figsize=(8,12))\n",
    "for ax in axs.flatten():\n",
    "    y = apply_tfms([random_resized_crop])(x, size=(3,224,224))\n",
    "    show_image(y, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.The affine way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scale and ratio is just an affine transformation that zooms in and squeeshes the picture in a given direction. Then the random crop corresponds to a center differnet from (0,0). So all of this can be done as an affine transformation (then coupled with others, like a rotation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@reg_affine\n",
    "def zoom_squish(scale: uniform = 1.0, squish: uniform=1.0, invert: rand_bool = False, \n",
    "                row_pct:uniform = 0.5, col_pct:uniform = 0.5) -> TfmType.Affine:\n",
    "    for s,r, i in zip(scale,squish, invert):\n",
    "        s,r = math.sqrt(s),math.sqrt(r)\n",
    "        if s * r <= 1 and s / r < 1:\n",
    "            w,h = (s/r, s*r) if i else (s*r,s/r)\n",
    "            col_c = (1-w) * (2*col_pct - 1)\n",
    "            row_c = (1-h) * (2*row_pct - 1)\n",
    "            return [[w, 0, col_c],\n",
    "                    [0, h, row_c],\n",
    "                    [0, 0, 1.   ]]\n",
    "    return [[1, 0, 0.],\n",
    "            [0, 1, 0.],\n",
    "            [0, 0, 1.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_resized_crop = zoom_squish_tfm(scale=(0.08,1.,10), squish=(0.75,1.33, 10), invert=(0.5,10), row_pct=(0,1.), col_pct=(0,1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,4,figsize=(8,12))\n",
    "for ax in axs.flatten():\n",
    "    #Crop\n",
    "    y = apply_tfms([random_resized_crop])(x, size=(3,224,224))\n",
    "    show_image(y, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic RandomResizedCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_ds[15][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = x.size(1) * x.size(2)\n",
    "target_area = 0.5 * area\n",
    "aspect_ratio = 0.8\n",
    "w = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "h = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_v1(img):\n",
    "    area = img.size(1) * img.size(2)\n",
    "    target_area = 0.5 * area\n",
    "    aspect_ratio = 0.8\n",
    "\n",
    "    w = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "    h = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "\n",
    "    w, h = h, w\n",
    "\n",
    "    i = int(0.2 * (img.size(1) - h))\n",
    "    j = int(0.4 * (img.size(2) - w))\n",
    "    x = img[:,i:i+h, j:j+w]\n",
    "    return F.interpolate(x[None], size=(224,224), mode='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(crop_v1(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_v2(img):\n",
    "    x = crop_with_ratio(img, [0.5], [0.8], [True], 0.2, 0.4)\n",
    "    x = F.interpolate(x[None], size=(224,224), mode='bilinear')\n",
    "    return x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(crop_v2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_ratio = math.sqrt(x.size(2)/x.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@reg_affine\n",
    "def zoom_squish1(scale: uniform = 1.0, squish: uniform=1.0, invert: rand_bool = False, \n",
    "                row_pct:uniform = 0.5, col_pct:uniform = 0.5) -> TfmType.Affine:\n",
    "    for s,r, i in zip(scale,squish, invert):\n",
    "        s,r = math.sqrt(s),math.sqrt(r)\n",
    "        if s * r <= 1 and s / r < 1:\n",
    "            w,h = (s/r, s*r) if i else (s*r,s/r)\n",
    "            w /= orig_ratio\n",
    "            h *= orig_ratio\n",
    "            col_c = (1-w) * (2*col_pct - 1)\n",
    "            row_c = (1-h) * (2*row_pct - 1)\n",
    "            return [[w, 0, col_c],\n",
    "                    [0, h, row_c],\n",
    "                    [0, 0, 1.   ]]\n",
    "    if orig_ratio > 1: \n",
    "        return [[1/orig_ratio**2, 0, 0.],\n",
    "                [0, 1, 0.],\n",
    "                [0, 0, 1.]]\n",
    "    else:\n",
    "        return [[1, 0, 0.],\n",
    "                [0, orig_ratio**2, 0.],\n",
    "                [0, 0, 1.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_v3(img):\n",
    "    x = apply_affine(zoom_squish1([0.5], [0.8], [True], 0.2, 0.4))(img, size=(3,224,224))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(crop_v3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_001b import *\n",
    "from PIL import Image\n",
    "import PIL, matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from operator import itemgetter, attrgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temp storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_listy(x): return isinstance(x, (list,tuple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carvana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/carvana')\n",
    "PATH_PNG = PATH/'train_masks_png'\n",
    "PATH_X = PATH/'train-128'\n",
    "PATH_Y = PATH/'train_masks-128'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert and resize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PNG.mkdir(exist_ok=True)\n",
    "PATH_X.mkdir(exist_ok=True)\n",
    "PATH_Y.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_img(fn): Image.open(fn).save(PATH_PNG/f'{fn.name[:-4]}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list((PATH/'train_masks').iterdir())\n",
    "with ThreadPoolExecutor(8) as e: e.map(convert_img, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(fn, dirname):\n",
    "    Image.open(fn).resize((128,128)).save((fn.parent.parent)/dirname/fn.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(PATH_PNG).iterdir())\n",
    "with ThreadPoolExecutor(8) as e: e.map(partial(resize_img, dirname='train_masks-128'), files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list((PATH/'train').iterdir())\n",
    "with ThreadPoolExecutor(8) as e: e.map(partial(resize_img, dirname='train-128'), files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_f = next(PATH_X.iterdir())\n",
    "img_x = open_image(img_f)\n",
    "show_image(img_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_fn(x_fn): return f'{x_fn[:-4]}_mask.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_y_f = PATH_Y/get_y_fn(img_f.name)\n",
    "img_y = open_image(img_y_f)\n",
    "show_image(img_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x(): return open_image(img_f)\n",
    "def y(): return open_image(img_y_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [flip_lr_tfm(p=0.5),\n",
    "        rotate_tfm(degrees=(-10,10.), p=0.25),\n",
    "        zoom_tfm(scale=(0.8,1.2), p=0.25),\n",
    "        contrast_tfm(scale=(0.8,1.2)),\n",
    "        brightness_tfm(change=(0.4,0.6))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(1,4, figsize=(12,3))\n",
    "for ax in axes: show_image(apply_pipeline(x(), tfms), ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(1,4, figsize=(12,3))\n",
    "for ax in axes: show_image(apply_pipeline(y(), tfms), ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependent var transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy(): return x(),y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolve_args(brightness, change=(0.4,0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_rand(x, y=None, smooth_y=True):\n",
    "    args = resolve_args(rotate, degrees=(-45,45.))\n",
    "    m = rotate(**args)\n",
    "    x = do_affine(x, m)\n",
    "    if y is None: return x\n",
    "    \n",
    "    y = do_affine(y, m)\n",
    "    if not smooth_y: torch.round_(y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgx,imgy = rotate_rand(*xy(), smooth_y=False)\n",
    "assert(torch.any((imgy>0.) & (imgy<1.)) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(2,4, figsize=(12,6))\n",
    "for i in range(4):\n",
    "    imgx,imgy = rotate_rand(*xy(), smooth_y=False)\n",
    "    show_image(imgx, axes[0][i])\n",
    "    show_image(imgy, axes[1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(2,4, figsize=(12,6))\n",
    "for i in range(4):\n",
    "    imgx,imgy = rotate_rand(x(),x())\n",
    "    show_image(imgx, axes[0][i])\n",
    "    show_image(imgy, axes[1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(1,4, figsize=(12,6))\n",
    "for ax in axes: show_image(rotate_rand(x()), ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_affine(img_x, img_y=None, m=None, funcs=None, smooth_y=True):\n",
    "    if m is None: m=eye_new(img_x, 3)\n",
    "    c = affine_grid(img_x,  img_x.new_tensor(m))\n",
    "    c = compose(funcs)(c)\n",
    "    img_x = grid_sample(img_x, c, padding='zeros')\n",
    "    if img_y is None: return img_x\n",
    "\n",
    "    img_y = grid_sample(img_y, c, padding='zeros')\n",
    "    if not smooth_y: torch.round_(img_y)\n",
    "    return img_x, img_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pixel_tfm(func): \n",
    "    def _inner(x,y=None):\n",
    "        logit_(x)\n",
    "        if y is None: return func(x).sigmoid()\n",
    "        logit_(y)\n",
    "        x,y = func(x,y)\n",
    "        return x.sigmoid(),y.sigmoid()\n",
    "    \n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pipeline(tfms, x, y=None, smooth_y=True):\n",
    "    tfms = listify(tfms)\n",
    "    if len(tfms)==0: return x\n",
    "    grouped_tfms = dict_groupby(tfms, lambda o: o.__annotations__['return'])\n",
    "    pixel_tfms,coord_tfms,affine_tfms = map(grouped_tfms.get, TfmType)\n",
    "    x = apply_pixel_tfm(compose(pixel_tfms))(x,y)\n",
    "    if isinstance(x,tuple): x,y = x\n",
    "    matrices = [f() for f in listify(affine_tfms)]\n",
    "    return do_affine(x, y, affines_mat(x, matrices), funcs=coord_tfms, smooth_y=smooth_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [rotate_tfm(degrees=(-45,45.)), brightness_tfm(change=(0.3,0.7))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgx,imgy = apply_pipeline(tfms, *xy(), smooth_y=False)\n",
    "assert(torch.any((imgy>0.) & (imgy<1.)) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(2,4, figsize=(12,6))\n",
    "for i in range(4):\n",
    "    imgx,imgy = apply_pipeline(tfms, *xy(), smooth_y=False)\n",
    "    show_image(imgx, axes[0][i])\n",
    "    show_image(imgy, axes[1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(2,4, figsize=(12,6))\n",
    "for i in range(4):\n",
    "    imgx,imgy = apply_pipeline(tfms, x(),x())\n",
    "    show_image(imgx, axes[0][i])\n",
    "    show_image(imgy, axes[1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(1,4, figsize=(12,6))\n",
    "for ax in axes: show_image(apply_pipeline(tfms, x()), ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms2 = [jitter_tfm(magnitude=(-0.1,0.1))]\n",
    "\n",
    "_,axes = plt.subplots(1,4, figsize=(12,6))\n",
    "for ax in axes: show_image(apply_pipeline(tfms2, x()), ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending the training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRFind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = PATH/'models'\n",
    "MODEL_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "TEMP_MODEL_NAME = 'tmp.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, fname): torch.save(model.state_dict(), fname)\n",
    "def load_model(model, fname): model.load_state_dict(torch.load(fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sylvain's transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import IntEnum\n",
    "\n",
    "class TfmType(IntEnum):\n",
    "    NO = 1\n",
    "    PIXEL = 2\n",
    "    COORD = 3\n",
    "    CLASS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "\n",
    "class Transform():\n",
    "    \n",
    "    def __init__(self, tfm_y=TfmType.NO, p=1, batch_lvl = False):\n",
    "        self.tfm_y,self.p,self.batch_lvl = tfm_y,p,batch_lvl\n",
    "    \n",
    "    def __call__(self, x, y):\n",
    "        x,y = ((self.transform(x),y) if self.tfm_y==TfmType.NO\n",
    "                else self.transform(x,y) if self.tfm_y in (TfmType.PIXEL, TfmType.CLASS)\n",
    "                else self.transform_coord(x,y))\n",
    "        return x, y\n",
    "    \n",
    "    def set_device(self, device):\n",
    "        if not self.batch_lvl: self.device = device\n",
    "    \n",
    "    def transform_coord(self, x, y):\n",
    "        if self.p == 1 or np.random.rand < self.p:\n",
    "            return self.transform(x),y\n",
    "\n",
    "    def transform(self, x, y=None):\n",
    "        if self.p == 1 or np.random.rand < self.p:\n",
    "            x = self.do_transform(x,False)\n",
    "            return (x, self.do_transform(y,True)) if y is not None else x\n",
    "        else: return x,y\n",
    "    \n",
    "    @abstractmethod\n",
    "    def do_transform(self, x, is_y): raise NotImplementedError\n",
    "    #In do_transform we can save a value (angle of a random rotation for instance) in self.save_for_y that will be used\n",
    "    #if is_y is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelOrder(Transform):\n",
    "    #If we use PIL for data augmentation, maybe the conversion to a numpy array should be handled here?\n",
    "    def __init__(self, tfm_y=TfmType.NO):\n",
    "        super().__init__(tfm_y=tfm_y)\n",
    "    \n",
    "    def do_transform(self, x, is_y):\n",
    "        if not is_y or self.tfm_y == TfmType.PIXEL: x = np.rollaxis(x, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(Transform):\n",
    "    \n",
    "    def __init__(self, means, stds, tfm_y=TfmType.NO):\n",
    "        self.means,self.stds = means,stds\n",
    "        super().__init__(tfm_y=tfm_y, batch_lvl=True)\n",
    "    \n",
    "    def set_device(self, device):\n",
    "        super().set_device(device)\n",
    "        if type(self.means) != torch.Tensor or not self.means.device == device:\n",
    "            self.means,self.stds = map(lambda x:torch.Tensor(x).to(device), (self.means, self.stds))\n",
    "    \n",
    "    def do_transform(self, x, is_y):\n",
    "        if not is_y or self.tfm_y == TfmType.PIXEL:\n",
    "            m, s = self.means[None,:,None,None].type_as(x), self.stds[None,:,None,None].type_as(x)\n",
    "            x = (x - m) / s\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose(tfms, x, y):\n",
    "    for tfm in tfms: x,y = tfm(x,y)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_one_tfms(tfms):\n",
    "    ds_tfms = [tfm for tfm in tfms if not tfm.batch_lvl]\n",
    "    dl_tfms = [tfm for tfm in tfms if tfm.batch_lvl]\n",
    "    return ds_tfms,dl_tfms\n",
    "    \n",
    "def split_tfms(trn_tfms, val_tfms):\n",
    "    trn_ds_tfms, trn_dl_tfms = split_one_tfms(trn_tfms)\n",
    "    val_ds_tfms, val_dl_tfms = split_one_tfms(val_tfms)\n",
    "    return trn_ds_tfms, val_ds_tfms, trn_dl_tfms, val_dl_tfms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Training metrics"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "*Metrics* for training fastai models are simply functions that take `input` and `target` tensors, and return some metric of interest for training. You can write your own metrics by defining a function of that type, and passing it to [`Learner`](/basic_train.html#Learner) in the [code]metrics[/code] parameter, or use one of the following pre-defined functions."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": "from fastai.gen_doc.nbdoc import *\nfrom fastai.metrics import * "
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Predefined metrics:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=accuracy></a>`accuracy`\n`accuracy`(`input`:`Tensor`, `targs`:`Tensor`) -> `OneEltTensor`\n\n\nAccuracy <a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/metrics.py#L31\">[source]</a>",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(accuracy)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=accuracy_thresh></a>`accuracy_thresh`\n`accuracy_thresh`(`y_pred`:`Tensor`, `y_true`:`Tensor`, `thresh`:`float`=`0.5`, `sigmoid`:`bool`=`True`) -> `OneEltTensor`\n<a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/metrics.py#L18\">[source]</a>",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(accuracy_thresh)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Accuracy for multi-label models, based on comparing predictions to `thresh`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=dice></a>`dice`\n`dice`(`input`:`Tensor`, `targs`:`Tensor`) -> `OneEltTensor`\n\n\nDice coefficient metric for binary target <a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/metrics.py#L22\">[source]</a>",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(dice)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=fbeta></a>`fbeta`\n`fbeta`(`y_pred`:`Tensor`, `y_true`:`Tensor`, `thresh`:`float`=`0.5`, `beta`:`float`=`2`, `eps`:`float`=`1e-09`, `sigmoid`:`bool`=`True`) -> `OneEltTensor`\n\n\nComputes the f_beta between preds and targets <a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/metrics.py#L6\">[source]</a>",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(fbeta)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "See the [F1 score wikipedia page](https://en.wikipedia.org/wiki/F1_score) for details."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=exp_rmspe></a>`exp_rmspe`\n`exp_rmspe`(`pred`:`Tensor`, `targ`:`Tensor`) -> `OneEltTensor`\n<a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/metrics.py#L38\">[source]</a>",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(exp_rmspe)"
  }
 ],
 "metadata": {
  "jekyll": {
   "summary": "Implements various metrics to measure training accuracy",
   "title": "metrics"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

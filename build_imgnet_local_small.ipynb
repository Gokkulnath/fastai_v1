{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import shutil\n",
    "import tqdm\n",
    "\n",
    "from nb_005 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMGNET = Path('/DATA/kaggle/imgnetloc/')\n",
    "IMAGES_TRAIN = Path('/DATA/kaggle/imgnetloc/ILSVRC/Data/CLS-LOC/train/')\n",
    "IMAGES_VAL = Path('/DATA/kaggle/imgnetloc/ILSVRC/Data/CLS-LOC/val/')\n",
    "TRAIN_SOLUTION_CSV = IMGNET/'LOC_train_solution.csv'\n",
    "VALID_SOLUTION_CSV = IMGNET/'LOC_val_solution.csv'\n",
    "ANNO_TRAIN = Path('/DATA/kaggle/imgnetloc/ILSVRC/Annotations/CLS-LOC/train/')\n",
    "ANNO_VAL = Path('/DATA/kaggle/imgnetloc/ILSVRC/Annotations/CLS-LOC/val/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse one line of class file, just going to grab first descriptions\n",
    "def parse_class_line(l):\n",
    "    id = l.split(' ')[0]\n",
    "    classes = l[len(id):].strip().split(',')\n",
    "    return id, classes[0].strip()\n",
    "\n",
    "# read in mapping of class id to text description\n",
    "def read_classes(fn):\n",
    "    classes = dict(map(parse_class_line, open(fn,'r').readlines()))\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = read_classes(IMGNET/'LOC_synset_mapping.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_fns(img_train_path, class_id):\n",
    "    img_fns = []\n",
    "    for fn in (img_train_path/class_id).iterdir():\n",
    "        img_fns.append(fn)\n",
    "    return img_fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(clsid):\n",
    "    img_fns = get_img_fns(IMAGES_TRAIN, clsid)\n",
    "    images = [open_image(fn) for fn in np.random.choice(img_fns, 9)]\n",
    "    _,axes = plt.subplots(3,3, figsize=(12,6))\n",
    "    for i in range(9):\n",
    "        images[i].show(axes[i//3,i%3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pull = {\n",
    "    'n01443537': 'goldfish',\n",
    "    'n01669191': 'box turtle',\n",
    "    'n01774750': 'tarantula',\n",
    "    'n01641577': 'bullfrog',\n",
    "    'n01882714': 'koala',\n",
    "    'n01983481': 'American lobster',\n",
    "    'n02114367': 'timber wolf',\n",
    "    'n02115641': 'dingo',\n",
    "    'n02317335': 'starfish',\n",
    "    'n01806143': 'peacock',\n",
    "    'n01484850': 'great white shark',\n",
    "    'n03063689': 'coffeepot',\n",
    "    'n03272010': 'electric guitar',\n",
    "    'n03124170': 'cowboy hat',\n",
    "    'n02799071': 'baseball',\n",
    "    'n03400231': 'frying pan',\n",
    "    'n03452741': 'grand piano',\n",
    "    'n02802426': 'basketball',\n",
    "    'n02692877': 'airship',\n",
    "    'n02787622': 'banjo',\n",
    "    'n03785016': 'moped',\n",
    "    'n04252077': 'snowmobile',\n",
    "    'n02088466': 'bloodhound',\n",
    "    'n04254680': 'soccer ball',\n",
    "    'n02504458': 'African elephant',\n",
    "    'n03345487': 'fire engine',\n",
    "    'n03642806': 'squirrel',\n",
    "    'n03063599': 'coffee mug',\n",
    "}\n",
    "\n",
    "pull_classes = to_pull.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in to_pull:\n",
    "    plot_samples(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_images = 0\n",
    "for clsid, name in to_pull.items():\n",
    "    img_fns = get_img_fns(IMAGES_TRAIN, clsid)\n",
    "    num_images = len(img_fns)\n",
    "    total_images += num_images\n",
    "    print(name, num_images)\n",
    "print('total images:', total_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv(VALID_SOLUTION_CSV)\n",
    "train_df = pd.read_csv(TRAIN_SOLUTION_CSV)\n",
    "\n",
    "len(train_df), len(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['classid'] = train_df.ImageId.apply(lambda x: x.split('_')[0])\n",
    "\n",
    "def parse_prediction_string(s):\n",
    "    ids = []\n",
    "    items = s.split(' ')\n",
    "    pred_count = len(items) // 5\n",
    "    for i in range(pred_count):\n",
    "        ids.append(items[i*5])\n",
    "    return ids[0]\n",
    "\n",
    "valid_df['classid'] = valid_df.PredictionString.apply(parse_prediction_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_df = train_df.loc[train_df.classid.isin(pull_classes)]\n",
    "small_valid_df = valid_df.loc[valid_df.classid.isin(pull_classes)]\n",
    "len(pull_classes), small_train_df.shape, small_valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMGNET_SMALL = Path('/DATA/kaggle/imgnetloc_small/')\n",
    "SMALL_DATA = IMGNET_SMALL/'ILSVRC/Data/CLS-LOC'\n",
    "SMALL_ANNO = IMGNET_SMALL/'ILSVRC/Annotations/CLS-LOC'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_DATA.mkdir(parents=True, exist_ok=True)\n",
    "SMALL_ANNO.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dirpath/'train').mkdir(parents=True, exist_ok=True)\n",
    "(dirpath/'val').mkdir(parents=True, exist_ok=True)\n",
    "(SMALL_DATA/'train').mkdir(parents=True, exist_ok=True)\n",
    "(SMALL_ANNO/'val').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy training directories\n",
    "for k in tqdm.tqdm_notebook(pull_classes):\n",
    "    src_data_path = IMAGES_TRAIN/k\n",
    "    dest_data_path = SMALL_DATA/'train'/k\n",
    "    if dest_data_path.exists():\n",
    "        shutil.rmtree(dest_data_path) \n",
    "    shutil.copytree(src_data_path, dest_data_path)\n",
    "    \n",
    "    src_data_path = ANNO_TRAIN/k\n",
    "    dest_data_path = SMALL_ANNO/'train'/k\n",
    "    if dest_data_path.exists():\n",
    "        shutil.rmtree(dest_data_path)\n",
    "    shutil.copytree(src_data_path, dest_data_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy validation directories\n",
    "dest_val_data = SMALL_DATA/'val'\n",
    "dest_val_anno = SMALL_ANNO/'val'\n",
    "if dest_val_data.exists():\n",
    "    shutil.rmtree(dest_val_data)\n",
    "if dest_val_anno.exists():\n",
    "    shutil.rmtree(dest_val_anno)\n",
    "\n",
    "dest_val_data.mkdir(parents=True, exist_ok=True)\n",
    "dest_val_anno.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for ix, row in tqdm.tqdm_notebook(list(small_valid_df.ImageId.items())):\n",
    "    src_file = IMAGES_VAL/f'{row}.JPEG'\n",
    "    dest_file = dest_val_data/f'{row}.JPEG'\n",
    "    shutil.copyfile(src_file, dest_file)\n",
    "    \n",
    "    src_file = ANNO_VAL/f'{row}.xml'\n",
    "    dest_file = dest_val_anno/f'{row}.xml'\n",
    "    shutil.copyfile(src_file, dest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy class file\n",
    "src_file = IMGNET/'LOC_synset_mapping.txt'\n",
    "dst_file = IMGNET_SMALL/'LOC_synset_mapping.txt'\n",
    "\n",
    "with open(src_file,'r') as rf:\n",
    "    src_lines = rf.readlines()\n",
    "with open(dst_file,'w') as wf:\n",
    "    for line in src_lines:\n",
    "        clsid = line.split(' ')[0]\n",
    "        if clsid in pull_classes:\n",
    "            wf.write(line)\n",
    "        \n",
    "\n",
    "# copy train train loc file\n",
    "src_file = IMGNET/'LOC_train_solution.csv'\n",
    "dst_file = IMGNET_SMALL/'LOC_train_solution.csv'\n",
    "\n",
    "with open(src_file,'r') as rf:\n",
    "    src_lines = rf.readlines()\n",
    "with open(dst_file,'w') as wf:\n",
    "    for line in src_lines:\n",
    "        clsid = line.split(' ')[0]\n",
    "        if clsid in pull_classes:\n",
    "            wf.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy train loc\n",
    "src_file = IMGNET/'LOC_train_solution.csv'\n",
    "dst_file = IMGNET_SMALL/'LOC_train_solution.csv'\n",
    "\n",
    "with open(src_file,'r') as rf:\n",
    "    src_lines = rf.readlines()\n",
    "\n",
    "with open(dst_file,'w') as wf:\n",
    "    wf.write(src_lines[0])\n",
    "    for line in src_lines[1:]:\n",
    "        clsid = line[0:9]\n",
    "        if clsid in pull_classes:\n",
    "            wf.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy val loc\n",
    "src_file = IMGNET/'LOC_val_solution.csv'\n",
    "dst_file = IMGNET_SMALL/'LOC_val_solution.csv'\n",
    "\n",
    "with open(src_file,'r') as rf:\n",
    "    src_lines = rf.readlines()\n",
    "\n",
    "with open(dst_file,'w') as wf:\n",
    "    wf.write(src_lines[0])\n",
    "    for line in src_lines[1:]:\n",
    "        clsid = line[0:9]\n",
    "        if clsid in pull_classes:\n",
    "            wf.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_file = IMGNET/'LOC_val_solution.csv'\n",
    "dst_file = IMGNET_SMALL/'LOC_val_solution.csv'\n",
    "\n",
    "with open(src_file,'r') as rf:\n",
    "    src_lines = rf.readlines()\n",
    "    \n",
    "with open(dst_file,'w') as wf:\n",
    "    wf.write(src_lines[0])\n",
    "    for line in src_lines[1:]:\n",
    "        clsid = line.split(',')[1][0:9]\n",
    "        if clsid in pull_classes:\n",
    "            wf.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_df.groupby('classid').ImageId.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
